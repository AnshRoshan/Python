{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üõ†Ô∏è Python Standard Library Essentials: Power Tools for Everyday Tasks\n",
    "\n",
    "**Welcome!** This notebook is your guide to some of the most powerful and frequently used modules within Python's extensive Standard Library: `datetime`, `math`, `re` (Regular Expressions), and `functools`. Mastering these modules unlocks significant capabilities for handling time, calculations, text patterns, and function manipulation, forming the bedrock of many Python applications.\n",
    "\n",
    "**Target Audience:** Beginner to Intermediate Python developers looking to leverage the built-in capabilities of Python for common programming tasks.\n",
    "\n",
    "**Learning Objectives:**\n",
    "*   Manipulate dates, times, durations, and timezones effectively using `datetime`.\n",
    "*   Perform advanced mathematical calculations with the `math` module.\n",
    "*   Master the art of pattern matching in strings using regular expressions (`re`).\n",
    "*   Enhance function capabilities with higher-order functions and decorators using `functools`.\n",
    "*   Understand best practices, performance considerations, and common pitfalls for each module.\n",
    "*   Apply these modules to solve practical problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. `datetime`: Working with Dates and Times\n",
    "\n",
    "**Introduction:** Handling dates and times is fundamental in many applications, from logging events and scheduling tasks to calculating durations and analyzing time-series data. Python's `datetime` module provides a comprehensive set of classes for these tasks.\n",
    "\n",
    "**Real-world Use Cases:**\n",
    "*   **Logging:** Timestamping events accurately.\n",
    "*   **Web Applications:** Handling user session timeouts, displaying post dates, calculating durations.\n",
    "*   **Data Analysis:** Parsing date strings, calculating time differences, working with time series.\n",
    "*   **Scheduling:** Determining when tasks should run (e.g., cron jobs).\n",
    "*   **Finance:** Calculating interest periods, expiration dates.\n",
    "\n",
    "**Analogy: The Timekeeper's Toolkit**\n",
    "Think of the `datetime` module as a sophisticated toolkit used by a master timekeeper. It contains:\n",
    "*   A precise **Calendar** (`date`): To represent specific days.\n",
    "*   An accurate **Clock** (`time`): To represent time within a day (independent of date).\n",
    "*   A combined **Chronometer** (`datetime`): To pinpoint an exact moment in time (date and time).\n",
    "*   A flexible **Stopwatch/Timer** (`timedelta`): To measure durations or calculate future/past points.\n",
    "*   A **World Atlas of Time Zones** (`timezone`, `tzinfo`, often used with `zoneinfo` or `pytz`): To handle different time zones correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Core Classes\n",
    "\n",
    "*   `datetime.date`: Represents a date (year, month, day).\n",
    "*   `datetime.time`: Represents a time (hour, minute, second, microsecond), independent of day. Can be *naive* or *aware* of time zones.\n",
    "*   `datetime.datetime`: Represents a specific point in time (combines date and time). Can be *naive* or *aware*.\n",
    "*   `datetime.timedelta`: Represents a duration or difference between two dates or times.\n",
    "*   `datetime.timezone`: Represents a timezone offset from UTC (e.g., `timezone(timedelta(hours=-5))`). Introduced in Python 3.2.\n",
    "*   `datetime.tzinfo`: Abstract base class for timezone information. You typically use concrete implementations like those from `zoneinfo` or `pytz`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Getting Current Date and Time\n",
    "\n",
    "**Important Distinction:**\n",
    "*   **Naive:** Objects don't have enough information to determine their offset from UTC or handle DST unambiguously.\n",
    "*   **Aware:** Objects *do* contain timezone information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today's date: 2025-04-20\n",
      "Year: 2025, Month: 4, Day: 20\n",
      "Weekday (0=Mon, 6=Sun): 6\n",
      "ISO Weekday (1=Mon, 7=Sun): 7\n",
      "\n",
      "Now (local, naive): 2025-04-20 16:11:53.066694\n",
      "Now (UTC, naive - Legacy): 2025-04-20 10:41:53.066901\n",
      "Now (UTC, aware - Recommended): 2025-04-20 10:41:53.067024+00:00\n",
      "Is aware? True\n",
      "\n",
      "Current Unix Timestamp: 1745145713.0672643\n",
      "Datetime from timestamp (UTC): 2025-04-20 10:41:53.067264+00:00\n",
      "Timestamp from aware datetime: 1745145713.067024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9625/1914975334.py:17: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  now_utc_naive_legacy = datetime.utcnow()\n"
     ]
    }
   ],
   "source": [
    "from datetime import date, time, datetime, timedelta, timezone\n",
    "import time as time_module # To avoid name collision\n",
    "\n",
    "# --- Current Date --- \n",
    "today = date.today()\n",
    "print(f\"Today's date: {today}\")\n",
    "print(f\"Year: {today.year}, Month: {today.month}, Day: {today.day}\")\n",
    "print(f\"Weekday (0=Mon, 6=Sun): {today.weekday()}\")\n",
    "print(f\"ISO Weekday (1=Mon, 7=Sun): {today.isoweekday()}\")\n",
    "\n",
    "# --- Current Date and Time --- \n",
    "# datetime.now() - Local time (can be naive or aware depending on tz arg)\n",
    "now_local_naive = datetime.now() # Naive local time by default\n",
    "print(f\"\\nNow (local, naive): {now_local_naive}\")\n",
    "\n",
    "# datetime.utcnow() - UTC time, BUT **NAIVE** (legacy, avoid for new code)\n",
    "now_utc_naive_legacy = datetime.utcnow()\n",
    "print(f\"Now (UTC, naive - Legacy): {now_utc_naive_legacy}\") \n",
    "\n",
    "# **Modern Best Practice: Get Aware UTC Time**\n",
    "now_utc_aware = datetime.now(timezone.utc)\n",
    "print(f\"Now (UTC, aware - Recommended): {now_utc_aware}\") \n",
    "print(f\"Is aware? {now_utc_aware.tzinfo is not None}\")\n",
    "\n",
    "# --- Unix Timestamp --- \n",
    "# Seconds since the Epoch (Jan 1, 1970 UTC)\n",
    "timestamp = time_module.time()\n",
    "print(f\"\\nCurrent Unix Timestamp: {timestamp}\")\n",
    "\n",
    "# Convert timestamp to aware datetime object\n",
    "dt_from_timestamp = datetime.fromtimestamp(timestamp, tz=timezone.utc)\n",
    "print(f\"Datetime from timestamp (UTC): {dt_from_timestamp}\")\n",
    "\n",
    "# Convert aware datetime back to timestamp\n",
    "timestamp_from_dt = now_utc_aware.timestamp()\n",
    "print(f\"Timestamp from aware datetime: {timestamp_from_dt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Creating Specific Dates and Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specific date: 2024-07-15\n",
      "Specific time (naive): 14:30:05\n",
      "Specific datetime (naive): 2024-07-15 14:30:05.123456\n",
      "Combined datetime (naive): 2024-07-15 14:30:05\n"
     ]
    }
   ],
   "source": [
    "from datetime import date, time, datetime\n",
    "\n",
    "d1 = date(2024, 7, 15)\n",
    "print(f\"Specific date: {d1}\")\n",
    "\n",
    "t1 = time(14, 30, 5) # 2:30:05 PM (naive)\n",
    "print(f\"Specific time (naive): {t1}\")\n",
    "\n",
    "dt1 = datetime(2024, 7, 15, 14, 30, 5, 123456) # Naive datetime\n",
    "print(f\"Specific datetime (naive): {dt1}\")\n",
    "\n",
    "# Combine date and time\n",
    "dt2 = datetime.combine(d1, t1)\n",
    "print(f\"Combined datetime (naive): {dt2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Time Deltas (`timedelta`)\n",
    "\n",
    "Used for representing durations and performing date/time arithmetic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time delta: 5 days, 3:15:10\n",
      "Total seconds in delta: 443710.0\n",
      "\n",
      "Current time: 2025-04-20 16:11:53.092456\n",
      "Future time: 2025-04-25 19:27:03.092456\n",
      "Past time: 2025-04-06 16:11:53.092456\n",
      "\n",
      "Duration between 2023-01-01 10:00:00 and 2023-01-05 14:30:00: 4 days, 4:30:00\n",
      "Duration in days: 4\n",
      "Duration total seconds: 361800.0\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "delta1 = timedelta(days=5, hours=3, minutes=15, seconds=10)\n",
    "print(f\"Time delta: {delta1}\")\n",
    "print(f\"Total seconds in delta: {delta1.total_seconds()}\")\n",
    "\n",
    "now = datetime.now() # Naive local\n",
    "print(f\"\\nCurrent time: {now}\")\n",
    "\n",
    "# Add timedelta\n",
    "future_time = now + delta1\n",
    "print(f\"Future time: {future_time}\")\n",
    "\n",
    "# Subtract timedelta\n",
    "past_time = now - timedelta(weeks=2)\n",
    "print(f\"Past time: {past_time}\")\n",
    "\n",
    "# Calculate difference between two datetimes\n",
    "dt_start = datetime(2023, 1, 1, 10, 0, 0)\n",
    "dt_end = datetime(2023, 1, 5, 14, 30, 0)\n",
    "duration = dt_end - dt_start\n",
    "print(f\"\\nDuration between {dt_start} and {dt_end}: {duration}\")\n",
    "print(f\"Duration in days: {duration.days}\")\n",
    "print(f\"Duration total seconds: {duration.total_seconds()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Formatting (`strftime`) and Parsing (`strptime`)\n",
    "\n",
    "*   `strftime` (String **Format** Time): Converts `datetime` object to a formatted string.\n",
    "*   `strptime` (String **Parse** Time): Converts a string into a `datetime` object based on a format.\n",
    "\n",
    "Common Format Codes (Full list in Python docs):\n",
    "*   `%Y`: Year with century (e.g., 2023)\n",
    "*   `%y`: Year without century (e.g., 23)\n",
    "*   `%m`: Month as zero-padded decimal (01, ..., 12)\n",
    "*   `%d`: Day of the month as zero-padded decimal (01, ..., 31)\n",
    "*   `%H`: Hour (24-hour clock) as zero-padded decimal (00, ..., 23)\n",
    "*   `%I`: Hour (12-hour clock) as zero-padded decimal (01, ..., 12)\n",
    "*   `%M`: Minute as zero-padded decimal (00, ..., 59)\n",
    "*   `%S`: Second as zero-padded decimal (00, ..., 59)\n",
    "*   `%f`: Microsecond as decimal number (000000-999999)\n",
    "*   `%a`: Abbreviated weekday name (Sun, Mon, ...)\n",
    "*   `%A`: Full weekday name (Sunday, Monday, ...)\n",
    "*   `%b`: Abbreviated month name (Jan, Feb, ...)\n",
    "*   `%B`: Full month name (January, February, ...)\n",
    "*   `%Z`: Time zone name (if timezone is aware).\n",
    "*   `%z`: UTC offset in the form ¬±HHMM[SS[.ffffff]] (e.g., +0000, -0400)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatted (YYYY-MM-DD HH:MM:SS): 2025-04-20 16:11:53\n",
      "Formatted (Verbose): Sunday, April 20, 2025 - 04:11 PM\n",
      "\n",
      "Parsed '2023-10-26 15:45:30' using '%Y-%m-%d %H:%M:%S': 2023-10-26 15:45:30\n",
      "Parsed object type: <class 'datetime.datetime'>\n",
      "Parsed 'Thu, 26 Oct 2023' using '%a, %d %b %Y': 2023-10-26 00:00:00\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "\n",
    "# --- Formatting (datetime to string) --- \n",
    "formatted_str1 = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(f\"Formatted (YYYY-MM-DD HH:MM:SS): {formatted_str1}\")\n",
    "\n",
    "formatted_str2 = now.strftime(\"%A, %B %d, %Y - %I:%M %p\") # More verbose\n",
    "print(f\"Formatted (Verbose): {formatted_str2}\")\n",
    "\n",
    "# --- Parsing (string to datetime) --- \n",
    "date_string1 = \"2023-10-26 15:45:30\"\n",
    "format_code1 = \"%Y-%m-%d %H:%M:%S\"\n",
    "try:\n",
    "    parsed_dt1 = datetime.strptime(date_string1, format_code1)\n",
    "    print(f\"\\nParsed '{date_string1}' using '{format_code1}': {parsed_dt1}\")\n",
    "    print(f\"Parsed object type: {type(parsed_dt1)}\")\n",
    "except ValueError as e:\n",
    "    print(f\"Error parsing '{date_string1}': {e}\")\n",
    "\n",
    "date_string2 = \"Thu, 26 Oct 2023\"\n",
    "format_code2 = \"%a, %d %b %Y\"\n",
    "try:\n",
    "    parsed_dt2 = datetime.strptime(date_string2, format_code2)\n",
    "    # Note: time part defaults to 00:00:00 when not in format string\n",
    "    print(f\"Parsed '{date_string2}' using '{format_code2}': {parsed_dt2}\") \n",
    "except ValueError as e:\n",
    "    print(f\"Error parsing '{date_string2}': {e}\")\n",
    "\n",
    "# Pitfall: Ambiguous formats or incorrect format codes will raise ValueError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 ISO 8601 Format (Modern Standard)\n",
    "\n",
    "ISO 8601 is the international standard format for representing dates and times (e.g., `2023-10-26T15:50:00.123456+00:00`). Python has built-in support:\n",
    "*   `datetime.isoformat()`: Converts `datetime` object to ISO 8601 string.\n",
    "*   `datetime.fromisoformat(date_string)`: Parses an ISO 8601 string back into a `datetime` object (handles timezone offsets automatically!).\n",
    "\n",
    "**Best Practice:** Use ISO 8601 for data interchange (APIs, file storage) whenever possible. It's unambiguous and machine-friendly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISO 8601 (UTC): 2025-04-20T10:41:53.115766+00:00\n",
      "ISO 8601 (Offset): 2025-04-20T05:41:53.115816-05:00\n",
      "\n",
      "Parsed ISO (UTC): 2023-10-26 10:30:00+00:00, Timezone: UTC\n",
      "Parsed ISO (Offset): 2023-10-26 05:30:00-05:00, Timezone: UTC-05:00\n",
      "Parsed ISO (Naive): 2023-10-26 12:00:00, Timezone: None\n",
      "Do UTC and Offset strings represent the same time? True\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timezone, timedelta\n",
    "\n",
    "now_utc_aware = datetime.now(timezone.utc)\n",
    "now_offset_aware = datetime.now(timezone(timedelta(hours=-5))) # Example timezone\n",
    "\n",
    "# --- Formatting to ISO 8601 --- \n",
    "iso_utc = now_utc_aware.isoformat()\n",
    "iso_offset = now_offset_aware.isoformat()\n",
    "print(f\"ISO 8601 (UTC): {iso_utc}\")\n",
    "print(f\"ISO 8601 (Offset): {iso_offset}\")\n",
    "\n",
    "# --- Parsing from ISO 8601 --- \n",
    "iso_string_utc = \"2023-10-26T10:30:00+00:00\"\n",
    "iso_string_offset = \"2023-10-26T05:30:00-05:00\"\n",
    "iso_string_naive = \"2023-10-26T12:00:00\" # Naive (no tz info)\n",
    "\n",
    "parsed_iso_utc = datetime.fromisoformat(iso_string_utc)\n",
    "parsed_iso_offset = datetime.fromisoformat(iso_string_offset)\n",
    "parsed_iso_naive = datetime.fromisoformat(iso_string_naive)\n",
    "\n",
    "print(f\"\\nParsed ISO (UTC): {parsed_iso_utc}, Timezone: {parsed_iso_utc.tzinfo}\")\n",
    "print(f\"Parsed ISO (Offset): {parsed_iso_offset}, Timezone: {parsed_iso_offset.tzinfo}\")\n",
    "print(f\"Parsed ISO (Naive): {parsed_iso_naive}, Timezone: {parsed_iso_naive.tzinfo}\")\n",
    "\n",
    "# Verify they represent the same point in time (if aware)\n",
    "print(f\"Do UTC and Offset strings represent the same time? {parsed_iso_utc == parsed_iso_offset}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7 Time Zones (`zoneinfo` - Python 3.9+)\n",
    "\n",
    "Handling time zones correctly, especially with Daylight Saving Time (DST), is complex.\n",
    "*   **Legacy:** `pytz` was the standard third-party library.\n",
    "*   **Modern (Python 3.9+):** The `zoneinfo` module provides access to the IANA Time Zone Database included with Python.\n",
    "\n",
    "**Best Practice:** Use `zoneinfo` if your Python version supports it. Always work with **aware** datetime objects, preferably storing and calculating internally in **UTC** and converting to local time zones only for display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive datetime assumed to be in London: 2023-11-01 10:00:00+00:00\n",
      "Current time in New York: 2025-04-20 06:41:53.134106-04:00\n",
      "\n",
      "Current time (UTC): 2025-04-20 10:41:53.134545+00:00\n",
      "Converted to London: 2025-04-20 11:41:53.134545+01:00\n",
      "Converted to New York: 2025-04-20 06:41:53.134545-04:00\n",
      "Converted to Tokyo: 2025-04-20 19:41:53.134545+09:00\n",
      "\n",
      "Time just before NY DST start: 2024-03-10 01:59:59-05:00\n",
      "Time just after NY DST start:  2024-03-10 02:00:00-05:00\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "# zoneinfo requires Python 3.9+ and the tzdata package on some systems\n",
    "# If running on older Python or tzdata not installed, this block will fail.\n",
    "# On Linux: sudo apt install tzdata\n",
    "# On Windows/macOS: pip install tzdata\n",
    "try:\n",
    "    from zoneinfo import ZoneInfo\n",
    "    ZONEINFO_AVAILABLE = True\n",
    "except ImportError:\n",
    "    ZONEINFO_AVAILABLE = False\n",
    "    print(\"zoneinfo module not available (requires Python 3.9+ and potentially 'tzdata' package). Skipping timezone examples.\")\n",
    "\n",
    "if ZONEINFO_AVAILABLE:\n",
    "    # --- Create aware datetime objects in specific time zones ---\n",
    "    dt_naive = datetime(2023, 11, 1, 10, 0, 0) # A naive datetime\n",
    "    \n",
    "    tz_london = ZoneInfo(\"Europe/London\")\n",
    "    tz_newyork = ZoneInfo(\"America/New_York\")\n",
    "    tz_tokyo = ZoneInfo(\"Asia/Tokyo\")\n",
    "    \n",
    "    # Make a naive datetime aware by assuming it *is* in a specific timezone\n",
    "    dt_london = dt_naive.replace(tzinfo=tz_london)\n",
    "    print(f\"Naive datetime assumed to be in London: {dt_london}\")\n",
    "    \n",
    "    # Get current time in a specific timezone\n",
    "    now_newyork = datetime.now(tz_newyork)\n",
    "    print(f\"Current time in New York: {now_newyork}\")\n",
    "\n",
    "    # --- Convert between time zones --- \n",
    "    # Start with an aware object (best practice: start from UTC)\n",
    "    utc_now = datetime.now(ZoneInfo(\"UTC\"))\n",
    "    print(f\"\\nCurrent time (UTC): {utc_now}\")\n",
    "    \n",
    "    london_time = utc_now.astimezone(tz_london)\n",
    "    newyork_time = utc_now.astimezone(tz_newyork)\n",
    "    tokyo_time = utc_now.astimezone(tz_tokyo)\n",
    "    \n",
    "    print(f\"Converted to London: {london_time}\")\n",
    "    print(f\"Converted to New York: {newyork_time}\")\n",
    "    print(f\"Converted to Tokyo: {tokyo_time}\")\n",
    "    \n",
    "    # --- DST Handling --- \n",
    "    # zoneinfo handles DST transitions automatically\n",
    "    # Example: DST change in New York (usually March)\n",
    "    dst_start_naive = datetime(2024, 3, 10, 1, 59, 59)\n",
    "    dst_start_aware = dst_start_naive.replace(tzinfo=tz_newyork)\n",
    "    dst_after = dst_start_aware + timedelta(seconds=1)\n",
    "    print(f\"\\nTime just before NY DST start: {dst_start_aware}\")\n",
    "    print(f\"Time just after NY DST start:  {dst_after}\") # Note the jump to 3 AM\n",
    "\n",
    "    # Ambiguous/Non-existent times during DST changes require careful handling\n",
    "    # naive_dt_in_gap = datetime(2024, 3, 10, 2, 30, 0)\n",
    "    # try:\n",
    "    #    aware_dt = naive_dt_in_gap.replace(tzinfo=tz_newyork) # Raises NonExistentTimeError\n",
    "    # except Exception as e:\n",
    "    #    print(f\"Error handling non-existent time: {e}\")\n",
    "    \n",
    "    # Use fold=1 during DST fall-back to specify the second occurrence of an hour\n",
    "    # naive_dt_ambiguous = datetime(2024, 11, 3, 1, 30, 0)\n",
    "    # aware_dt_first = naive_dt_ambiguous.replace(tzinfo=tz_newyork, fold=0)\n",
    "    # aware_dt_second = naive_dt_ambiguous.replace(tzinfo=tz_newyork, fold=1)\n",
    "    # print(f\"Ambiguous time (first hour): {aware_dt_first}\")\n",
    "    # print(f\"Ambiguous time (second hour): {aware_dt_second}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.8 `datetime` Best Practices & Pitfalls\n",
    "\n",
    "**Best Practices:**\n",
    "*   **Be Timezone Aware:** Store and perform calculations using timezone-aware `datetime` objects, preferably in UTC.\n",
    "*   **Use `zoneinfo` (Python 3.9+):** Prefer `zoneinfo` over `pytz` for modern timezone handling.\n",
    "*   **Use ISO 8601:** Use `isoformat()` and `fromisoformat()` for reliable data exchange.\n",
    "*   **Explicit is Better:** Be explicit about whether a `datetime` is naive or aware, and which timezone it represents.\n",
    "*   **Careful Arithmetic:** Understand that adding `timedelta` to a naive `datetime` yields a naive `datetime`.\n",
    "\n",
    "**Pitfalls:**\n",
    "*   **Naive vs. Aware Confusion:** Mixing naive and aware objects in comparisons or calculations often leads to `TypeError` or incorrect results.\n",
    "*   **DST Ambiguity:** Incorrectly handling the hour that repeats or is skipped during DST transitions.\n",
    "*   **`utcnow()` is Naive:** Using the legacy `utcnow()` thinking it's aware.\n",
    "*   **Parsing Ambiguity:** Relying on `strptime` with potentially ambiguous formats without strict validation.\n",
    "*   **Leap Seconds:** Standard `datetime` does not handle leap seconds (most applications don't need to, but be aware if you work in specialized fields)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.9 `datetime` Interview Questions\n",
    "\n",
    "1.  What's the difference between a naive and an aware datetime object?\n",
    "2.  How do you get the current time in UTC as an aware object?\n",
    "3.  How do you convert a string like \"2023-10-26\" into a date object?\n",
    "4.  How do you format a datetime object into a string like \"October 26, 2023\"?\n",
    "5.  What is a `timedelta` object used for? Give an example.\n",
    "6.  How would you represent a specific timezone like \"Europe/Berlin\"?\n",
    "7.  How do you convert a datetime object from one timezone to another?\n",
    "8.  What is ISO 8601 format and why is it useful?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. `math`: Mathematical Functions\n",
    "\n",
    "**Introduction:** Provides access to standard mathematical functions beyond the basic arithmetic operators.\n",
    "\n",
    "**Real-world Use Cases:**\n",
    "*   **Scientific & Engineering:** Trigonometry, logarithms, exponentiation.\n",
    "*   **Graphics:** Calculating distances, angles, transformations.\n",
    "*   **Statistics:** Square roots, factorials (though `statistics` module is more specialized).\n",
    "*   **Financial Modeling:** Exponential growth, powers.\n",
    "\n",
    "**Analogy: The Scientific Calculator**\n",
    "The `math` module is like Python's built-in scientific calculator, offering functions found on such devices (sin, cos, log, sqrt, etc.) and important mathematical constants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Common Functions and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pi (œÄ): 3.141592653589793\n",
      "Euler's number (e): 2.718281828459045\n",
      "Infinity (float): inf\n",
      "Not a Number (float): nan\n",
      "\n",
      "--- Rounding & Representation ---\n",
      "Ceiling of 4.7: 5\n",
      "Floor of 4.7: 4\n",
      "Ceiling of -4.2: -4\n",
      "Floor of -4.2: -5\n",
      "Absolute value of -4.2: 4.2\n",
      "Truncated value of 4.7: 4\n",
      "Factorial of 5: 120\n",
      "Is 10 close to 10.0000001? False\n",
      "Is 10 close to 10.001? False\n",
      "Is 10 close to 10.001 (tighter tolerance)? False\n",
      "Is inf finite? False\n",
      "Is nan NaN? True\n",
      "Greatest Common Divisor (GCD) of 48 and 180: 12\n",
      "Least Common Multiple (LCM) of 12 and 18: 36\n",
      "\n",
      "--- Power & Logarithms ---\n",
      "Square root of 16: 4.0\n",
      "2 to the power of 10: 1024.0\n",
      "e to the power of 3: 20.085536923187668\n",
      "Natural logarithm (base e) of 100: 4.605170185988092\n",
      "Log base 10 of 1000: 3.0\n",
      "Log base 2 of 1024: 10.0\n",
      "\n",
      "--- Trigonometry ---\n",
      "Sine of pi/4 radians: 0.7071067811865475\n",
      "Cosine of pi/4 radians: 0.7071067811865476\n",
      "Tangent of pi/4 radians: 0.9999999999999999\n",
      "60 degrees in radians: 1.0471975511965976\n",
      "pi/3 radians in degrees: 59.99999999999999\n",
      "\n",
      "--- Combinatorics (Py 3.8+) ---\n",
      "Combinations (5 choose 2): 10\n",
      "Permutations (5 permute 3): 60\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# --- Constants --- \n",
    "print(f\"Pi (œÄ): {math.pi}\")\n",
    "print(f\"Euler's number (e): {math.e}\")\n",
    "print(f\"Infinity (float): {math.inf}\")\n",
    "print(f\"Not a Number (float): {math.nan}\")\n",
    "\n",
    "# --- Number-theoretic and representation functions --- \n",
    "print(f\"\\n--- Rounding & Representation ---\")\n",
    "x = 4.7\n",
    "y = -4.2\n",
    "print(f\"Ceiling of {x}: {math.ceil(x)}\") # Smallest integer >= x\n",
    "print(f\"Floor of {x}: {math.floor(x)}\") # Largest integer <= x\n",
    "print(f\"Ceiling of {y}: {math.ceil(y)}\")\n",
    "print(f\"Floor of {y}: {math.floor(y)}\")\n",
    "print(f\"Absolute value of {y}: {math.fabs(y)}\")\n",
    "print(f\"Truncated value of {x}: {math.trunc(x)}\") # Remove fractional part\n",
    "print(f\"Factorial of 5: {math.factorial(5)}\") # 5*4*3*2*1\n",
    "print(f\"Is 10 close to 10.0000001? {math.isclose(10, 10.0000001)}\")\n",
    "print(f\"Is 10 close to 10.001? {math.isclose(10, 10.001)}\")\n",
    "print(f\"Is 10 close to 10.001 (tighter tolerance)? {math.isclose(10, 10.001, abs_tol=0.0001)}\")\n",
    "print(f\"Is {math.inf} finite? {math.isfinite(math.inf)}\")\n",
    "print(f\"Is {math.nan} NaN? {math.isnan(math.nan)}\")\n",
    "print(f\"Greatest Common Divisor (GCD) of 48 and 180: {math.gcd(48, 180)}\")\n",
    "# lcm available in Python 3.9+\n",
    "if hasattr(math, 'lcm'):\n",
    "    print(f\"Least Common Multiple (LCM) of 12 and 18: {math.lcm(12, 18)}\")\n",
    "\n",
    "# --- Power and logarithmic functions --- \n",
    "print(f\"\\n--- Power & Logarithms ---\")\n",
    "print(f\"Square root of 16: {math.sqrt(16)}\")\n",
    "print(f\"2 to the power of 10: {math.pow(2, 10)}\")\n",
    "print(f\"e to the power of 3: {math.exp(3)}\")\n",
    "print(f\"Natural logarithm (base e) of 100: {math.log(100)}\")\n",
    "print(f\"Log base 10 of 1000: {math.log10(1000)}\")\n",
    "print(f\"Log base 2 of 1024: {math.log2(1024)}\")\n",
    "\n",
    "# --- Trigonometric functions --- \n",
    "# Angles are typically in radians\n",
    "print(f\"\\n--- Trigonometry ---\")\n",
    "angle_rad = math.pi / 4 # 45 degrees in radians\n",
    "print(f\"Sine of pi/4 radians: {math.sin(angle_rad)}\")\n",
    "print(f\"Cosine of pi/4 radians: {math.cos(angle_rad)}\")\n",
    "print(f\"Tangent of pi/4 radians: {math.tan(angle_rad)}\")\n",
    "\n",
    "angle_deg = 60\n",
    "print(f\"{angle_deg} degrees in radians: {math.radians(angle_deg)}\")\n",
    "print(f\"pi/3 radians in degrees: {math.degrees(math.pi/3)}\")\n",
    "\n",
    "# --- Combinatorics (Python 3.8+) --- \n",
    "if hasattr(math, 'comb'):\n",
    "    print(f\"\\n--- Combinatorics (Py 3.8+) ---\")\n",
    "    # How many ways to choose 2 items from 5 (order doesn't matter)\n",
    "    print(f\"Combinations (5 choose 2): {math.comb(5, 2)}\") \n",
    "    # How many ways to arrange 3 items from 5 (order matters)\n",
    "    print(f\"Permutations (5 permute 3): {math.perm(5, 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 `cmath` for Complex Numbers\n",
    "\n",
    "If you need to work with complex numbers (numbers with a real and imaginary part), use the `cmath` module, which provides complex-aware versions of many `math` functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex number z: (3+4j)\n",
      "Real part: 3.0\n",
      "Imaginary part: 4.0\n",
      "math.sqrt(-1) error: math domain error\n",
      "cmath.sqrt(-1): 1j\n",
      "Phase of (3+4j): 0.9272952180016122 radians\n",
      "Magnitude (abs) of (3+4j): 5.0\n"
     ]
    }
   ],
   "source": [
    "import cmath\n",
    "\n",
    "z = 3 + 4j # Complex number\n",
    "print(f\"Complex number z: {z}\")\n",
    "print(f\"Real part: {z.real}\")\n",
    "print(f\"Imaginary part: {z.imag}\")\n",
    "\n",
    "# Note: math.sqrt() would raise ValueError for negative numbers\n",
    "try:\n",
    "    root_neg_one_math = math.sqrt(-1)\n",
    "except ValueError as e:\n",
    "    print(f\"math.sqrt(-1) error: {e}\")\n",
    "\n",
    "# cmath.sqrt() handles complex results\n",
    "root_neg_one_cmath = cmath.sqrt(-1)\n",
    "print(f\"cmath.sqrt(-1): {root_neg_one_cmath}\")\n",
    "\n",
    "# Phase (angle) and magnitude (polar coordinates)\n",
    "print(f\"Phase of {z}: {cmath.phase(z)} radians\")\n",
    "print(f\"Magnitude (abs) of {z}: {abs(z)}\") # abs() works for complex too"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 `math` Best Practices & Pitfalls\n",
    "\n",
    "**Best Practices:**\n",
    "*   **Use `math.isclose()` for Float Comparisons:** Avoid direct equality checks (`==`) with floats due to potential precision issues. Use `math.isclose()` with appropriate tolerances.\n",
    "*   **Understand Radians vs. Degrees:** Trigonometric functions in `math` use radians. Convert using `math.radians()` and `math.degrees()` if needed.\n",
    "*   **Check Domain:** Be aware of the valid input domain for functions (e.g., `math.sqrt()` requires non-negative input, `math.log()` requires positive input).\n",
    "\n",
    "**Pitfalls:**\n",
    "*   **Floating-Point Inaccuracy:** Standard floats have limited precision. Don't expect exact results for all calculations (e.g., `0.1 + 0.2` is not exactly `0.3`). For exact decimal arithmetic, use the `decimal` module.\n",
    "*   **Domain Errors:** Passing invalid input to functions (e.g., `math.sqrt(-1)`, `math.log(0)`) raises `ValueError`.\n",
    "*   **Integer Overflow (Less Common in Python):** Python integers have arbitrary precision, but operations involving massive numbers can consume significant memory/time.\n",
    "*   **Confusion with NumPy:** NumPy provides its own, often faster, array-oriented mathematical functions that operate element-wise on NumPy arrays. Don't mix them up with standard `math` functions if you're not using NumPy arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 `math` Interview Questions\n",
    "\n",
    "1.  How should you compare two floating-point numbers for equality in Python?\n",
    "2.  What is the difference between `math.ceil()` and `math.floor()`?\n",
    "3.  What units do Python's trigonometric functions (like `math.sin`) expect for angles?\n",
    "4.  What does `math.sqrt(-1)` return? What module should you use if you need the complex result?\n",
    "5.  Name two mathematical constants available in the `math` module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. `re`: Regular Expressions\n",
    "\n",
    "**Introduction:** Regular expressions (regex) are sequences of characters that define a search pattern. They are incredibly powerful for finding, extracting, and manipulating text based on complex patterns.\n",
    "\n",
    "**Real-world Use Cases:**\n",
    "*   **Input Validation:** Checking if strings match formats like email addresses, URLs, phone numbers, zip codes.\n",
    "*   **Data Scraping:** Extracting specific information (e.g., prices, dates) from web pages or text documents.\n",
    "*   **Log File Analysis:** Finding specific error messages, IP addresses, or timestamps in log files.\n",
    "*   **Search and Replace:** Performing complex substitutions in text.\n",
    "*   **Parsing:** Breaking down structured text into components.\n",
    "\n",
    "**Analogy: The Expert Pattern Finder**\n",
    "Imagine you have a massive library of books (text data). Regular expressions are like giving instructions to an expert librarian who can instantly find:\n",
    "*   All sentences starting with \"To be\" (`^To be.*`).\n",
    "*   All occurrences of phone numbers in a specific format (`\\d{3}-\\d{3}-\\d{4}`).\n",
    "*   All email addresses (`[\\w.-]+@[\\w.-]+\\.\\w+`).\n",
    "*   Replacing all occurrences of \"color\" with \"colour\" (`re.sub('color', 'colour', text)`).\n",
    "\n",
    "The power lies in defining precise *patterns*, not just literal strings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Core Functions\n",
    "\n",
    "*   `re.search(pattern, string, flags=0)`: Scans through `string` looking for the *first* location where `pattern` produces a match. Returns a match object if found, else `None`.\n",
    "*   `re.match(pattern, string, flags=0)`: Tries to match `pattern` only at the *beginning* of the `string`. Returns a match object if found, else `None`.\n",
    "*   `re.findall(pattern, string, flags=0)`: Finds *all* non-overlapping matches of `pattern` in `string` and returns them as a list of strings (or tuples if the pattern contains capturing groups).\n",
    "*   `re.finditer(pattern, string, flags=0)`: Finds all non-overlapping matches and returns an *iterator* yielding match objects. More memory-efficient than `findall` for many matches.\n",
    "*   `re.sub(pattern, repl, string, count=0, flags=0)`: Replaces occurrences of `pattern` in `string` with `repl`. `repl` can be a string (with backreferences like `\\1`, `\\g<name>`) or a function.\n",
    "*   `re.split(pattern, string, maxsplit=0, flags=0)`: Splits `string` by occurrences of `pattern`.\n",
    "*   `re.compile(pattern, flags=0)`: **Compiles** a regular expression pattern into a regex object. This is **highly recommended for performance** if you use the same pattern multiple times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Basic Syntax and Metacharacters\n",
    "\n",
    "**Recommendation:** Use **raw strings** (`r\"...\"`) for regex patterns to avoid issues with backslashes being interpreted by Python before the regex engine sees them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 'fox' at index 16-19\n",
      "\n",
      "--- Regex Examples ---\n",
      "Found phone number: 123-456-7890\n",
      "Found words starting with q/l: ['quick', 'lazy']\n",
      "Found email: test.user@example.com\n",
      "Match 'The' at start? Yes\n",
      "Match 'quick' at start? No\n",
      "Finding all words (using finditer):\n",
      "  Word 1: The at index 0\n",
      "  Word 2: quick at index 4\n",
      "  Word 3: brown at index 10\n",
      "  Word 4: fox at index 16\n",
      "  Word 5: jumps at index 20\n",
      "  Word 6: over at index 26\n",
      "  Word 7: the at index 31\n",
      "  Word 8: lazy at index 35\n",
      "  Word 9: dog at index 40\n",
      "  Word 10: Phone at index 45\n",
      "  Word 11: 123 at index 52\n",
      "  Word 12: 456 at index 56\n",
      "  Word 13: 7890 at index 60\n",
      "  Word 14: Email at index 66\n",
      "  Word 15: test at index 73\n",
      "  Word 16: user at index 78\n",
      "  Word 17: example at index 83\n",
      "  Word 18: com at index 91\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"The quick brown fox jumps over the lazy dog. Phone: 123-456-7890. Email: test.user@example.com.\"\n",
    "\n",
    "# --- Simple Literal Match --- \n",
    "pattern_literal = r\"fox\"\n",
    "match_literal = re.search(pattern_literal, text)\n",
    "if match_literal:\n",
    "    print(f\"Found '{match_literal.group(0)}' at index {match_literal.start()}-{match_literal.end()}\")\n",
    "\n",
    "# --- Metacharacters --- \n",
    "# '.' - Any character (except newline)\n",
    "# '^' - Start of string (or line in MULTILINE mode)\n",
    "# '$' - End of string (or line in MULTILINE mode)\n",
    "# '*' - 0 or more occurrences of the preceding character/group\n",
    "# '+' - 1 or more occurrences\n",
    "# '?' - 0 or 1 occurrence\n",
    "# '{}' - Specific number of occurrences (e.g., {3}, {2,4}, {5,})\n",
    "# '[]' - Character set (e.g., [aeiou], [a-zA-Z0-9])\n",
    "# '|' - OR operator (e.g., fox|dog)\n",
    "# '()' - Capturing group\n",
    "# '\\' - Escape special characters (e.g., \\., \\*, \\?)\n",
    "\n",
    "# --- Character Classes --- \n",
    "# '\\d' - Digit (0-9)\n",
    "# '\\D' - Non-digit\n",
    "# '\\s' - Whitespace (space, tab, newline, etc.)\n",
    "# '\\S' - Non-whitespace\n",
    "# '\\w' - Word character (letters, numbers, underscore)\n",
    "# '\\W' - Non-word character\n",
    "\n",
    "# --- Examples --- \n",
    "print(\"\\n--- Regex Examples ---\")\n",
    "\n",
    "# Find a phone number (North American format)\n",
    "pattern_phone = r\"\\d{3}-\\d{3}-\\d{4}\" \n",
    "match_phone = re.search(pattern_phone, text)\n",
    "if match_phone:\n",
    "    print(f\"Found phone number: {match_phone.group(0)}\")\n",
    "\n",
    "# Find all words starting with 'q' or 'l'\n",
    "pattern_words = r\"\\b[ql]\\w*\\b\" # \\b is word boundary\n",
    "matches_words = re.findall(pattern_words, text, re.IGNORECASE) # Ignore case flag\n",
    "print(f\"Found words starting with q/l: {matches_words}\")\n",
    "\n",
    "# Find email address\n",
    "pattern_email = r\"[\\w\\.-]+@[\\w\\.-]+\\.\\w+\" # Simplified email pattern\n",
    "match_email = re.search(pattern_email, text)\n",
    "if match_email:\n",
    "    print(f\"Found email: {match_email.group(0)}\")\n",
    "\n",
    "# Use match() - only matches at the beginning\n",
    "pattern_start = r\"The\"\n",
    "match_start = re.match(pattern_start, text)\n",
    "match_fail = re.match(r\"quick\", text) # Won't match\n",
    "print(f\"Match 'The' at start? {'Yes' if match_start else 'No'}\")\n",
    "print(f\"Match 'quick' at start? {'Yes' if match_fail else 'No'}\")\n",
    "\n",
    "# Use finditer() - iterating over matches\n",
    "print(\"Finding all words (using finditer):\")\n",
    "pattern_all_words = r\"\\b\\w+\\b\"\n",
    "for i, match in enumerate(re.finditer(pattern_all_words, text)):\n",
    "    print(f\"  Word {i+1}: {match.group(0)} at index {match.start()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Groups and Capturing\n",
    "\n",
    "Parentheses `()` create capturing groups, allowing you to extract specific parts of the matched text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Simple Group Capturing ---\n",
      "Full match (group 0): 2023-10-26 16:30:15 ERROR [UserThread] Failed login attempt for user 'admin' from 192.168.1.100\n",
      "Timestamp (group 1): 2023-10-26 16:30:15\n",
      "Level (group 2): ERROR\n",
      "User (group 3): admin\n",
      "IP Address (group 4): 192.168.1.100\n",
      "All groups as tuple: ('2023-10-26 16:30:15', 'ERROR', 'admin', '192.168.1.100')\n",
      "\n",
      "--- Named Group Capturing ---\n",
      "Timestamp: 2023-10-26 16:30:15\n",
      "Level: ERROR\n",
      "User: admin\n",
      "IP Address: 192.168.1.100\n",
      "All groups as dict: {'timestamp': '2023-10-26 16:30:15', 'level': 'ERROR', 'user': 'admin', 'ip': '192.168.1.100'}\n",
      "\n",
      "--- Non-Capturing Group (findall) ---\n",
      "Found pairs (Order ID, Item ID): [('123', '45'), ('456', '78')]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "log_line = \"2023-10-26 16:30:15 ERROR [UserThread] Failed login attempt for user 'admin' from 192.168.1.100\"\n",
    "\n",
    "# Pattern to extract timestamp, level, user, and IP\n",
    "# Using capturing groups ()\n",
    "pattern_log_simple = r\"(\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2})\\s+(\\w+).*user '(\\w+)'.*from (\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3})\"\n",
    "\n",
    "match_log_simple = re.search(pattern_log_simple, log_line)\n",
    "\n",
    "if match_log_simple:\n",
    "    print(\"--- Simple Group Capturing ---\")\n",
    "    print(f\"Full match (group 0): {match_log_simple.group(0)}\")\n",
    "    print(f\"Timestamp (group 1): {match_log_simple.group(1)}\")\n",
    "    print(f\"Level (group 2): {match_log_simple.group(2)}\")\n",
    "    print(f\"User (group 3): {match_log_simple.group(3)}\")\n",
    "    print(f\"IP Address (group 4): {match_log_simple.group(4)}\")\n",
    "    print(f\"All groups as tuple: {match_log_simple.groups()}\")\n",
    "\n",
    "# Using Named Groups (?P<name>...)\n",
    "pattern_log_named = r\"(?P<timestamp>\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2})\\s+(?P<level>\\w+).*user '(?P<user>\\w+)'.*from (?P<ip>\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3})\"\n",
    "match_log_named = re.search(pattern_log_named, log_line)\n",
    "\n",
    "if match_log_named:\n",
    "    print(\"\\n--- Named Group Capturing ---\")\n",
    "    print(f\"Timestamp: {match_log_named.group('timestamp')}\")\n",
    "    print(f\"Level: {match_log_named.group('level')}\")\n",
    "    print(f\"User: {match_log_named.group('user')}\")\n",
    "    print(f\"IP Address: {match_log_named.group('ip')}\")\n",
    "    print(f\"All groups as dict: {match_log_named.groupdict()}\")\n",
    "\n",
    "# Non-capturing group (?:...)\n",
    "text_nums = \"Order 123, Item 45; Order 456, Item 78\"\n",
    "pattern_non_capture = r\"Order (\\d+), (?:Item|Product) (\\d+)\" # Match 'Item' or 'Product' but don't capture it\n",
    "matches_non_capture = re.findall(pattern_non_capture, text_nums)\n",
    "print(f\"\\n--- Non-Capturing Group (findall) ---\")\n",
    "print(f\"Found pairs (Order ID, Item ID): {matches_non_capture}\") # Only captures the digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Substitution (`re.sub`)\n",
    "\n",
    "Powerful replacement using patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Redacted text: Contact us at support@[REDACTED] or sales-info@[REDACTED] for details.\n",
      "Converted temperatures: Temperature is 0.0C today, yesterday was 23.9C.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"Contact us at support@example.com or sales-info@example.co.uk for details.\"\n",
    "\n",
    "# Replace all email domains with '[REDACTED]'\n",
    "# Use backreference \\1 to keep the username part\n",
    "pattern_email_sub = r\"([\\w\\.-]+)@([\\w\\.-]+\\.\\w+)\"\n",
    "redacted_text = re.sub(pattern_email_sub, r\"\\1@[REDACTED]\", text)\n",
    "print(f\"Redacted text: {redacted_text}\")\n",
    "\n",
    "# Using a function for replacement (e.g., convert temperatures)\n",
    "temp_text = \"Temperature is 32F today, yesterday was 75F.\"\n",
    "def fahrenheit_to_celsius(match_obj):\n",
    "    fahrenheit = int(match_obj.group(1)) # Group 1 captures the digits\n",
    "    celsius = (fahrenheit - 32) * 5 / 9\n",
    "    return f\"{celsius:.1f}C\" # Return the replacement string\n",
    "\n",
    "pattern_temp = r\"(\\d+)F\\b\" # Capture digits before 'F'\n",
    "celsius_text = re.sub(pattern_temp, fahrenheit_to_celsius, temp_text)\n",
    "print(f\"Converted temperatures: {celsius_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Compiled Expressions (`re.compile`)\n",
    "\n",
    "**Performance Best Practice:** If you use a regex pattern multiple times (e.g., inside a loop), compile it first for significant speed improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time without compiling (100 runs): 0.115639 seconds\n",
      "Time with compiling (100 runs):    0.075046 seconds\n",
      "Compiled is faster by factor: 1.54x (approx)\n",
      "Compiled regex match successful.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import timeit\n",
    "\n",
    "emails = [f\"user{i}@test.com\" for i in range(1000)] + [\"invalid-email\"] * 10\n",
    "pattern_email = r\"^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$\" # Stricter pattern with ^ $\n",
    "\n",
    "# --- Without compiling --- \n",
    "def validate_emails_no_compile(email_list):\n",
    "    valid_count = 0\n",
    "    for email in email_list:\n",
    "        if re.match(pattern_email, email):\n",
    "            valid_count += 1\n",
    "    return valid_count\n",
    "\n",
    "# --- With compiling --- \n",
    "COMPILED_EMAIL_REGEX = re.compile(pattern_email)\n",
    "def validate_emails_compiled(email_list):\n",
    "    valid_count = 0\n",
    "    for email in email_list:\n",
    "        if COMPILED_EMAIL_REGEX.match(email):\n",
    "            valid_count += 1\n",
    "    return valid_count\n",
    "\n",
    "# --- Timing comparison --- \n",
    "iterations = 100\n",
    "time_no_compile = timeit.timeit(lambda: validate_emails_no_compile(emails), number=iterations)\n",
    "time_compiled = timeit.timeit(lambda: validate_emails_compiled(emails), number=iterations)\n",
    "\n",
    "print(f\"Time without compiling ({iterations} runs): {time_no_compile:.6f} seconds\")\n",
    "print(f\"Time with compiling ({iterations} runs):    {time_compiled:.6f} seconds\")\n",
    "print(f\"Compiled is faster by factor: {time_no_compile / time_compiled:.2f}x (approx)\")\n",
    "\n",
    "# Also allows using methods directly on the compiled object\n",
    "match = COMPILED_EMAIL_REGEX.match(\"test@domain.com\")\n",
    "if match:\n",
    "    print(\"Compiled regex match successful.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Verbose Flag (`re.VERBOSE`)\n",
    "\n",
    "For complex patterns, use the `re.VERBOSE` flag to allow whitespace and comments within the pattern string for greatly improved readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match with complex pattern successful: True\n",
      "Match with verbose pattern successful: True\n",
      "  Date: 2023-10-27\n",
      "  Level: INFO\n",
      "  Thread: MainThread\n",
      "  Message: Application started successfully.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "pattern_complex = r\"^(\\d{4}-\\d{2}-\\d{2})\\s+([A-Z]+)\\s+\\[(.*?)\\]\\s+(.*)$\"\n",
    "\n",
    "pattern_verbose = r\"\"\"\n",
    "^                 # Start of the string/line\n",
    "(\\d{4}-\\d{2}-\\d{2}) # Capture YYYY-MM-DD date (Group 1)\n",
    "\\s+               # One or more whitespace characters\n",
    "([A-Z]+)          # Capture log level (e.g., ERROR) (Group 2)\n",
    "\\s+               # One or more whitespace characters\n",
    "\\[(.*?)\\]         # Capture thread name inside [] (non-greedy) (Group 3)\n",
    "\\s+               # One or more whitespace characters\n",
    "(.*)              # Capture the rest of the message (Group 4)\n",
    "$                 # End of the string/line\n",
    "\"\"\"\n",
    "\n",
    "log_entry = \"2023-10-27 INFO [MainThread] Application started successfully.\"\n",
    "\n",
    "match1 = re.match(pattern_complex, log_entry)\n",
    "# Use re.VERBOSE flag\n",
    "match2 = re.match(pattern_verbose, log_entry, re.VERBOSE)\n",
    "\n",
    "print(f\"Match with complex pattern successful: {match1 is not None}\")\n",
    "print(f\"Match with verbose pattern successful: {match2 is not None}\")\n",
    "if match2:\n",
    "    print(f\"  Date: {match2.group(1)}\")\n",
    "    print(f\"  Level: {match2.group(2)}\")\n",
    "    print(f\"  Thread: {match2.group(3)}\")\n",
    "    print(f\"  Message: {match2.group(4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 `re` Best Practices & Pitfalls\n",
    "\n",
    "**Best Practices:**\n",
    "*   **Use Raw Strings (`r\"...\"`):** Almost always use raw strings for regex patterns.\n",
    "*   **Compile Often-Used Patterns:** Use `re.compile()` for performance.\n",
    "*   **Be Specific:** Write patterns that are specific enough to avoid unwanted matches. Avoid overly broad patterns like `.*` where possible.\n",
    "*   **Use `re.VERBOSE`:** Make complex patterns readable with comments and whitespace.\n",
    "*   **Test Your Regex:** Use online tools (like regex101.com) or Python's interactive mode to test patterns thoroughly on sample data.\n",
    "*   **Consider Alternatives:** For simple tasks (like checking prefixes/suffixes, simple splitting), standard string methods (`.startswith()`, `.endswith()`, `.split()`, `.find()`, `.replace()`) might be clearer and faster.\n",
    "*   **Use Non-Greedy Qualifiers (`*?`, `+?`)**: When you want the *shortest* possible match for `*` or `+`.\n",
    "\n",
    "**Pitfalls:**\n",
    "*   **Forgetting Raw Strings:** Backslashes get interpreted by Python first, breaking the pattern.\n",
    "*   **Greedy Matching:** Default quantifiers (`*`, `+`) match as *much* as possible. Use non-greedy (`*?`, `+?`) or more specific patterns if needed.\n",
    "*   **Complexity:** Overly complex regexes are hard to read, debug, and maintain.\n",
    "*   **Catastrophic Backtracking (ReDoS):** Poorly written regexes (especially with nested quantifiers and alternation) can take exponential time on certain inputs, leading to Denial of Service vulnerabilities. Test patterns on edge cases.\n",
    "*   **`match()` vs `search()`:** Forgetting that `match()` only checks the beginning of the string.\n",
    "*   **Character Encoding:** Ensure the string being searched and the pattern use compatible encodings (usually less of an issue with standard Python strings, but relevant if reading bytes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8 `re` Interview Questions\n",
    "\n",
    "1.  What are regular expressions used for?\n",
    "2.  What is the difference between `re.match()` and `re.search()`?\n",
    "3.  Why should you use raw strings (`r\"...\"`) for regex patterns?\n",
    "4.  Explain the meaning of these metacharacters: `.` `*` `+` `?` `[]` `()` `^` `$` `\\b`.\n",
    "5.  How do you capture a group within a regex pattern?\n",
    "6.  What does `re.findall()` return?\n",
    "7.  When and why would you use `re.compile()`?\n",
    "8.  What is the purpose of the `re.IGNORECASE` flag?\n",
    "9.  How can you replace parts of a string using a regex pattern? (`re.sub`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. `functools`: Tools for Functions and Callables\n",
    "\n",
    "**Introduction:** This module provides higher-order functions (functions that operate on or return other functions) and tools for creating, modifying, and introspecting callable objects.\n",
    "\n",
    "**Real-world Use Cases:**\n",
    "*   **Decorators:** Modifying or enhancing function behavior (`@wraps`).\n",
    "*   **Caching/Memoization:** Speeding up expensive function calls (`@lru_cache`, `@cache`).\n",
    "*   **Partial Function Application:** Creating specialized versions of functions with some arguments pre-filled (`partial`).\n",
    "*   **Function Composition:** Combining functions (though often done manually or with other libraries).\n",
    "*   **Generic Functions:** Dispatching function calls based on argument types (`@singledispatch`).\n",
    "\n",
    "**Analogy: The Function Enhancer Kit**\n",
    "Think of `functools` as a kit containing special tools to modify and improve your existing Python functions:\n",
    "*   **`@wraps`:** A label maker that ensures when you wrap a function (like putting it in a new box - a decorator), it still retains its original name tag and instructions.\n",
    "*   **`@lru_cache` / `@cache`:** A smart sticky note pad that remembers the results of function calls for specific inputs, so you don't have to recalculate them.\n",
    "*   **`partial`:** A template maker that lets you create pre-filled versions of a function's order form (arguments).\n",
    "*   **`@singledispatch`:** A smart dispatcher that routes a task to the right specialist function based on the type of item (argument) it receives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Decorator Helper: `functools.wraps`\n",
    "\n",
    "**Problem:** When you write a decorator, the decorated function often loses its original metadata (name, docstring, etc.), which can confuse debuggers and documentation tools.\n",
    "**Solution:** Use `@functools.wraps(original_func)` inside your decorator's wrapper function to copy the essential metadata from the original function to the wrapper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Calling function decorated WITHOUT @wraps ---\n",
      "[No wraps] slow_operation_a took 0.100085 seconds\n",
      "Function name: wrapper\n",
      "Function docstring: Wrapper docstring - This hides the original!\n",
      "\n",
      "--- Calling function decorated WITH @wraps ---\n",
      "[With wraps] slow_operation_b took 0.100087 seconds\n",
      "Function name: slow_operation_b\n",
      "Function docstring: This is the original docstring for slow_operation_b.\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "import time\n",
    "\n",
    "# --- Decorator WITHOUT @wraps --- \n",
    "def timing_decorator_no_wraps(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        \"\"\"Wrapper docstring - This hides the original!\"\"\"\n",
    "        start_time = time.perf_counter()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.perf_counter()\n",
    "        print(f\"[No wraps] {func.__name__} took {end_time - start_time:.6f} seconds\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "@timing_decorator_no_wraps\n",
    "def slow_operation_a(n):\n",
    "    \"\"\"This is the original docstring for slow_operation_a.\"\"\"\n",
    "    time.sleep(n)\n",
    "    return n * n\n",
    "\n",
    "print(\"--- Calling function decorated WITHOUT @wraps ---\")\n",
    "slow_operation_a(0.1)\n",
    "print(f\"Function name: {slow_operation_a.__name__}\") # Output: wrapper\n",
    "print(f\"Function docstring: {slow_operation_a.__doc__}\") # Output: Wrapper docstring...\n",
    "\n",
    "# --- Decorator WITH @wraps --- \n",
    "def timing_decorator_with_wraps(func):\n",
    "    @functools.wraps(func) # Apply wraps to the inner wrapper\n",
    "    def wrapper(*args, **kwargs):\n",
    "        \"\"\"Wrapper docstring - not visible externally now.\"\"\"\n",
    "        start_time = time.perf_counter()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.perf_counter()\n",
    "        print(f\"[With wraps] {func.__name__} took {end_time - start_time:.6f} seconds\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "@timing_decorator_with_wraps\n",
    "def slow_operation_b(n):\n",
    "    \"\"\"This is the original docstring for slow_operation_b.\"\"\"\n",
    "    time.sleep(n)\n",
    "    return n + n\n",
    "\n",
    "print(\"\\n--- Calling function decorated WITH @wraps ---\")\n",
    "slow_operation_b(0.1)\n",
    "print(f\"Function name: {slow_operation_b.__name__}\") # Output: slow_operation_b\n",
    "print(f\"Function docstring: {slow_operation_b.__doc__}\") # Output: This is the original docstring...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3167d2c9",
   "metadata": {},
   "source": [
    "**Best Practice:** *Always* use `@functools.wraps` when writing decorators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Caching: `functools.lru_cache` and `functools.cache` (Py 3.9+)\n",
    "\n",
    "Memoization technique to automatically cache the results of function calls. If the function is called again with the same arguments, the cached result is returned instantly, avoiding re-computation.\n",
    "\n",
    "*   `@lru_cache(maxsize=128, typed=False)`: Least Recently Used cache. Stores up to `maxsize` results. When full, discards the least recently used item. `typed=True` treats arguments of different types (e.g., `3` and `3.0`) as distinct cache keys.\n",
    "*   `@cache`: (Python 3.9+) Simpler version of `lru_cache` with `maxsize=None` (cache grows indefinitely) and `typed=False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Fibonacci Calculations (n=35) ---\n",
      "Recursive Fibonacci took: 1.573020 seconds. Result: 9227465\n",
      "Cached Fibonacci took:    0.000096 seconds. Result: 9227465\n",
      "Cached Fibonacci (2nd call): 0.000040 seconds. Result: 9227465\n",
      "Cache Info: CacheInfo(hits=34, misses=36, maxsize=128, currsize=36)\n",
      "Cache Info after clear: CacheInfo(hits=0, misses=0, maxsize=128, currsize=0)\n",
      "\n",
      "--- Factorial Calculations (n=20) ---\n",
      "Cached Factorial took: 0.000047 seconds. Result: 2432902008176640000\n",
      "Cached Factorial (2nd call): 0.000041 seconds. Result: 2432902008176640000\n",
      "Cache Info: CacheInfo(hits=1, misses=21, maxsize=None, currsize=21)\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "import time\n",
    "import sys\n",
    "\n",
    "# --- Expensive Fibonacci calculation (recursive) ---\n",
    "def fibonacci_recursive(n):\n",
    "    if n < 2:\n",
    "        return n\n",
    "    return fibonacci_recursive(n-1) + fibonacci_recursive(n-2)\n",
    "\n",
    "# --- Apply LRU Cache --- \n",
    "@functools.lru_cache(maxsize=128)\n",
    "def fibonacci_cached(n):\n",
    "    # print(f\"Calculating fibonacci_cached({n})\") # Uncomment to see calls\n",
    "    if n < 2:\n",
    "        return n\n",
    "    return fibonacci_cached(n-1) + fibonacci_cached(n-2)\n",
    "\n",
    "# --- Apply Simple Cache (Python 3.9+) --- \n",
    "if sys.version_info >= (3, 9):\n",
    "    @functools.cache\n",
    "    def factorial_cached(n):\n",
    "        # print(f\"Calculating factorial_cached({n})\") # Uncomment to see calls\n",
    "        return n * factorial_cached(n-1) if n else 1\n",
    "else:\n",
    "    # Fallback for older Python using lru_cache\n",
    "    @functools.lru_cache(maxsize=None) \n",
    "    def factorial_cached(n):\n",
    "        # print(f\"Calculating factorial_cached({n}) - fallback\")\n",
    "        return n * factorial_cached(n-1) if n else 1\n",
    "\n",
    "# --- Timing Comparisons --- \n",
    "print(\"--- Fibonacci Calculations (n=35) ---\")\n",
    "start = time.perf_counter()\n",
    "result_recursive = fibonacci_recursive(35) \n",
    "end = time.perf_counter()\n",
    "print(f\"Recursive Fibonacci took: {end - start:.6f} seconds. Result: {result_recursive}\")\n",
    "\n",
    "start = time.perf_counter()\n",
    "result_cached = fibonacci_cached(35)\n",
    "end = time.perf_counter()\n",
    "print(f\"Cached Fibonacci took:    {end - start:.6f} seconds. Result: {result_cached}\")\n",
    "\n",
    "# Call again - should be near instant\n",
    "start = time.perf_counter()\n",
    "result_cached_again = fibonacci_cached(35)\n",
    "end = time.perf_counter()\n",
    "print(f\"Cached Fibonacci (2nd call): {end - start:.6f} seconds. Result: {result_cached_again}\")\n",
    "\n",
    "print(f\"Cache Info: {fibonacci_cached.cache_info()}\")\n",
    "fibonacci_cached.cache_clear() # Clear the cache if needed\n",
    "print(f\"Cache Info after clear: {fibonacci_cached.cache_info()}\")\n",
    "\n",
    "\n",
    "print(\"\\n--- Factorial Calculations (n=20) ---\")\n",
    "start = time.perf_counter()\n",
    "result_fact = factorial_cached(20)\n",
    "end = time.perf_counter()\n",
    "print(f\"Cached Factorial took: {end - start:.6f} seconds. Result: {result_fact}\")\n",
    "\n",
    "start = time.perf_counter()\n",
    "result_fact_again = factorial_cached(20)\n",
    "end = time.perf_counter()\n",
    "print(f\"Cached Factorial (2nd call): {end - start:.6f} seconds. Result: {result_fact_again}\")\n",
    "\n",
    "print(f\"Cache Info: {factorial_cached.cache_info()}\")\n",
    "\n",
    "# Note: Arguments to cached functions must be hashable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Partial Function Application: `functools.partial`\n",
    "\n",
    "Creates a new callable object with some of the arguments of the original function pre-filled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Square of 5: 25\n",
      "Cube of 5: 125\n",
      "Power of 2 to 8: 256\n",
      "\n",
      "--- Partial for Callbacks ---\n",
      "Processing event 'USER_LOGIN' with data: {'user': 'alice'}\n",
      "Success Handler: Received 'Processed {'user': 'alice'}'\n",
      "Processing event 'FILE_NOT_FOUND' with data: {'path': '/a/b/c'}\n",
      "Error Handler: Code 404, Message: 'Processed {'path': '/a/b/c'}'\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "\n",
    "def power(base, exponent):\n",
    "    \"\"\"Calculates base to the power of exponent.\"\"\"\n",
    "    return base ** exponent\n",
    "\n",
    "# Create specialized versions of the power function\n",
    "square = functools.partial(power, exponent=2)\n",
    "cube = functools.partial(power, exponent=3)\n",
    "\n",
    "# Create a version with a fixed base\n",
    "power_of_two = functools.partial(power, 2) # Fills 'base' argument\n",
    "\n",
    "print(f\"Square of 5: {square(5)}\") # Only need to provide 'base'\n",
    "print(f\"Cube of 5: {cube(5)}\")\n",
    "print(f\"Power of 2 to 8: {power_of_two(8)}\") # Only need to provide 'exponent'\n",
    "\n",
    "# --- Use Case: Callbacks --- \n",
    "def process_event(event_type, data, callback):\n",
    "    print(f\"Processing event '{event_type}' with data: {data}\")\n",
    "    # Simulate processing\n",
    "    result = f\"Processed {data}\"\n",
    "    callback(result) # Call the provided callback\n",
    "\n",
    "def handle_success(result_data):\n",
    "    print(f\"Success Handler: Received '{result_data}'\")\n",
    "\n",
    "def handle_error(error_code, message):\n",
    "    print(f\"Error Handler: Code {error_code}, Message: '{message}'\")\n",
    "\n",
    "# Create a partial function for the error handler with a specific code\n",
    "specific_error_handler = functools.partial(handle_error, 404)\n",
    "\n",
    "print(\"\\n--- Partial for Callbacks ---\")\n",
    "process_event(\"USER_LOGIN\", {\"user\": \"alice\"}, handle_success)\n",
    "process_event(\"FILE_NOT_FOUND\", {\"path\": \"/a/b/c\"}, specific_error_handler) # Only needs 'message'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Reduction: `functools.reduce`\n",
    "\n",
    "Applies a function of two arguments cumulatively to the items of a sequence, from left to right, so as to reduce the sequence to a single value. \n",
    "\n",
    "**Note:** While powerful, `reduce` can often be less readable than an explicit loop or built-in functions like `sum()` for simple cases. Use judiciously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum using reduce (lambda): 15\n",
      "Sum using reduce (operator.add): 15\n",
      "Sum using built-in sum(): 15\n",
      "Product using reduce (operator.mul): 120\n",
      "Max using reduce: 5\n",
      "Max using built-in max(): 5\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "import operator # Provides functions corresponding to operators\n",
    "\n",
    "numbers = [1, 2, 3, 4, 5]\n",
    "\n",
    "# Calculate sum using reduce\n",
    "sum_result = functools.reduce(lambda x, y: x + y, numbers)\n",
    "# Equivalent using operator module (often slightly faster/clearer)\n",
    "sum_result_op = functools.reduce(operator.add, numbers)\n",
    "# Easiest way: use built-in sum()\n",
    "sum_result_builtin = sum(numbers)\n",
    "print(f\"Sum using reduce (lambda): {sum_result}\")\n",
    "print(f\"Sum using reduce (operator.add): {sum_result_op}\")\n",
    "print(f\"Sum using built-in sum(): {sum_result_builtin}\")\n",
    "\n",
    "# Calculate product using reduce\n",
    "product_result = functools.reduce(operator.mul, numbers)\n",
    "print(f\"Product using reduce (operator.mul): {product_result}\")\n",
    "\n",
    "# Find the maximum value\n",
    "max_result = functools.reduce(lambda x, y: x if x > y else y, numbers)\n",
    "# Easiest way: use built-in max()\n",
    "max_result_builtin = max(numbers)\n",
    "print(f\"Max using reduce: {max_result}\")\n",
    "print(f\"Max using built-in max(): {max_result_builtin}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Generic Functions: `functools.singledispatch`\n",
    "\n",
    "Allows a function to have different implementations based on the type of its *first* argument. Similar to function overloading in other languages, but based on runtime types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Single Dispatch Examples ---\n",
      "(Int) Formatting integer: 1234567\n",
      "(Float) Formatting float: 9876.54321\n",
      "(List) Formatting list: [1, 'a', 3.0]\n",
      "(Default) Formatting value: a string\n",
      "(Decimal) Formatting Decimal: 1234.5600\n",
      "--- Results ---\n",
      "Integer: 1,234,567\n",
      "Float: 9876.54\n",
      "List with 3 items: [1, a, 3.0]\n",
      "a string\n",
      "Decimal: 1234.56\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "from decimal import Decimal\n",
    "\n",
    "# Define the generic function using the decorator\n",
    "@functools.singledispatch\n",
    "def format_value(arg):\n",
    "    \"\"\"Default implementation for unrecognized types.\"\"\"\n",
    "    print(f\"(Default) Formatting value: {arg}\")\n",
    "    return str(arg)\n",
    "\n",
    "# Register specific implementations for different types\n",
    "@format_value.register(int)\n",
    "def _(arg):\n",
    "    \"\"\"Implementation for integers.\"\"\"\n",
    "    print(f\"(Int) Formatting integer: {arg}\")\n",
    "    return f\"Integer: {arg:,}\" # Add comma separators\n",
    "\n",
    "@format_value.register(float)\n",
    "def _(arg):\n",
    "    \"\"\"Implementation for floats.\"\"\"\n",
    "    print(f\"(Float) Formatting float: {arg}\")\n",
    "    return f\"Float: {arg:.2f}\" # Format to 2 decimal places\n",
    "\n",
    "# Can register for complex types too\n",
    "@format_value.register(list)\n",
    "def _(arg):\n",
    "    print(f\"(List) Formatting list: {arg}\")\n",
    "    return f\"List with {len(arg)} items: [{', '.join(map(str, arg))}]\"\n",
    "\n",
    "# You can also register functions separately\n",
    "def _format_decimal(arg):\n",
    "    print(f\"(Decimal) Formatting Decimal: {arg}\")\n",
    "    return f\"Decimal: {arg.normalize()}\"\n",
    "format_value.register(Decimal, _format_decimal)\n",
    "\n",
    "# --- Calling the generic function --- \n",
    "print(\"--- Single Dispatch Examples ---\")\n",
    "formatted1 = format_value(1234567)\n",
    "formatted2 = format_value(9876.54321)\n",
    "formatted3 = format_value([1, 'a', 3.0])\n",
    "formatted4 = format_value(\"a string\") # Uses default\n",
    "formatted5 = format_value(Decimal(\"1234.5600\"))\n",
    "\n",
    "print(\"--- Results ---\")\n",
    "print(formatted1)\n",
    "print(formatted2)\n",
    "print(formatted3)\n",
    "print(formatted4)\n",
    "print(formatted5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 `functools` Best Practices & Pitfalls\n",
    "\n",
    "**Best Practices:**\n",
    "*   **`@wraps` is Essential:** Always use `@wraps` in decorators to preserve function metadata.\n",
    "*   **Choose Cache Wisely:** Use `@cache` (3.9+) for simple unbounded caching. Use `@lru_cache` if you need a size limit or typed caching.\n",
    "*   **`partial` Readability:** Use `partial` to create cleaner code when passing callbacks or specializing functions, rather than complex lambdas.\n",
    "*   **`reduce` Sparingly:** Prefer explicit loops or built-ins (`sum`, `max`, `min`, `all`, `any`) over `reduce` for common operations as they are often more readable.\n",
    "*   **`singledispatch` for Type Overloading:** Use `@singledispatch` when you need a function to behave differently based on the type of its first argument, offering an alternative to complex `if/elif/else` type checks.\n",
    "\n",
    "**Pitfalls:**\n",
    "*   **Forgetting `@wraps`:** Leads to confusing debugging and documentation issues.\n",
    "*   **`lru_cache` with Unhashable Args:** Arguments to cached functions must be hashable (e.g., lists or dicts cannot be arguments directly unless converted to tuples/frozensets).\n",
    "*   **Cache Invalidation:** Caches (`lru_cache`, `cache`) live for the lifetime of the function object. Be mindful of stale data if the underlying source the function depends on changes.\n",
    "*   **Mutable Defaults with `partial`:** If a partial function pre-fills an argument with a mutable object, that object is shared across all calls to the partial function.\n",
    "*   **Overly Complex `reduce`:** Can quickly become hard to understand compared to a simple loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7 `functools` Interview Questions\n",
    "\n",
    "1.  What problem does `functools.wraps` solve when writing decorators?\n",
    "2.  What is memoization, and how does `functools.lru_cache` help achieve it?\n",
    "3.  What are the main differences between `@lru_cache` and `@cache` (Python 3.9+)?\n",
    "4.  What does `functools.partial` do? Give a use case.\n",
    "5.  What is the purpose of `functools.reduce`? When might it be less preferred than a loop?\n",
    "6.  What problem does `functools.singledispatch` address?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Combined Challenge: Log File Analysis\n",
    "\n",
    "**Goal:** Write a script that parses a log file, extracts specific information using regex, converts timestamps, and calculates the time difference between the first and last relevant log entries.\n",
    "\n",
    "**Tasks:**\n",
    "\n",
    "1.  **Create Sample Log File (`app.log`):** Create a text file with entries like:\n",
    "    ```\n",
    "    2023-11-01 10:05:15 INFO [MainThread] Service started.\n",
    "    2023-11-01 10:05:20 DEBUG [Worker-1] Processing item 1...\n",
    "    2023-11-01 10:05:22 INFO [Worker-1] Item 1 processed successfully.\n",
    "    2023-11-01 10:06:05 WARNING [MainThread] Low disk space detected.\n",
    "    2023-11-01 10:07:10 ERROR [DBThread] Database connection failed. Retrying...\n",
    "    2023-11-01 10:07:12 INFO [DBThread] Database connection successful.\n",
    "    2023-11-01 10:08:00 INFO [MainThread] Service shutting down.\n",
    "    INVALID LOG ENTRY\n",
    "    ```\n",
    "2.  **Define Regex:** Create a compiled regular expression (`re.compile`) to capture the timestamp (YYYY-MM-DD HH:MM:SS) and the log level (e.g., INFO, ERROR) from valid log lines. Use named groups.\n",
    "3.  **Process File:**\n",
    "    *   Read the log file line by line (`pathlib` or `open` with `with`).\n",
    "    *   Use the compiled regex's `search()` method to find matches on each line.\n",
    "    *   If a line matches:\n",
    "        *   Extract the timestamp string and log level using group names.\n",
    "        *   Use `datetime.strptime()` to convert the timestamp string into a **naive** `datetime` object.\n",
    "        *   Keep track of the first and last valid timestamps encountered.\n",
    "        *   (Optional) Count occurrences of each log level.\n",
    "    *   Handle potential `IOError` and regex `AttributeError` (if search returns None).\n",
    "4.  **Calculate Duration:** If both a first and last timestamp were found, calculate the `timedelta` between them.\n",
    "5.  **Output:** Print the total number of valid log entries processed, the first timestamp, the last timestamp, and the total duration. (Optional: Print log level counts).\n",
    "6.  **(Bonus using `functools`):** If you were repeatedly parsing timestamps in the *exact same string format*, how could `@lru_cache` be applied to potentially speed up the `datetime.strptime` conversion (assuming identical timestamp strings appear multiple times)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created sample log file: app.log\n",
      "INFO: Analyzing log file: app.log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Log Analysis Results ---\n",
      "Processed 8 valid log entries.\n",
      "First Timestamp: 2023-11-01 10:05:15\n",
      "Last Timestamp:  2023-11-01 10:07:10\n",
      "Total Duration:  0:01:55 (Total Seconds: 115.00)\n",
      "\n",
      "Log Level Counts:\n",
      "  INFO: 4\n",
      "  DEBUG: 1\n",
      "  WARNING: 1\n",
      "  ERROR: 2\n"
     ]
    }
   ],
   "source": [
    "# --- Solution Space for Challenge ---\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from collections import Counter\n",
    "import functools # For bonus\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s', force=True)\n",
    "\n",
    "# 1. Create Sample Log File\n",
    "log_content = \"\"\"\n",
    "2023-11-01 10:05:15 INFO [MainThread] Service started.\n",
    "2023-11-01 10:05:20 DEBUG [Worker-1] Processing item 1...\n",
    "2023-11-01 10:05:22 INFO [Worker-1] Item 1 processed successfully.\n",
    "2023-11-01 10:06:05 WARNING [MainThread] Low disk space detected.\n",
    "2023-11-01 10:07:10 ERROR [DBThread] Database connection failed. Retrying...\n",
    "2023-11-01 10:07:12 INFO [DBThread] Database connection successful.\n",
    "2023-11-01 10:08:00 INFO [MainThread] Service shutting down.\n",
    "INVALID LOG ENTRY\n",
    "2023-11-01 10:07:10 ERROR [DBThread] Another error for testing counts.\n",
    "\"\"\"\n",
    "log_file_path = Path(\"app.log\")\n",
    "try:\n",
    "    log_file_path.write_text(log_content.strip(), encoding='utf-8')\n",
    "    logging.info(f\"Created sample log file: {log_file_path}\")\n",
    "except IOError as e:\n",
    "    logging.error(f\"Failed to write log file: {e}\")\n",
    "    # Exit if file can't be written for the test\n",
    "    exit()\n",
    "\n",
    "# 2. Define Regex\n",
    "LOG_ENTRY_PATTERN = re.compile(\n",
    "    r\"^(?P<timestamp>\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2})\\s+\"\n",
    "    r\"(?P<level>DEBUG|INFO|WARNING|ERROR|CRITICAL)\"\n",
    "    # Optional: r\"\\s+\\[(?P<thread>.*?)\\]\\s+(?P<message>.*)$\"\n",
    ")\n",
    "TIMESTAMP_FORMAT = \"%Y-%m-%d %H:%M:%S\"\n",
    "\n",
    "# Bonus: Cached strptime function\n",
    "@functools.lru_cache(maxsize=1024) # Cache up to 1024 unique timestamp strings\n",
    "def parse_timestamp_cached(ts_string, fmt):\n",
    "    # print(f\"Parsing timestamp: {ts_string}\") # Uncomment to see cache misses\n",
    "    return datetime.strptime(ts_string, fmt)\n",
    "\n",
    "def analyze_log_file(filepath: Path):\n",
    "    first_timestamp: datetime | None = None\n",
    "    last_timestamp: datetime | None = None\n",
    "    valid_entry_count = 0\n",
    "    level_counts = Counter()\n",
    "\n",
    "    logging.info(f\"Analyzing log file: {filepath}\")\n",
    "    try:\n",
    "        with filepath.open('r', encoding='utf-8') as f:\n",
    "            for line_num, line in enumerate(f, 1):\n",
    "                match = LOG_ENTRY_PATTERN.search(line)\n",
    "                if match:\n",
    "                    valid_entry_count += 1\n",
    "                    data = match.groupdict()\n",
    "                    timestamp_str = data['timestamp']\n",
    "                    level = data['level']\n",
    "                    level_counts[level] += 1\n",
    "                    \n",
    "                    try:\n",
    "                        # Use the cached version for parsing\n",
    "                        current_dt = parse_timestamp_cached(timestamp_str, TIMESTAMP_FORMAT)\n",
    "                        # Or without cache: \n",
    "                        # current_dt = datetime.strptime(timestamp_str, TIMESTAMP_FORMAT)\n",
    "                        \n",
    "                        if first_timestamp is None:\n",
    "                            first_timestamp = current_dt\n",
    "                        # Always update last_timestamp (or check if > current last)\n",
    "                        # Assuming logs are mostly chronological, just assigning is fine\n",
    "                        last_timestamp = current_dt \n",
    "                        \n",
    "                    except ValueError:\n",
    "                        logging.warning(f\"Line {line_num}: Invalid date format '{timestamp_str}' despite regex match.\")\n",
    "                # else: # Optional: Log lines that don't match the pattern\n",
    "                    # logging.debug(f\"Line {line_num}: Skipping line, no pattern match.\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"Log file not found: {filepath}\")\n",
    "        return\n",
    "    except IOError as e:\n",
    "        logging.error(f\"Error reading log file {filepath}: {e}\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        logging.exception(f\"An unexpected error occurred during analysis: {e}\")\n",
    "        return\n",
    "\n",
    "    # 4. Calculate Duration & 5. Output\n",
    "    print(\"\\n--- Log Analysis Results ---\")\n",
    "    print(f\"Processed {valid_entry_count} valid log entries.\")\n",
    "    \n",
    "    if first_timestamp and last_timestamp:\n",
    "        print(f\"First Timestamp: {first_timestamp.strftime(TIMESTAMP_FORMAT)}\")\n",
    "        print(f\"Last Timestamp:  {last_timestamp.strftime(TIMESTAMP_FORMAT)}\")\n",
    "        duration = last_timestamp - first_timestamp\n",
    "        print(f\"Total Duration:  {duration} (Total Seconds: {duration.total_seconds():.2f})\")\n",
    "    else:\n",
    "        print(\"No valid timestamps found to calculate duration.\")\n",
    "        \n",
    "    print(\"\\nLog Level Counts:\")\n",
    "    for level, count in level_counts.items():\n",
    "        print(f\"  {level}: {count}\")\n",
    "\n",
    "# Run the analysis\n",
    "analyze_log_file(log_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusion\n",
    "\n",
    "The Python Standard Library is a treasure trove of powerful tools. `datetime`, `math`, `re`, and `functools` are prime examples, providing essential building blocks for a vast range of programming tasks.\n",
    "\n",
    "*   `datetime` allows precise control over dates, times, and timezones.\n",
    "*   `math` offers fundamental mathematical operations.\n",
    "*   `re` provides sophisticated text pattern matching and manipulation.\n",
    "*   `functools` enhances function capabilities through caching, partial application, and decorator support.\n",
    "\n",
    "By understanding their capabilities, best practices, and potential pitfalls, you can leverage these modules to write more efficient, robust, and readable Python code. Continuously exploring the standard library is key to becoming a more effective Python developer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
