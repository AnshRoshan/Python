{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üóÑÔ∏è Mastering File Handling & OS Interactions in Python\n",
    "\n",
    "**Welcome!** This notebook is your guide to effectively interacting with the file system and operating system using Python. We'll cover everything from basic file reading/writing to modern path manipulation with `pathlib`, essential `os` module functions, and handling common data formats like CSV, JSON, and XML.\n",
    "\n",
    "**Target Audience:** Python developers needing to read, write, manipulate files, and interact with the underlying operating system environment.\n",
    "\n",
    "**Learning Objectives:**\n",
    "*   Understand fundamental file I/O operations using `open()` and context managers (`with`).\n",
    "*   Master modern, object-oriented path manipulation using the `pathlib` module.\n",
    "*   Learn key functions from the `os` module for environment variables, process interaction, and directory management.\n",
    "*   Effectively read and write structured data in CSV, JSON, and XML formats.\n",
    "*   Implement robust error handling for file operations.\n",
    "*   Understand best practices for cross-platform compatibility, security, and performance.\n",
    "*   Explore advanced topics like temporary files and high-level file operations (`shutil`).\n",
    "*   Identify common pitfalls and prepare for related interview questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction: Python as Your Digital Filing Assistant\n",
    "\n",
    "Many applications need to interact with files and the operating system. Whether it's reading configuration, writing logs, processing user data, managing datasets, or organizing project files, Python provides powerful tools to handle these tasks.\n",
    "\n",
    "**Analogy: The Digital Filing Cabinet**\n",
    "\n",
    "Think of your computer's file system as a complex filing cabinet. \n",
    "*   `open()` is like taking out a specific file to read or write in it.\n",
    "*   `pathlib` is like having an intelligent assistant who understands the cabinet's structure (folders, files), can find items easily, label them, move them, and tell you properties about them (is it a folder? when was it created?).\n",
    "*   The `os` module gives you tools to interact with the cabinet room itself ‚Äì checking the environment (temperature/environment variables), managing who's working (`os.getpid`), or even running external tools (`subprocess`).\n",
    "*   Handling CSV, JSON, or XML is like knowing how to read and write specific *types* of documents within the files (spreadsheets, structured notes, tagged documents).\n",
    "\n",
    "Mastering these tools allows you to automate tasks, manage data efficiently, and build more sophisticated applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic File I/O: The `open()` Function and Context Managers\n",
    "\n",
    "The built-in `open()` function is the fundamental way to interact with individual files.\n",
    "\n",
    "`open(file, mode='r', buffering=-1, encoding=None, errors=None, newline=None, closefd=True, opener=None)`\n",
    "\n",
    "*   `file`: Path to the file (string or `pathlib.Path` object).\n",
    "*   `mode`: A string indicating how the file is to be opened.\n",
    "*   `encoding`: **Crucial!** The encoding used to decode/encode the file (e.g., `'utf-8'`, `'cp1252'`). Use `locale.getpreferredencoding(False)` for the system default, but **explicit `'utf-8'` is strongly recommended** for cross-platform compatibility and modern text handling.\n",
    "*   `errors`: How encoding/decoding errors should be handled ('strict', 'ignore', 'replace').\n",
    "\n",
    "### 2.1 File Modes\n",
    "\n",
    "| Mode | Description                                                     | Behavior if File Exists | Behavior if File Doesn't Exist |\n",
    "| :--- | :-------------------------------------------------------------- | :---------------------- | :----------------------------- |\n",
    "| `'r'` | **Read** (default).                                             | Read from start         | `FileNotFoundError`            |\n",
    "| `'w'` | **Write**. Truncates file to zero length or creates new file. | **Overwrites**          | Creates new file               |\n",
    "| `'a'` | **Append**. Writes to end of file or creates new file.        | Appends to end          | Creates new file               |\n",
    "| `'x'` | **Exclusive Creation**. Writes only if file does not exist.     | `FileExistsError`       | Creates new file               |\n",
    "| `'b'` | **Binary mode**. Append to mode (e.g., `'rb'`, `'wb'`).         | N/A                     | N/A                            |\n",
    "| `'t'` | **Text mode** (default). Append to mode (e.g., `'rt'`, `'wt'`).| N/A                     | N/A                            |\n",
    "| `'+'` | **Update** (Reading and Writing). Append (e.g.,`'r+'`,`'w+'`).| Varies (see below)      | Varies (see below)             |\n",
    "\n",
    "*   `'r+'`: Read/Write. Doesn't truncate. `FileNotFoundError` if not exists.\n",
    "*   `'w+'`: Write/Read. **Overwrites** or creates. \n",
    "*   `'a+'`: Append/Read. Appends or creates. Reading starts at beginning, writing at end.\n",
    "*   `'x+'`: Exclusive Create/Read/Write. `FileExistsError` if exists.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 The `with` Statement (Context Manager) - **The Right Way**\n",
    "\n",
    "**Best Practice:** Always use the `with` statement when working with files. It ensures the file is automatically closed, even if errors occur within the block. This prevents resource leaks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "382dd83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Successfully wrote to my_sample_file.txt\n",
      "INFO: Successfully appended to my_sample_file.txt\n",
      "INFO: Successfully wrote binary data to my_binary_file.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System preferred encoding: UTF-8\n",
      "\n",
      "--- Reading my_sample_file.txt --- \n",
      "Content line by line:\n",
      "Content as list of lines: ['Hello from Python!\\n', 'This is the second line. Special chars: √§√∂√º√ü ‚Ç¨\\n', 'Third line\\n', 'Fourth line\\n', 'This line was appended.\\n']\n",
      "First 10 chars: 'Hello from'\n",
      "\n",
      "Read binary data: b'\\x00\\x01\\x02\\xff\\xfeHello binary!'\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import locale\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s', force=True)\n",
    "\n",
    "# Determine preferred encoding, but default to UTF-8\n",
    "preferred_encoding = locale.getpreferredencoding(False)\n",
    "print(f\"System preferred encoding: {preferred_encoding}\")\n",
    "# For consistency and broader compatibility, we'll explicitly use UTF-8\n",
    "FILE_ENCODING = 'utf-8'\n",
    "\n",
    "file_path = \"my_sample_file.txt\"\n",
    "\n",
    "# --- Writing to a file ('w' mode - overwrites or creates) --- \n",
    "try:\n",
    "    # 'with' ensures file is closed automatically\n",
    "    with open(file_path, mode='w', encoding=FILE_ENCODING) as f:\n",
    "        f.write(\"Hello from Python!\\n\")\n",
    "        f.write(\"This is the second line. Special chars: √§√∂√º√ü ‚Ç¨\\n\")\n",
    "        lines_to_write = [\"Third line\\n\", \"Fourth line\\n\"]\n",
    "        f.writelines(lines_to_write) # Writes a list of strings\n",
    "    logging.info(f\"Successfully wrote to {file_path}\")\n",
    "except IOError as e:\n",
    "    logging.error(f\"Error writing to {file_path}: {e}\")\n",
    "\n",
    "# --- Appending to a file ('a' mode) --- \n",
    "try:\n",
    "    with open(file_path, mode='a', encoding=FILE_ENCODING) as f:\n",
    "        f.write(\"This line was appended.\\n\")\n",
    "    logging.info(f\"Successfully appended to {file_path}\")\n",
    "except IOError as e:\n",
    "    logging.error(f\"Error appending to {file_path}: {e}\")\n",
    "\n",
    "# --- Reading from a file ('r' mode) --- \n",
    "try:\n",
    "    with open(file_path, mode='r', encoding=FILE_ENCODING) as f:\n",
    "        print(f\"\\n--- Reading {file_path} --- \")\n",
    "        \n",
    "        # Method 1: Read the whole file into a string\n",
    "        # content = f.read()\n",
    "        # print(\"Full content:\\n\", content)\n",
    "        \n",
    "        # Method 2: Read line by line (memory efficient for large files)\n",
    "        print(\"Content line by line:\")\n",
    "        # f.seek(0) # Go back to start if you already read()\n",
    "        # for line in f:\n",
    "        #     print(f\"  Line: {line.strip()}\") # strip() removes leading/trailing whitespace/newline\n",
    "        \n",
    "        # Method 3: Read all lines into a list\n",
    "        f.seek(0) # Go back to start\n",
    "        all_lines = f.readlines()\n",
    "        print(f\"Content as list of lines: {all_lines}\")\n",
    "        \n",
    "        # Method 4: Read specific number of characters\n",
    "        f.seek(0) # Go back to start\n",
    "        first_chars = f.read(10) \n",
    "        print(f\"First 10 chars: '{first_chars}'\")\n",
    "        \n",
    "except FileNotFoundError:\n",
    "    logging.error(f\"Error: File {file_path} not found.\")\n",
    "except IOError as e:\n",
    "    logging.error(f\"Error reading {file_path}: {e}\")\n",
    "\n",
    "# --- Reading/Writing Binary Files ('rb', 'wb') --- \n",
    "binary_file_path = \"my_binary_file.bin\"\n",
    "try:\n",
    "    some_bytes = b'\\x00\\x01\\x02\\xFF\\xFEHello binary!' # Note the b'' prefix\n",
    "    with open(binary_file_path, mode='wb') as bf: # No encoding for binary\n",
    "        bf.write(some_bytes)\n",
    "    logging.info(f\"Successfully wrote binary data to {binary_file_path}\")\n",
    "    \n",
    "    with open(binary_file_path, mode='rb') as bf:\n",
    "        read_bytes = bf.read()\n",
    "        print(f\"\\nRead binary data: {read_bytes}\")\n",
    "        assert read_bytes == some_bytes # Verify data integrity\n",
    "\n",
    "except IOError as e:\n",
    "    logging.error(f\"Error with binary file {binary_file_path}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72fab33",
   "metadata": {},
   "source": [
    "**Pitfalls with `open()`:**\n",
    "*   **Forgetting `with`:** Leading to resource leaks if files aren't closed, especially if errors occur.\n",
    "*   **Incorrect Mode:** Using `'r'` when intending to write, or `'w'` when intending to append, leading to errors or data loss.\n",
    "*   **Encoding Issues:** Not specifying `encoding='utf-8'` (or the correct encoding) can lead to `UnicodeDecodeError`, `UnicodeEncodeError`, or silently corrupted data, especially across different operating systems.\n",
    "*   **Not Handling `FileNotFoundError`:** Trying to read a file that doesn't exist without a `try...except` block will crash the program."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1989cb",
   "metadata": {},
   "source": [
    "## 3. Modern Path Handling: The `pathlib` Module\n",
    "\n",
    "Introduced in Python 3.4, `pathlib` offers an **object-oriented** way to represent and interact with filesystem paths, making code cleaner, more readable, and less error-prone than traditional string manipulation with `os.path`.\n",
    "\n",
    "**Key Advantages:**\n",
    "*   **Object-Oriented:** Paths are objects with methods and attributes, not just strings.\n",
    "*   **Cross-Platform:** Handles path separator differences ( `/` vs `\\`) automatically.\n",
    "*   **Readability:** Operations like joining paths or getting parent directories are more intuitive.\n",
    "*   **Integrated Operations:** Many common file operations (checking existence, reading/writing basic files, iterating directories) are built into the `Path` object.\n",
    "\n",
    "**Recommendation:** Use `pathlib` for all new code involving path manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5469fed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Directory (cwd): /mnt/Study/Python/THEORY/2-Advance\n",
      "Home Directory: /home/ansh\n",
      "File Path Object: my_sample_file.txt\n",
      "Log File Path: logs/app.log\n",
      "\n",
      "--- Path Components for: logs/app.log ---\n",
      "Parent directory: logs\n",
      "Filename: app.log\n",
      "Stem (name without suffix): app\n",
      "Suffix (extension): .log\n",
      "Is absolute path? False\n",
      "Absolute path of log_file: /mnt/Study/Python/THEORY/2-Advance/logs/app.log\n",
      "\n",
      "--- Existence Checks ---\n",
      "Does 'my_sample_file.txt' exist? True\n",
      "Is 'my_sample_file.txt' a file? True\n",
      "Is 'my_sample_file.txt' a directory? False\n",
      "Does 'no_such_file_here.dat' exist? False\n",
      "\n",
      "--- Creating and Deleting (Use with caution!) ---\n",
      "Directory 'my_temp_dir/subdir' created or already exists.\n",
      "File 'my_temp_dir/subdir/temp_file.txt' created.\n",
      "Wrote 27 bytes to my_temp_dir/subdir/temp_file.txt\n",
      "Read from my_temp_dir/subdir/temp_file.txt: 'Content written by pathlib!'\n",
      "Read binary from my_temp_dir/subdir/temp_file.txt: b'\\xca\\xfe\\xba\\xbe'\n",
      "File 'my_temp_dir/subdir/temp_file.txt' deleted.\n",
      "Directory 'my_temp_dir/subdir' deleted.\n",
      "Directory 'my_temp_dir' deleted.\n",
      "\n",
      "--- Iterating CWD (/mnt/Study/Python/THEORY/2-Advance) ---\n",
      "\n",
      "--- Globbing for '.txt' files in CWD (/mnt/Study/Python/THEORY/2-Advance) ---\n",
      "Found .txt files: [PosixPath('/mnt/Study/Python/THEORY/2-Advance/context_demo.txt'), PosixPath('/mnt/Study/Python/THEORY/2-Advance/manual_example.txt'), PosixPath('/mnt/Study/Python/THEORY/2-Advance/my_sample_file.txt'), PosixPath('/mnt/Study/Python/THEORY/2-Advance/temp_log.txt'), PosixPath('/mnt/Study/Python/THEORY/2-Advance/with_example.txt')]\n",
      "\n",
      "--- Recursive Globbing for '*.py' files starting from CWD's parent ---\n",
      "(Skipping recursive glob output for brevity)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os # Import os for comparison/specific tasks\n",
    "\n",
    "# --- Creating Path Objects --- \n",
    "# Current working directory\n",
    "cwd = Path.cwd()\n",
    "print(f\"Current Directory (cwd): {cwd}\")\n",
    "\n",
    "# Home directory\n",
    "home = Path.home()\n",
    "print(f\"Home Directory: {home}\")\n",
    "\n",
    "# Creating paths from strings (automatically handles separators)\n",
    "file_path_obj = Path(\"./my_sample_file.txt\") # Relative path\n",
    "config_dir = Path(\"/etc/my_app/config\") # Absolute path (example)\n",
    "log_dir = Path(\"logs\")\n",
    "log_file = log_dir / \"app.log\" # Intuitive joining using '/'\n",
    "print(f\"File Path Object: {file_path_obj}\")\n",
    "print(f\"Log File Path: {log_file}\")\n",
    "\n",
    "# --- Path Components & Properties --- \n",
    "print(f\"\\n--- Path Components for: {log_file} ---\")\n",
    "print(f\"Parent directory: {log_file.parent}\")\n",
    "print(f\"Filename: {log_file.name}\")\n",
    "print(f\"Stem (name without suffix): {log_file.stem}\")\n",
    "print(f\"Suffix (extension): {log_file.suffix}\")\n",
    "print(f\"Is absolute path? {log_file.is_absolute()}\")\n",
    "\n",
    "# Get absolute path\n",
    "print(f\"Absolute path of log_file: {log_file.resolve()}\")\n",
    "\n",
    "# --- Checking Existence and Type --- \n",
    "print(f\"\\n--- Existence Checks ---\")\n",
    "print(f\"Does '{file_path_obj}' exist? {file_path_obj.exists()}\")\n",
    "print(f\"Is '{file_path_obj}' a file? {file_path_obj.is_file()}\")\n",
    "print(f\"Is '{file_path_obj}' a directory? {file_path_obj.is_dir()}\")\n",
    "\n",
    "non_existent = Path(\"no_such_file_here.dat\")\n",
    "print(f\"Does '{non_existent}' exist? {non_existent.exists()}\")\n",
    "\n",
    "# --- Creating Files and Directories --- \n",
    "print(\"\\n--- Creating and Deleting (Use with caution!) ---\")\n",
    "new_dir = Path(\"my_temp_dir/subdir\")\n",
    "new_file = new_dir / \"temp_file.txt\"\n",
    "\n",
    "try:\n",
    "    # Create directories recursively (like os.makedirs)\n",
    "    new_dir.mkdir(parents=True, exist_ok=True) # exist_ok=True prevents error if dir exists\n",
    "    print(f\"Directory '{new_dir}' created or already exists.\")\n",
    "    \n",
    "    # Create an empty file (like 'touch' command)\n",
    "    if not new_file.exists():\n",
    "        new_file.touch()\n",
    "        print(f\"File '{new_file}' created.\")\n",
    "    else:\n",
    "        print(f\"File '{new_file}' already exists.\")\n",
    "        \n",
    "    # --- Basic File Read/Write with pathlib --- \n",
    "    # Simple text writing (overwrites)\n",
    "    bytes_written = new_file.write_text(\"Content written by pathlib!\", encoding=FILE_ENCODING)\n",
    "    print(f\"Wrote {bytes_written} bytes to {new_file}\")\n",
    "    \n",
    "    # Simple text reading\n",
    "    content = new_file.read_text(encoding=FILE_ENCODING)\n",
    "    print(f\"Read from {new_file}: '{content}'\")\n",
    "    \n",
    "    # Simple binary writing/reading\n",
    "    new_file.write_bytes(b'\\xCA\\xFE\\xBA\\xBE')\n",
    "    binary_content = new_file.read_bytes()\n",
    "    print(f\"Read binary from {new_file}: {binary_content}\")\n",
    "    \n",
    "    # --- Deleting Files and Directories --- \n",
    "    new_file.unlink() # Delete the file (remove link)\n",
    "    print(f\"File '{new_file}' deleted.\")\n",
    "    new_file.unlink(missing_ok=True) # missing_ok=True prevents error if already gone\n",
    "    \n",
    "    # Delete empty directories (must be empty)\n",
    "    new_dir.rmdir()\n",
    "    print(f\"Directory '{new_dir}' deleted.\")\n",
    "    # To remove parent as well if empty:\n",
    "    new_dir.parent.rmdir()\n",
    "    print(f\"Directory '{new_dir.parent}' deleted.\")\n",
    "    \n",
    "except OSError as e:\n",
    "    print(f\"Error during file/dir operation: {e}\")\n",
    "\n",
    "# --- Iterating Directory Contents --- \n",
    "print(f\"\\n--- Iterating CWD ({cwd}) ---\")\n",
    "for item in cwd.iterdir():\n",
    "    item_type = \"Dir\" if item.is_dir() else \"File\" if item.is_file() else \"Other\"\n",
    "    # print(f\"  [{item_type}] {item.name}\")\n",
    "    # Pass on printing all CWD items for brevity in example output\n",
    "\n",
    "# --- Globbing (Pattern Matching) --- \n",
    "print(f\"\\n--- Globbing for '.txt' files in CWD ({cwd}) ---\")\n",
    "txt_files = list(cwd.glob('*.txt'))\n",
    "print(f\"Found .txt files: {txt_files}\")\n",
    "\n",
    "print(f\"\\n--- Recursive Globbing for '*.py' files starting from CWD's parent ---\")\n",
    "# rglob() searches recursively\n",
    "# py_files = list(cwd.parent.rglob('*.py')) \n",
    "# print(f\"Found .py files recursively: {py_files}\") # Might find many files!\n",
    "print(\"(Skipping recursive glob output for brevity)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665fbff3",
   "metadata": {},
   "source": [
    "## 4. OS Module Interactions (`os`)\n",
    "\n",
    "While `pathlib` handles *path manipulation* beautifully, the `os` module provides lower-level access to operating system functionality, including:\n",
    "*   Environment variables\n",
    "*   Process information and management (though `subprocess` is often preferred for running external commands)\n",
    "*   User/Group information (less common in general scripts)\n",
    "*   Some directory operations (often have `pathlib` equivalents)\n",
    "\n",
    "### 4.1 Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93de036e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Skipping printing all env vars for brevity)\n",
      "\n",
      "User Home (from os.environ): /home/ansh\n",
      "API Key (from os.getenv): None\n",
      "DB Host (from os.getenv): localhost\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get all environment variables (returns a dict-like object)\n",
    "environment_vars = os.environ\n",
    "# print(\"--- All Environment Variables ---\")\n",
    "# for key, value in environment_vars.items():\n",
    "#     print(f\"  {key}={value}\")\n",
    "print(\"(Skipping printing all env vars for brevity)\")\n",
    "\n",
    "# Get a specific environment variable (case-sensitive, raises KeyError if not found)\n",
    "try:\n",
    "    user_home_os = os.environ['HOME'] # Common on Linux/macOS\n",
    "    # user_home_os = os.environ['USERPROFILE'] # Common on Windows\n",
    "    print(f\"\\nUser Home (from os.environ): {user_home_os}\")\n",
    "except KeyError:\n",
    "    print(\"\\nCould not find standard home directory variable in os.environ\")\n",
    "\n",
    "# Get a specific environment variable safely (returns None or default if not found)\n",
    "api_key = os.getenv('MY_APP_API_KEY')\n",
    "db_host = os.getenv('DB_HOST', 'localhost') # Provide a default value\n",
    "\n",
    "print(f\"API Key (from os.getenv): {api_key}\") # Likely None unless set externally\n",
    "print(f\"DB Host (from os.getenv): {db_host}\")\n",
    "\n",
    "# Set an environment variable (for the current process and its children)\n",
    "# os.environ['MY_TEMP_VAR'] = 'my_value'\n",
    "# print(f\"MY_TEMP_VAR: {os.getenv('MY_TEMP_VAR')}\")\n",
    "# del os.environ['MY_TEMP_VAR'] # Unset it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcc8954",
   "metadata": {},
   "source": [
    "### 4.2 Running External Commands (`subprocess` - Preferred over `os.system`)\n",
    "\n",
    "While `os.system(\"command\")` exists, it's generally **discouraged** due to security risks (shell injection) and lack of control over input/output.\n",
    "\n",
    "**Best Practice:** Use the `subprocess` module for running external commands. It's more secure and flexible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ae9a8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running 'ls -lha' using subprocess --- \n",
      "Command executed successfully (Return Code: 0)\n",
      "Output:\n",
      "total 750K\n",
      "drwxrwxrwx 1 root root 4.0K Apr 20 16:33 .\n",
      "drwxrwxrwx 1 root root  12K Apr 19 16:56 ..\n",
      "-rwxrwxrwx 1 root root  74K Apr 20 16:13 01-OOPS.ipynb\n",
      "-rwxrwxrwx 1 root root  47K Apr 20 16:13 02-Logging.ipynb\n",
      "-rwxrwxrwx 1 root root  37K Apr 20 16:13 03-Generators.ipynb\n",
      "-rwxrwxrwx 1 root root  56K Apr 20 16:14 04-Decoratos.ipynb\n",
      "-rwxrwxrwx 1 root root  46K Apr 20 16:14 05-Exceptions.ipynb\n",
      "-rwxrwxrwx 1 root root  13K Apr 19 14:27 06-Concurrency.ipynb\n",
      "-rwxrwxrwx 1 root root  11K Apr 20 16:16 06-C...\n",
      "\n",
      "--- Running 'ls -lha' using subprocess (shell=False) --- \n",
      "Command executed successfully.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Determine the command based on OS\n",
    "list_command = \"dir\" if sys.platform == \"win32\" else \"ls -lha\"\n",
    "\n",
    "print(f\"\\n--- Running '{list_command}' using subprocess --- \")\n",
    "try:\n",
    "    # Run command, capture output, check for errors\n",
    "    # text=True decodes output as text using default encoding\n",
    "    # shell=True can be a security risk if command includes untrusted input!\n",
    "    # Better to pass command and args as a list: ['ls', '-lha'] when shell=False\n",
    "    process = subprocess.run(list_command, \n",
    "                             capture_output=True, \n",
    "                             text=True, \n",
    "                             check=True, # Raises CalledProcessError if command returns non-zero exit code\n",
    "                             shell=True, # Use with caution \n",
    "                             encoding=locale.getpreferredencoding(False))\n",
    "    \n",
    "    print(f\"Command executed successfully (Return Code: {process.returncode})\")\n",
    "    print(\"Output:\")\n",
    "    print(process.stdout[:500] + \"...\") # Print first 500 chars of output\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    # If the command itself isn't found\n",
    "    print(f\"Error: Command not found: {e}\")\n",
    "except subprocess.CalledProcessError as e:\n",
    "    # If the command returns an error exit code\n",
    "    print(f\"Error: Command '{e.cmd}' failed with return code {e.returncode}\")\n",
    "    print(f\"Stderr:\\n{e.stderr}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred running subprocess: {e}\")\n",
    "\n",
    "# Example without shell=True (safer)\n",
    "list_command_parts = [\"ls\", \"-lha\"] if sys.platform != \"win32\" else [\"cmd\", \"/c\", \"dir\"] \n",
    "print(f\"\\n--- Running '{' '.join(list_command_parts)}' using subprocess (shell=False) --- \")\n",
    "try:\n",
    "    process_safe = subprocess.run(list_command_parts,\n",
    "                                capture_output=True,\n",
    "                                text=True,\n",
    "                                check=True,\n",
    "                                encoding=locale.getpreferredencoding(False))\n",
    "    print(\"Command executed successfully.\")\n",
    "    # print(process_safe.stdout[:500] + \"...\")\n",
    "except (FileNotFoundError, subprocess.CalledProcessError, Exception) as e:\n",
    "    print(f\"Error running command safely: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c117036e",
   "metadata": {},
   "source": [
    "### 4.3 Other Useful `os` Functions\n",
    "\n",
    "*   `os.getcwd()`: Get current working directory (returns string - use `Path.cwd()` for a Path object).\n",
    "*   `os.chdir(path)`: Change current working directory.\n",
    "*   `os.listdir(path='.')`: List directory contents (returns list of strings - `Path.iterdir()` is often preferred).\n",
    "*   `os.makedirs(name, mode=0o777, exist_ok=False)`: Recursive directory creation (like `Path.mkdir(parents=True)`).\n",
    "*   `os.remove(path)` or `os.unlink(path)`: Remove/delete a file (like `Path.unlink()`).\n",
    "*   `os.rmdir(path)`: Remove an *empty* directory (like `Path.rmdir()`).\n",
    "*   `os.getpid()`: Get the current process ID.\n",
    "*   `os.path.join(path, *paths)`: Join path components intelligently (use `Path / ...` instead).\n",
    "*   `os.path.exists(path)`: Check if path exists (use `Path.exists()` instead).\n",
    "*   `os.path.isfile(path)` / `os.path.isdir(path)`: Check type (use `Path.is_file()` / `Path.is_dir()` instead).\n",
    "\n",
    "**Takeaway:** While `pathlib` replaces many `os.path` functions, `os` itself is still needed for environment variables, process interactions, and sometimes lower-level file descriptor operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1163cc",
   "metadata": {},
   "source": [
    "## 5. Working with Common File Formats\n",
    "\n",
    "Beyond plain text, you'll often work with structured data formats.\n",
    "\n",
    "### 5.1 CSV (Comma Separated Values)\n",
    "\n",
    "Use the built-in `csv` module for basic reading and writing.\n",
    "**Note:** For complex CSV manipulation, filtering, and analysis, the `pandas` library is highly recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3d653b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Successfully wrote list data to data.csv\n",
      "INFO: Successfully wrote dict data to data_dict.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Reading data.csv (as lists) ---\n",
      "Header: ['Name', 'Department', 'Salary']\n",
      "  Row 1: ['Alice', 'Engineering', '80000']\n",
      "  Row 2: ['Bob', 'Sales', '75000']\n",
      "  Row 3: ['Charlie', 'Engineering', '90000']\n",
      "\n",
      "--- Reading data_dict.csv (as dicts) ---\n",
      "Fieldnames detected: ['ID', 'Product', 'Price']\n",
      "  Row 1: {'ID': '1', 'Product': 'Laptop', 'Price': '1200.5'}\n",
      "  Row 2: {'ID': '2', 'Product': 'Mouse', 'Price': '25.99'}\n",
      "  Row 3: {'ID': '3', 'Product': 'Keyboard', 'Price': '75.0'}\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "csv_file_path = Path(\"data.csv\")\n",
    "dict_csv_file_path = Path(\"data_dict.csv\")\n",
    "\n",
    "# --- Writing CSV Data (List of Lists) --- \n",
    "data_to_write = [\n",
    "    [\"Name\", \"Department\", \"Salary\"],\n",
    "    [\"Alice\", \"Engineering\", 80000],\n",
    "    [\"Bob\", \"Sales\", 75000],\n",
    "    [\"Charlie\", \"Engineering\", 90000]\n",
    "]\n",
    "\n",
    "try:\n",
    "    # newline='' is important to prevent extra blank rows on some OS\n",
    "    with csv_file_path.open(mode='w', newline='', encoding=FILE_ENCODING) as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(data_to_write) # Write all rows at once\n",
    "        # Or write row by row: \n",
    "        # writer.writerow([\"David\", \"HR\", 60000])\n",
    "    logging.info(f\"Successfully wrote list data to {csv_file_path}\")\n",
    "except IOError as e:\n",
    "    logging.error(f\"Error writing CSV: {e}\")\n",
    "\n",
    "# --- Reading CSV Data (as Lists) --- \n",
    "try:\n",
    "    with csv_file_path.open(mode='r', newline='', encoding=FILE_ENCODING) as f:\n",
    "        reader = csv.reader(f)\n",
    "        print(f\"\\n--- Reading {csv_file_path} (as lists) ---\")\n",
    "        header = next(reader) # Read the header row\n",
    "        print(f\"Header: {header}\")\n",
    "        for i, row in enumerate(reader):\n",
    "            # Row is a list of strings\n",
    "            print(f\"  Row {i+1}: {row}\") \n",
    "            # Example: Accessing data\n",
    "            # name = row[0]\n",
    "            # salary = int(row[2]) # Remember data is read as strings\n",
    "except (IOError, StopIteration) as e:\n",
    "    logging.error(f\"Error reading CSV: {e}\")\n",
    "\n",
    "# --- Writing CSV Data (List of Dictionaries) --- \n",
    "dict_data_to_write = [\n",
    "    {'ID': 1, 'Product': 'Laptop', 'Price': 1200.50},\n",
    "    {'ID': 2, 'Product': 'Mouse', 'Price': 25.99},\n",
    "    {'ID': 3, 'Product': 'Keyboard', 'Price': 75.00}\n",
    "]\n",
    "fieldnames = ['ID', 'Product', 'Price'] # Must specify fieldnames\n",
    "\n",
    "try:\n",
    "    with dict_csv_file_path.open(mode='w', newline='', encoding=FILE_ENCODING) as f:\n",
    "        # Use DictWriter for writing lists of dictionaries\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        \n",
    "        writer.writeheader() # Write the header row from fieldnames\n",
    "        writer.writerows(dict_data_to_write) # Write all dicts\n",
    "        # Or write single dict: writer.writerow({'ID': 4, ...})\n",
    "    logging.info(f\"Successfully wrote dict data to {dict_csv_file_path}\")\n",
    "except IOError as e:\n",
    "    logging.error(f\"Error writing Dict CSV: {e}\")\n",
    "\n",
    "# --- Reading CSV Data (as Dictionaries) --- \n",
    "try:\n",
    "    with dict_csv_file_path.open(mode='r', newline='', encoding=FILE_ENCODING) as f:\n",
    "        # Use DictReader for reading rows as dictionaries\n",
    "        reader = csv.DictReader(f)\n",
    "        print(f\"\\n--- Reading {dict_csv_file_path} (as dicts) ---\")\n",
    "        print(f\"Fieldnames detected: {reader.fieldnames}\")\n",
    "        for i, row_dict in enumerate(reader):\n",
    "            # row_dict is an OrderedDict or dict (depending on Python version)\n",
    "            print(f\"  Row {i+1}: {row_dict}\")\n",
    "            # Example: Accessing data by key\n",
    "            # product_name = row_dict['Product']\n",
    "            # price = float(row_dict['Price']) # Data still read as strings\n",
    "except IOError as e:\n",
    "     logging.error(f\"Error reading Dict CSV: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fe6a01",
   "metadata": {},
   "source": [
    "### 5.2 JSON (JavaScript Object Notation)\n",
    "\n",
    "Use the built-in `json` module. (Assumes familiarity from the dedicated JSON notebook - focuses here on file I/O aspects)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fcfbe40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Successfully wrote JSON to data.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Reading data.json --- \n",
      "Loaded data type: <class 'dict'>\n",
      "Location: {'lat': 40.7128, 'lon': -74.006}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "json_file_path = Path(\"data.json\")\n",
    "python_object = {\n",
    "    \"name\": \"Sensor Array\",\n",
    "    \"location\": {\"lat\": 40.7128, \"lon\": -74.0060},\n",
    "    \"readings\": [\n",
    "        {\"timestamp\": \"2023-10-26T10:00:00Z\", \"value\": 15.5, \"unit\": \"C\"},\n",
    "        {\"timestamp\": \"2023-10-26T10:05:00Z\", \"value\": 15.8, \"unit\": \"C\"}\n",
    "    ],\n",
    "    \"active\": True,\n",
    "    \"calibration_factor\": None\n",
    "}\n",
    "\n",
    "# --- Writing JSON to File (json.dump) --- \n",
    "try:\n",
    "    with json_file_path.open(mode='w', encoding=FILE_ENCODING) as f:\n",
    "        # dump serializes and writes to file object\n",
    "        json.dump(python_object, f, indent=4) # indent for pretty printing\n",
    "    logging.info(f\"Successfully wrote JSON to {json_file_path}\")\n",
    "except (IOError, TypeError) as e:\n",
    "    logging.error(f\"Error writing JSON: {e}\")\n",
    "\n",
    "# --- Reading JSON from File (json.load) --- \n",
    "try:\n",
    "    with json_file_path.open(mode='r', encoding=FILE_ENCODING) as f:\n",
    "        # load reads from file object and deserializes\n",
    "        loaded_data = json.load(f)\n",
    "        print(f\"\\n--- Reading {json_file_path} --- \")\n",
    "        print(f\"Loaded data type: {type(loaded_data)}\")\n",
    "        # print(json.dumps(loaded_data, indent=2)) # Pretty print the loaded data\n",
    "        print(f\"Location: {loaded_data.get('location')}\")\n",
    "except (IOError, json.JSONDecodeError) as e:\n",
    "    logging.error(f\"Error reading JSON: {e}\")\n",
    "\n",
    "# For details on dumps/loads (strings) and custom objects, see the JSON notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8608ada",
   "metadata": {},
   "source": [
    "### 5.3 XML (eXtensible Markup Language)\n",
    "\n",
    "Use the built-in `xml.etree.ElementTree` module for basic XML parsing and creation.\n",
    "**Note:** For complex XML, namespaces, validation, and transformations (XPath, XSLT), the third-party `lxml` library is significantly more powerful and generally recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49dd06af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Successfully wrote XML to data.xml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Reading data.xml --- \n",
      "Root element tag: catalog\n",
      "Books found:\n",
      "  - Title: The Pragmatic Programmer, Author: Andrew Hunt, ISBN: 978-0321765723\n",
      "  - Title: Clean Code, Author: Robert C. Martin, ISBN: 978-0132350884\n",
      "Found Clean Code title: Clean Code\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "xml_file_path = Path(\"data.xml\")\n",
    "\n",
    "# --- Creating and Writing XML --- \n",
    "# Create root element\n",
    "root = ET.Element(\"catalog\")\n",
    "\n",
    "# Create child elements\n",
    "book1 = ET.SubElement(root, \"book\", isbn=\"978-0321765723\")\n",
    "title1 = ET.SubElement(book1, \"title\")\n",
    "title1.text = \"The Pragmatic Programmer\"\n",
    "author1 = ET.SubElement(book1, \"author\")\n",
    "author1.text = \"Andrew Hunt\"\n",
    "\n",
    "book2 = ET.SubElement(root, \"book\", isbn=\"978-0132350884\")\n",
    "title2 = ET.SubElement(book2, \"title\")\n",
    "title2.text = \"Clean Code\"\n",
    "author2 = ET.SubElement(book2, \"author\")\n",
    "author2.text = \"Robert C. Martin\"\n",
    "\n",
    "# Build the tree structure\n",
    "tree = ET.ElementTree(root)\n",
    "\n",
    "# Pretty print function (optional, for nicer output)\n",
    "def indent_xml(elem, level=0):\n",
    "    i = \"\\n\" + level*\"  \"\n",
    "    if len(elem):\n",
    "        if not elem.text or not elem.text.strip():\n",
    "            elem.text = i + \"  \"\n",
    "        if not elem.tail or not elem.tail.strip():\n",
    "            elem.tail = i\n",
    "        for subelem in elem:\n",
    "            indent_xml(subelem, level+1)\n",
    "        if not subelem.tail or not subelem.tail.strip():\n",
    "            subelem.tail = i\n",
    "    else:\n",
    "        if level and (not elem.tail or not elem.tail.strip()):\n",
    "            elem.tail = i\n",
    "\n",
    "try:\n",
    "    indent_xml(root) # Apply indentation\n",
    "    # Write the tree to a file\n",
    "    # encoding='unicode' writes as text, 'utf-8' would write as bytes\n",
    "    tree.write(xml_file_path, encoding='unicode', xml_declaration=True)\n",
    "    logging.info(f\"Successfully wrote XML to {xml_file_path}\")\n",
    "\n",
    "    # Get XML as string\n",
    "    # xml_string = ET.tostring(root, encoding='unicode')\n",
    "    # print(xml_string)\n",
    "\n",
    "except IOError as e:\n",
    "    logging.error(f\"Error writing XML: {e}\")\n",
    "\n",
    "# --- Parsing and Reading XML --- \n",
    "try:\n",
    "    # Parse an XML file\n",
    "    parsed_tree = ET.parse(xml_file_path)\n",
    "    parsed_root = parsed_tree.getroot()\n",
    "    \n",
    "    print(f\"\\n--- Reading {xml_file_path} --- \")\n",
    "    print(f\"Root element tag: {parsed_root.tag}\")\n",
    "    \n",
    "    # Find specific elements\n",
    "    print(\"Books found:\")\n",
    "    # findall looks for direct children matching the tag\n",
    "    for book in parsed_root.findall('book'): \n",
    "        isbn = book.get('isbn') # Get attribute value\n",
    "        title = book.find('title').text # Find child and get its text content\n",
    "        author = book.find('author').text\n",
    "        print(f\"  - Title: {title}, Author: {author}, ISBN: {isbn}\")\n",
    "        \n",
    "    # Example: Find book by attribute\n",
    "    clean_code_book = parsed_root.find(\".//book[@isbn='978-0132350884']\") # Basic XPath support\n",
    "    if clean_code_book is not None:\n",
    "        print(f\"Found Clean Code title: {clean_code_book.find('title').text}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    logging.error(f\"XML file not found: {xml_file_path}\")\n",
    "except ET.ParseError as e:\n",
    "    logging.error(f\"Error parsing XML file {xml_file_path}: {e}\")\n",
    "except IOError as e:\n",
    "    logging.error(f\"Error reading XML file {xml_file_path}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ba5881",
   "metadata": {},
   "source": [
    "## 6. Advanced Topics & Enterprise Considerations\n",
    "\n",
    "### 6.1 Temporary Files and Directories (`tempfile`)\n",
    "When you need temporary storage that gets cleaned up automatically.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e71542a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created temporary file: /tmp/myapp_7nkys_05.tmp\n",
      "  Content: Temporary data\n",
      "Does temp file exist after close? True\n",
      "Manually removed temp file: /tmp/myapp_7nkys_05.tmp\n",
      "\n",
      "Created temporary directory: /tmp/data_trwhuihr_work\n",
      "  Created subfile: /tmp/data_trwhuihr_work/results.txt\n",
      "  Does temp dir exist inside 'with'? True\n",
      "Does temp dir exist after 'with'? False\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "import os\n",
    "\n",
    "# --- Create a temporary file --- \n",
    "# NamedTemporaryFile is deleted when closed\n",
    "# Use delete=False to keep the file after closing (manual cleanup needed)\n",
    "try:\n",
    "    with tempfile.NamedTemporaryFile(mode='w+', delete=False, suffix=\".tmp\", prefix=\"myapp_\", encoding=FILE_ENCODING) as temp_file:\n",
    "        temp_file_path = temp_file.name\n",
    "        print(f\"Created temporary file: {temp_file_path}\")\n",
    "        temp_file.write(\"Temporary data\\n\")\n",
    "        temp_file.seek(0)\n",
    "        print(f\"  Content: {temp_file.read().strip()}\")\n",
    "    # File is now closed. If delete=False, it remains.\n",
    "    print(f\"Does temp file exist after close? {os.path.exists(temp_file_path)}\")\n",
    "    # Manual cleanup if delete=False\n",
    "    if os.path.exists(temp_file_path):\n",
    "       os.remove(temp_file_path)\n",
    "       print(f\"Manually removed temp file: {temp_file_path}\")\n",
    "except (IOError, OSError) as e:\n",
    "    print(f\"Error with temporary file: {e}\")\n",
    "\n",
    "# --- Create a temporary directory --- \n",
    "# TemporaryDirectory is automatically cleaned up when the context manager exits\n",
    "try:\n",
    "    with tempfile.TemporaryDirectory(suffix=\"_work\", prefix=\"data_\") as temp_dir_path:\n",
    "        print(f\"\\nCreated temporary directory: {temp_dir_path}\")\n",
    "        # You can create files inside this directory\n",
    "        temp_subfile = Path(temp_dir_path) / \"results.txt\"\n",
    "        temp_subfile.write_text(\"Results data\", encoding=FILE_ENCODING)\n",
    "        print(f\"  Created subfile: {temp_subfile}\")\n",
    "        print(f\"  Does temp dir exist inside 'with'? {os.path.exists(temp_dir_path)}\")\n",
    "    # The directory and its contents are deleted upon exiting the 'with' block\n",
    "    print(f\"Does temp dir exist after 'with'? {os.path.exists(temp_dir_path)}\") \n",
    "except (IOError, OSError) as e:\n",
    "    print(f\"Error with temporary directory: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7e99c0",
   "metadata": {},
   "source": [
    "### 6.2 High-Level File Operations (`shutil`)\n",
    "For operations like copying files/directories, moving, or deleting entire directory trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22ff002e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- shutil Operations ---\n",
      "Copied source_to_copy.txt to destination_dir. Checksum: True\n",
      "Copied directory tree source_dir_to_copy to dest_dir_tree. Checksum: True\n",
      "Moved destination_dir/source_to_copy.txt to destination_dir/moved_file.txt. Checksum: True\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# Setup: Create source file and destination directory\n",
    "source_file = Path(\"source_to_copy.txt\")\n",
    "dest_dir = Path(\"destination_dir\")\n",
    "dest_file = dest_dir / source_file.name\n",
    "source_dir = Path(\"source_dir_to_copy\")\n",
    "source_dir_subfile = source_dir / \"subfile.txt\"\n",
    "dest_dir_tree = Path(\"dest_dir_tree\")\n",
    "\n",
    "try:\n",
    "    source_file.write_text(\"Data to be copied.\", encoding=FILE_ENCODING)\n",
    "    dest_dir.mkdir(exist_ok=True)\n",
    "    source_dir.mkdir(exist_ok=True)\n",
    "    source_dir_subfile.write_text(\"Subfile data\", encoding=FILE_ENCODING)\n",
    "\n",
    "    print(\"\\n--- shutil Operations ---\")\n",
    "    # Copy file (src, dst) - dst can be file or dir\n",
    "    shutil.copy(source_file, dest_dir)\n",
    "    print(f\"Copied {source_file} to {dest_dir}. Checksum: {dest_file.exists()}\")\n",
    "    \n",
    "    # Copy file preserving metadata (copy2)\n",
    "    # shutil.copy2(source_file, dest_dir / \"copied_meta.txt\")\n",
    "    \n",
    "    # Copy directory tree\n",
    "    if dest_dir_tree.exists(): # Remove existing dest if needed for copytree\n",
    "        shutil.rmtree(dest_dir_tree)\n",
    "    shutil.copytree(source_dir, dest_dir_tree)\n",
    "    print(f\"Copied directory tree {source_dir} to {dest_dir_tree}. Checksum: {(dest_dir_tree / source_dir_subfile.name).exists()}\")\n",
    "\n",
    "    # Move file or directory\n",
    "    move_dest = dest_dir / \"moved_file.txt\"\n",
    "    shutil.move(dest_file, move_dest)\n",
    "    print(f\"Moved {dest_file} to {move_dest}. Checksum: {move_dest.exists()}\")\n",
    "\n",
    "    # Remove directory tree (use with extreme caution!)\n",
    "    # shutil.rmtree(dest_dir_tree)\n",
    "    # print(f\"Removed directory tree {dest_dir_tree}\")\n",
    "\n",
    "except (IOError, OSError, shutil.Error) as e:\n",
    "    print(f\"Error during shutil operation: {e}\")\n",
    "finally:\n",
    "    # Cleanup demo files/dirs\n",
    "    source_file.unlink(missing_ok=True)\n",
    "    move_dest.unlink(missing_ok=True)\n",
    "    if dest_dir_tree.exists(): shutil.rmtree(dest_dir_tree)\n",
    "    source_dir_subfile.unlink(missing_ok=True)\n",
    "    source_dir.rmdir()\n",
    "    dest_dir.rmdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7268b624",
   "metadata": {},
   "source": [
    "### 6.3 Performance Considerations\n",
    "*   **Buffering:** File I/O is usually buffered by default (OS level). Reading/writing in larger chunks can sometimes be more efficient than many small operations, but the defaults are often good.\n",
    "*   **Memory Usage:** Avoid reading entire large files into memory (`read()`, `readlines()`). Iterate line by line or process in chunks.\n",
    "*   **`pathlib` vs `os.path`:** `pathlib` might have a small overhead for object creation, but it's negligible for most applications and the readability gain is significant.\n",
    "*   **`shutil`:** Generally efficient for high-level operations as it often uses optimized OS calls.\n",
    "\n",
    "### 6.4 Security Considerations\n",
    "*   **Path Traversal:** Never construct file paths directly from untrusted user input (e.g., web requests). An attacker could provide input like `../../../etc/passwd` to access sensitive files. Sanitize and validate input, or use safer methods like generating unique IDs for user files stored in a designated base directory.\n",
    "*   **Permissions:** Be mindful of file permissions when creating or modifying files, especially in multi-user environments. Use `os.chmod` if needed.\n",
    "*   **Running Commands:** Be extremely careful when running external commands (`subprocess`). Avoid `shell=True` with untrusted input. Sanitize arguments passed to commands.\n",
    "*   **Race Conditions:** In concurrent environments, multiple processes/threads accessing the same file can lead to race conditions (e.g., checking `exists()` then trying to `open()` might fail if another process deletes the file in between). Use file locking mechanisms or atomic operations where necessary.\n",
    "\n",
    "### 6.5 Idempotency\n",
    "*   Ensure file operations can be repeated safely without unintended side effects (e.g., using `Path.mkdir(exist_ok=True)`, checking existence before writing if overwriting is not desired)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcb0969",
   "metadata": {},
   "source": [
    "## 7. Pitfalls and Common Interview Questions\n",
    "\n",
    "**Common Pitfalls:**\n",
    "\n",
    "*   **Not using `with open(...)`:** Forgetting to close files, leading to resource leaks or data not being flushed.\n",
    "*   **Encoding Errors:** Assuming default encoding or using the wrong one, causing `UnicodeDecodeError`/`UnicodeEncodeError` or corrupted text.\n",
    "*   **Path Separator Issues:** Hardcoding `\\` or `/` instead of using `pathlib` or `os.path.join` for cross-platform compatibility.\n",
    "*   **Overwriting Files:** Using `'w'` mode accidentally when `'a'` (append) or existence checks were needed.\n",
    "*   **Path Traversal Vulnerabilities:** Building paths from unsanitized user input.\n",
    "*   **Permissions Errors:** Trying to read/write files without sufficient OS permissions.\n",
    "*   **Forgetting `newline=''` for `csv`:** Resulting in extra blank rows in the CSV file on Windows.\n",
    "*   **Reading Large Files into Memory:** Causing performance issues or crashes.\n",
    "*   **Race Conditions:** In concurrent access scenarios without proper locking.\n",
    "\n",
    "**Common Interview Questions:**\n",
    "\n",
    "1.  How do you open a file in Python? What is the importance of the `with` statement?\n",
    "2.  Explain the different file modes (`r`, `w`, `a`, `b`, `+`).\n",
    "3.  Why is specifying file encoding (like `utf-8`) important?\n",
    "4.  What is `pathlib` and why is it preferred over `os.path`?\n",
    "5.  Show how to join path components using `pathlib`.\n",
    "6.  How do you check if a file or directory exists using `pathlib`?\n",
    "7.  How can you list the contents of a directory?\n",
    "8.  How do you read/write a CSV file in Python?\n",
    "9.  How do you read/write a JSON file?\n",
    "10. How do you run an external command safely in Python? (Mention `subprocess`). Why avoid `os.system`?\n",
    "11. How do you get the value of an environment variable?\n",
    "12. What are some security considerations when working with files and paths?\n",
    "13. How would you handle potential `FileNotFoundError` when opening a file?\n",
    "14. How can you copy or move files/directories using Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5d3414",
   "metadata": {},
   "source": [
    "## 8. Mini-Project: File Organizer\n",
    "\n",
    "**Goal:** Create a script that organizes files in a specified directory into subdirectories based on their file extension.\n",
    "\n",
    "**Tasks:**\n",
    "\n",
    "1.  **Input:** The script should take a source directory path as input (e.g., via command-line argument using `argparse`, or just hardcoded for simplicity in the notebook).\n",
    "2.  **Logic:**\n",
    "    *   Use `pathlib` to represent the source directory.\n",
    "    *   Iterate through all *files* (not directories) directly within the source directory (`Path.iterdir()` combined with `is_file()`).\n",
    "    *   For each file, get its extension (e.g., `.txt`, `.jpg`, `.pdf`). Handle files with no extension (e.g., place them in a `no_extension` folder or skip them).\n",
    "    *   Create a subdirectory named after the extension (lowercase, without the leading dot, e.g., `txt`, `jpg`, `pdf`) inside the source directory if it doesn't already exist (`Path.mkdir(exist_ok=True)`).\n",
    "    *   Move the file into the corresponding subdirectory (`shutil.move` or `Path.rename`).\n",
    "3.  **Error Handling:** Handle potential errors like the source directory not existing or permission issues during file moving/directory creation (use `try...except`).\n",
    "4.  **Logging:** Add logging messages (INFO level) indicating which file is being moved and to which directory, and log any errors encountered.\n",
    "5.  **Setup:** Before running, manually create a test directory (e.g., `organize_me`) and place a few dummy files with different extensions inside it (e.g., `report.txt`, `image.jpg`, `document.pdf`, `archive.zip`, `no_extension_file`).\n",
    "\n",
    "**(Bonus):** Add an option to organize recursively through subdirectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d81d6ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-20 16:33:10,192 - INFO - Starting organization for directory: organize_me\n",
      "2025-04-20 16:33:10,195 - INFO - Moved 'archive.tar.gz' to 'gz/'\n",
      "2025-04-20 16:33:10,198 - INFO - Moved 'data.csv' to 'csv/'\n",
      "2025-04-20 16:33:10,200 - INFO - Moved 'document.PDF' to 'pdf/'\n",
      "2025-04-20 16:33:10,202 - INFO - Moved 'image.jpg' to 'jpg/'\n",
      "2025-04-20 16:33:10,204 - INFO - Moved 'NO_EXTENSION_FILE' to 'no_extension/'\n",
      "2025-04-20 16:33:10,207 - INFO - Moved 'report.txt' to 'txt/'\n",
      "2025-04-20 16:33:10,208 - INFO - Organization finished for directory: organize_me\n"
     ]
    }
   ],
   "source": [
    "# --- Solution Space for Mini-Project ---\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', force=True)\n",
    "\n",
    "def organize_files(source_dir_path_str: str):\n",
    "    \"\"\"Organizes files in a source directory into subdirs by extension.\n",
    "\n",
    "    Args:\n",
    "        source_dir_path_str: The path to the directory to organize.\n",
    "    \"\"\"\n",
    "    source_dir = Path(source_dir_path_str)\n",
    "\n",
    "    if not source_dir.is_dir():\n",
    "        logging.error(f\"Source directory '{source_dir}' not found or is not a directory.\")\n",
    "        return\n",
    "\n",
    "    logging.info(f\"Starting organization for directory: {source_dir}\")\n",
    "\n",
    "    try:\n",
    "        for item in source_dir.iterdir():\n",
    "            if item.is_file(): # Process only files\n",
    "                file_extension = item.suffix.lower() # Get extension (e.g., '.txt')\n",
    "\n",
    "                if not file_extension: # Handle files with no extension\n",
    "                    dest_folder_name = \"no_extension\"\n",
    "                else:\n",
    "                    # Remove leading dot for folder name\n",
    "                    dest_folder_name = file_extension[1:] \n",
    "                \n",
    "                destination_dir = source_dir / dest_folder_name\n",
    "                \n",
    "                try:\n",
    "                    # Create destination directory if it doesn't exist\n",
    "                    destination_dir.mkdir(exist_ok=True)\n",
    "                    \n",
    "                    # Move the file\n",
    "                    destination_path = destination_dir / item.name\n",
    "                    shutil.move(str(item), str(destination_path)) # shutil.move often needs strings\n",
    "                    logging.info(f\"Moved '{item.name}' to '{dest_folder_name}/'\")\n",
    "                    \n",
    "                except OSError as e:\n",
    "                    logging.error(f\"Could not move file '{item.name}' or create directory '{destination_dir}': {e}\")\n",
    "                except shutil.Error as e:\n",
    "                     logging.error(f\"Error moving file '{item.name}' using shutil: {e}\")\n",
    "\n",
    "    except OSError as e:\n",
    "         logging.error(f\"Error iterating source directory '{source_dir}': {e}\")\n",
    "\n",
    "    logging.info(f\"Organization finished for directory: {source_dir}\")\n",
    "\n",
    "# --- Setup and Run --- \n",
    "# 1. Manually create a directory named 'organize_me'\n",
    "# 2. Manually create dummy files inside 'organize_me': \n",
    "#    e.g., report.txt, image.jpg, data.csv, script.py, NO_EXT\n",
    "test_directory = \"organize_me\"\n",
    "\n",
    "# Create directory and dummy files if they don't exist\n",
    "setup_dir = Path(test_directory)\n",
    "setup_dir.mkdir(exist_ok=True)\n",
    "(setup_dir / \"report.txt\").touch()\n",
    "(setup_dir / \"image.jpg\").touch()\n",
    "(setup_dir / \"document.PDF\").touch() # Test case insensitivity\n",
    "(setup_dir / \"data.csv\").touch()\n",
    "(setup_dir / \"NO_EXTENSION_FILE\").touch()\n",
    "(setup_dir / \"archive.tar.gz\").touch() # Test multi-part extension\n",
    "\n",
    "# Run the organizer\n",
    "organize_files(test_directory)\n",
    "\n",
    "# Check the 'organize_me' directory afterwards!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Conclusion\n",
    "\n",
    "Python provides a rich and robust ecosystem for interacting with the file system and operating system. By leveraging the modern `pathlib` module for path manipulation, understanding the fundamentals of `open()` with context managers for file I/O, knowing key `os` functions for environment/process interactions, and utilizing specialized modules (`csv`, `json`, `xml`) for data formats, you can write clean, efficient, cross-platform, and maintainable code.\n",
    "\n",
    "Always prioritize using `with` for resource management, specify encoding (prefer `'utf-8'`), handle exceptions gracefully, and be mindful of security implications, especially when dealing with external input or running commands. With these tools and practices, you can confidently tackle a wide range of file and OS-related tasks in your Python projects."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
