{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ⚙️ Python Generators: Memory-Efficient Iteration and Data Pipelines\n",
    "\n",
    "**Welcome!** This notebook explores Python Generators, a powerful and memory-efficient way to create iterators. We'll delve into how they work using the `yield` keyword, contrast them with regular functions and list comprehensions, and see how they enable lazy evaluation for handling large datasets and building elegant data processing pipelines.\n",
    "\n",
    "**Target Audience:** Python developers looking to understand iterators, generators, and lazy evaluation for writing more efficient and Pythonic code.\n",
    "\n",
    "**Learning Objectives:**\n",
    "*   Understand Python's iteration protocol (`__iter__`, `__next__`, `StopIteration`).\n",
    "*   Learn how generator functions use `yield` to create iterators.\n",
    "*   Understand the concept of lazy evaluation and its memory benefits.\n",
    "*   Create concise generators using generator expressions.\n",
    "*   Learn how to chain generators to build data pipelines.\n",
    "*   Use `yield from` to delegate iteration to sub-generators.\n",
    "*   Briefly touch upon asynchronous generators.\n",
    "*   Identify best practices and common use cases for generators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction: The Problem with Large Sequences\n",
    "\n",
    "Imagine you need to process a file containing millions of log entries, or generate a sequence of the first billion Fibonacci numbers. Storing such massive sequences entirely in memory using lists can be inefficient or even impossible due to memory constraints.\n",
    "\n",
    "**Generators provide a solution:** They allow you to define iterable sequences where items are generated **one at a time** and **only when requested**. This is known as **lazy evaluation**.\n",
    "\n",
    "**Analogy: The Streaming Service vs. Downloading Everything**\n",
    "\n",
    "*   **Lists/Tuples:** Like downloading an entire movie series Box Set before you can watch the first episode. It takes up a lot of disk space (memory) upfront.\n",
    "*   **Generators:** Like a streaming service (Netflix, YouTube). You request the next chunk of video (the next item) only when you're ready to watch it. The service generates and sends just that chunk, without needing to send the entire series at once. It's efficient for large content and you can even handle potentially infinite streams (like a live broadcast).\n",
    "\n",
    "Generators are a fundamental concept for writing memory-efficient and elegant data processing code in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The Foundation: Iterables and Iterators\n",
    "\n",
    "To understand generators, we first need to understand Python's iteration protocol.\n",
    "\n",
    "*   **Iterable:** An object capable of returning its members one at a time. Examples include lists, tuples, dictionaries, sets, strings, files, and generators. An object is iterable if it implements the `__iter__()` method, which must return an iterator.\n",
    "*   **Iterator:** An object representing a stream of data. It must implement the iterator protocol, consisting of:\n",
    "    *   `__iter__()`: Returns the iterator object itself.\n",
    "    *   `__next__()`: Returns the next item from the stream. When there are no more items, it raises the `StopIteration` exception.\n",
    "\n",
    "Python's `for` loop automatically handles this protocol: it calls `iter()` on the iterable to get an iterator, and then repeatedly calls `next()` on the iterator until `StopIteration` is caught."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is list iterable? True\n",
      "Type of iterator: <class 'list_iterator'>\n",
      "Does iterator have __iter__? True\n",
      "Does iterator have __next__? True\n",
      "\n",
      "Manual iteration:\n",
      "  Item 1: a\n",
      "  Item 2: b\n",
      "  Item 3: c\n",
      "  Caught StopIteration - iterator exhausted.\n",
      "Trying list() on exhausted iterator: []\n",
      "\n",
      "Using a for loop (on a new iterator):\n",
      "  Item: a\n",
      "  Item: b\n",
      "  Item: c\n"
     ]
    }
   ],
   "source": [
    "my_list = ['a', 'b', 'c']\n",
    "print(f\"Is list iterable? {'__iter__' in dir(my_list)}\")\n",
    "\n",
    "# Get an iterator from the list\n",
    "my_iterator = iter(my_list)\n",
    "print(f\"Type of iterator: {type(my_iterator)}\")\n",
    "print(f\"Does iterator have __iter__? {'__iter__' in dir(my_iterator)}\")\n",
    "print(f\"Does iterator have __next__? {'__next__' in dir(my_iterator)}\")\n",
    "\n",
    "# Manually iterating\n",
    "print(\"\\nManual iteration:\")\n",
    "try:\n",
    "    print(f\"  Item 1: {next(my_iterator)}\")\n",
    "    print(f\"  Item 2: {next(my_iterator)}\")\n",
    "    print(f\"  Item 3: {next(my_iterator)}\")\n",
    "    print(f\"  Item 4: {next(my_iterator)}\") # This will raise StopIteration\n",
    "except StopIteration:\n",
    "    print(\"  Caught StopIteration - iterator exhausted.\")\n",
    "\n",
    "# The iterator is now exhausted\n",
    "print(f\"Trying list() on exhausted iterator: {list(my_iterator)}\")\n",
    "\n",
    "# For loop handles this automatically\n",
    "print(\"\\nUsing a for loop (on a new iterator):\")\n",
    "for item in my_list: # Implicitly calls iter() and next()\n",
    "    print(f\"  Item: {item}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generator Functions: `yield`\n",
    "\n",
    "The easiest way to create an iterator is using a generator function. This looks like a normal function but uses the `yield` keyword to return values one at a time.\n",
    "\n",
    "*   When a generator function is called, it returns a **generator object** (which is an iterator) without executing the function body yet.\n",
    "*   When `next()` is called on the generator object for the first time, execution starts and runs until the first `yield` statement is encountered.\n",
    "*   The value specified after `yield` is returned by `next()`.\n",
    "*   The function's state (local variables, instruction pointer) is **paused** at the `yield`.\n",
    "*   On subsequent calls to `next()`, execution resumes *immediately after* the last `yield` statement, continuing until the next `yield` or the function ends.\n",
    "*   If the function finishes without hitting another `yield`, `StopIteration` is raised automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of gen_obj: <class 'generator'>\n",
      "\n",
      "--- Manual iteration with next() ---\n",
      "-> Generator function called, returning generator object.\n",
      "--> Inside generator: before yielding 0\n",
      "Received from next(): 0\n",
      "<-- Inside generator: after yielding 0\n",
      "--> Inside generator: before yielding 1\n",
      "Received from next(): 1\n",
      "<-- Inside generator: after yielding 1\n",
      "--> Inside generator: before yielding 2\n",
      "Received from next(): 2\n",
      "<-- Inside generator: after yielding 2\n",
      "-> Generator function finished.\n",
      "Caught StopIteration.\n",
      "\n",
      "--- Iteration with for loop (on a new generator object) ---\n",
      "-> Generator function called, returning generator object.\n",
      "--> Inside generator: before yielding 0\n",
      "Received in for loop: 0\n",
      "<-- Inside generator: after yielding 0\n",
      "--> Inside generator: before yielding 1\n",
      "Received in for loop: 1\n",
      "<-- Inside generator: after yielding 1\n",
      "-> Generator function finished.\n"
     ]
    }
   ],
   "source": [
    "from typing import Generator, Any\n",
    "\n",
    "def simple_generator(n: int) -> Generator[int, None, None]: # Type hint for generator\n",
    "    \"\"\"Yields numbers from 0 up to (but not including) n.\"\"\"\n",
    "    print(\"-> Generator function called, returning generator object.\")\n",
    "    i = 0\n",
    "    while i < n:\n",
    "        print(f\"--> Inside generator: before yielding {i}\")\n",
    "        yield i\n",
    "        print(f\"<-- Inside generator: after yielding {i}\")\n",
    "        i += 1\n",
    "    print(\"-> Generator function finished.\")\n",
    "    # No explicit StopIteration needed\n",
    "\n",
    "# Call the function - it returns the generator object immediately\n",
    "gen_obj = simple_generator(3)\n",
    "print(f\"Type of gen_obj: {type(gen_obj)}\")\n",
    "\n",
    "# Manually iterate using next()\n",
    "print(\"\\n--- Manual iteration with next() ---\")\n",
    "try:\n",
    "    val1 = next(gen_obj)\n",
    "    print(f\"Received from next(): {val1}\")\n",
    "    \n",
    "    val2 = next(gen_obj)\n",
    "    print(f\"Received from next(): {val2}\")\n",
    "    \n",
    "    val3 = next(gen_obj)\n",
    "    print(f\"Received from next(): {val3}\")\n",
    "    \n",
    "    val4 = next(gen_obj) # Will raise StopIteration\n",
    "    print(f\"Received from next(): {val4}\")\n",
    "except StopIteration:\n",
    "    print(\"Caught StopIteration.\")\n",
    "\n",
    "# Using a for loop (more typical)\n",
    "print(\"\\n--- Iteration with for loop (on a new generator object) ---\")\n",
    "for value in simple_generator(2):\n",
    "    print(f\"Received in for loop: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Memory Efficiency Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- List Approach ---\n",
      "Creating list with 1000000 elements...\n",
      "Size of list object: 8,000,056 bytes\n",
      "Sum of first 10 from list: 45\n",
      "\n",
      "--- Generator Approach ---\n",
      "Size of generator object: 216 bytes\n",
      "Starting generator for 1000000 elements...\n",
      "Sum of first 10 from generator: 45\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# Function returning a potentially large list\n",
    "def create_large_list(n: int) -> list:\n",
    "    print(f\"Creating list with {n} elements...\")\n",
    "    return list(range(n))\n",
    "\n",
    "# Generator function yielding elements\n",
    "def generate_large_sequence(n: int) -> Generator[int, None, None]:\n",
    "    print(f\"Starting generator for {n} elements...\")\n",
    "    for i in range(n):\n",
    "        yield i\n",
    "\n",
    "num_elements = 1_000_000 # One million\n",
    "\n",
    "# --- Using List (High Memory) --- \n",
    "print(\"--- List Approach ---\")\n",
    "large_list = create_large_list(num_elements)\n",
    "print(f\"Size of list object: {sys.getsizeof(large_list):,} bytes\")\n",
    "# Processing the list (example: summing first 10)\n",
    "list_sum_first_10 = sum(large_list[:10])\n",
    "print(f\"Sum of first 10 from list: {list_sum_first_10}\")\n",
    "# Keep large_list in memory for comparison\n",
    "\n",
    "# --- Using Generator (Low Memory) --- \n",
    "print(\"\\n--- Generator Approach ---\")\n",
    "large_gen = generate_large_sequence(num_elements)\n",
    "print(f\"Size of generator object: {sys.getsizeof(large_gen):,} bytes\") # Size is constant!\n",
    "# Processing the generator (example: summing first 10)\n",
    "gen_sum_first_10 = 0\n",
    "for i, val in enumerate(large_gen):\n",
    "    if i >= 10:\n",
    "        break # Stop consuming after 10 items\n",
    "    gen_sum_first_10 += val\n",
    "print(f\"Sum of first 10 from generator: {gen_sum_first_10}\")\n",
    "\n",
    "# The generator is partially consumed, but the full sequence was never in memory\n",
    "# If we now sum the *rest* of the generator:\n",
    "# total_sum_gen = gen_sum_first_10 + sum(large_gen) # sum() consumes the rest\n",
    "# print(f\"Total sum from generator: {total_sum_gen}\")\n",
    "\n",
    "del large_list # Free memory from the list example\n",
    "del large_gen  # Free generator object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generator Expressions\n",
    "\n",
    "Similar to list comprehensions, but create generator objects instead of lists. Use parentheses `()` instead of square brackets `[]`.\n",
    "\n",
    "**Syntax:** `(expression for item in iterable if condition)`\n",
    "\n",
    "They provide a concise way to create simple generators, often replacing simple uses of generator functions or `map`/`filter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Squares list: [0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n",
      "Type: <class 'list'>\n",
      "\n",
      "Squares generator object: <generator object <genexpr> at 0x70196d414fb0>\n",
      "Type: <class 'generator'>\n",
      "Values from squares generator: [0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n",
      "\n",
      "Even squares generator: [0, 4, 16, 36, 64]\n",
      "Sum of squares (using genexpr): 285\n"
     ]
    }
   ],
   "source": [
    "# List comprehension (creates full list)\n",
    "squares_list = [x*x for x in range(10)]\n",
    "print(f\"Squares list: {squares_list}\")\n",
    "print(f\"Type: {type(squares_list)}\")\n",
    "\n",
    "# Generator expression (creates a generator object)\n",
    "squares_gen = (x*x for x in range(10))\n",
    "print(f\"\\nSquares generator object: {squares_gen}\")\n",
    "print(f\"Type: {type(squares_gen)}\")\n",
    "\n",
    "# Iterate over the generator to get values\n",
    "print(f\"Values from squares generator: {list(squares_gen)}\")\n",
    "\n",
    "# Example with condition\n",
    "even_squares_gen = (x*x for x in range(10) if x % 2 == 0)\n",
    "print(f\"\\nEven squares generator: {list(even_squares_gen)}\")\n",
    "\n",
    "# Can be passed directly to functions that accept iterables\n",
    "total_sum_of_squares = sum(x*x for x in range(10))\n",
    "print(f\"Sum of squares (using genexpr): {total_sum_of_squares}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Advanced Generator Features\n",
    "\n",
    "### 5.1 `yield from`: Delegating to Sub-Generators (Python 3.3+)\n",
    "\n",
    "Allows a generator to delegate part of its operations to another generator (or any iterable), avoiding the need for an explicit inner loop.\n",
    "\n",
    "**Syntax:** `yield from other_iterable`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Using yield from ---\n",
      "Main generator starting\n",
      "Main generator finished\n",
      "Combined results: ['A', 'B', '---', 1, 2, 0, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "from typing import Iterable, TypeVar, Generator\n",
    "\n",
    "T = TypeVar('T')\n",
    "\n",
    "def sub_generator_letters() -> Generator[str, None, None]:\n",
    "    yield 'A'\n",
    "    yield 'B'\n",
    "\n",
    "def sub_generator_numbers() -> Generator[int, None, None]:\n",
    "    yield 1\n",
    "    yield 2\n",
    "\n",
    "def main_generator() -> Generator[Any, None, None]:\n",
    "    print(\"Main generator starting\")\n",
    "    # Without yield from:\n",
    "    # for letter in sub_generator_letters():\n",
    "    #     yield letter\n",
    "    # for number in sub_generator_numbers():\n",
    "    #     yield number\n",
    "    \n",
    "    # With yield from (cleaner):\n",
    "    yield from sub_generator_letters() \n",
    "    yield \"---\" # Can yield other values in between\n",
    "    yield from sub_generator_numbers()\n",
    "    yield from range(3) # Can yield from any iterable\n",
    "    print(\"Main generator finished\")\n",
    "\n",
    "print(\"--- Using yield from ---\")\n",
    "combined_gen = main_generator()\n",
    "print(f\"Combined results: {list(combined_gen)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Sending Values into Generators (`.send()`)\n",
    "\n",
    "Generators can also *receive* values using the `send()` method. The `yield` expression itself evaluates to the value sent.\n",
    "This turns generators into a form of **coroutine** (though Python's `async/await` is the modern way for explicit asynchronous programming)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Receiver starting...\n",
      "Initial yield from receiver: 'Ready to receive (last was: None)'\n",
      "--> Receiver got: 'Hello'\n",
      "Yield after send('Hello'): 'Ready to receive (last was: Hello)'\n",
      "--> Receiver got: 123\n",
      "Yield after send(123): 'Ready to receive (last was: 123)'\n",
      "--> Receiver got: 'stop'\n",
      "Receiver stopping.\n",
      "Receiver finished after 'stop'.\n",
      "Receiver starting...\n",
      "Receiver closing gracefully.\n"
     ]
    }
   ],
   "source": [
    "from typing import Generator, Optional, Any\n",
    "\n",
    "def receiver_generator() -> Generator[str, str, None]: # Yields str, Receives str, Returns None\n",
    "    print(\"Receiver starting...\")\n",
    "    received_value = None\n",
    "    while True:\n",
    "        try:\n",
    "            # Yield a value, and pause here to potentially receive a sent value\n",
    "            received_value = yield f\"Ready to receive (last was: {received_value})\"\n",
    "            print(f\"--> Receiver got: {received_value!r}\")\n",
    "            if received_value == 'stop':\n",
    "                print(\"Receiver stopping.\")\n",
    "                break\n",
    "        except GeneratorExit:\n",
    "            print(\"Receiver closing gracefully.\")\n",
    "            raise # Must re-raise GeneratorExit\n",
    "        except Exception as e:\n",
    "            print(f\"Receiver caught exception: {e}\")\n",
    "\n",
    "recv_gen = receiver_generator()\n",
    "\n",
    "# Must call next() first to advance to the first yield\n",
    "initial_yield = next(recv_gen)\n",
    "print(f\"Initial yield from receiver: {initial_yield!r}\")\n",
    "\n",
    "# Send values into the generator\n",
    "yield1 = recv_gen.send(\"Hello\")\n",
    "print(f\"Yield after send('Hello'): {yield1!r}\")\n",
    "\n",
    "yield2 = recv_gen.send(123)\n",
    "print(f\"Yield after send(123): {yield2!r}\")\n",
    "\n",
    "# Stop the generator by sending a specific value\n",
    "try:\n",
    "    recv_gen.send('stop')\n",
    "except StopIteration:\n",
    "    print(\"Receiver finished after 'stop'.\")\n",
    "\n",
    "# Closing a generator\n",
    "recv_gen_close = receiver_generator()\n",
    "next(recv_gen_close) # Start it\n",
    "recv_gen_close.close() # Raises GeneratorExit inside the generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Asynchronous Generators (`async def` with `yield` - Python 3.6+)\n",
    "\n",
    "Used with `asyncio` to create iterators that can pause during `await` calls, allowing other asynchronous tasks to run. Consumed using `async for`.\n",
    "\n",
    "**(Note:** Requires an `asyncio` event loop to run. We won't run a full example here, but show the structure.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Async example structure shown, not executed in this notebook)\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from typing import AsyncGenerator\n",
    "\n",
    "async def async_data_fetcher(urls: list) -> AsyncGenerator[str, None]:\n",
    "    \"\"\"Example async generator (conceptual).\"\"\"\n",
    "    print(\"Starting async fetcher...\")\n",
    "    for url in urls:\n",
    "        print(f\"  Fetching {url}...\")\n",
    "        # Simulate an async network request\n",
    "        await asyncio.sleep(0.5) \n",
    "        result = f\"Data from {url}\"\n",
    "        yield result # Yield data as it becomes available\n",
    "    print(\"Async fetcher finished.\")\n",
    "\n",
    "async def main_async():\n",
    "    urls_to_fetch = [\"http://example.com/1\", \"http://example.com/2\", \"http://example.com/3\"]\n",
    "    \n",
    "    print(\"Iterating over async generator:\")\n",
    "    # Use 'async for' to consume an async generator\n",
    "    async for data in async_data_fetcher(urls_to_fetch):\n",
    "        print(f\"  Received async data: {data}\")\n",
    "\n",
    "# To run this, you would typically use:\n",
    "# asyncio.run(main_async())\n",
    "print(\"(Async example structure shown, not executed in this notebook)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. The `itertools` Module: Iteration Power Tools\n",
    "\n",
    "This module (covered briefly before) provides building blocks for creating complex iterator logic. It's highly relevant to functional programming and generator usage.\n",
    "\n",
    "**Examples Revisited:** `chain`, `islice`, `combinations`, `permutations`, `cycle`, `repeat`, `count`, `accumulate`, `groupby`, `takewhile`, `dropwhile`, `zip_longest`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Grouping Consecutive Numbers --- \n",
      "  Run found: [1, 2, 3]\n",
      "  Run found: [5, 6]\n",
      "  Run found: [8, 9, 10]\n",
      "\n",
      "--- zip_longest Example ---\n",
      "[('a', 1), ('b', 2), ('c', None)]\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "# Example: Find runs of consecutive numbers\n",
    "data = [1, 2, 3, 5, 6, 8, 9, 10]\n",
    "\n",
    "# groupby groups consecutive items based on a key function\n",
    "# Here, key = value - index. This key is constant for consecutive numbers.\n",
    "print(\"--- Grouping Consecutive Numbers --- \")\n",
    "for k, g in itertools.groupby(enumerate(data), lambda item: item[1] - item[0]):\n",
    "    run = [item[1] for item in g] # Extract values from the group\n",
    "    print(f\"  Run found: {run}\")\n",
    "\n",
    "# Example: Create pairs from two lists, padding shorter one\n",
    "keys = ['a', 'b', 'c']\n",
    "values = [1, 2]\n",
    "paired = itertools.zip_longest(keys, values, fillvalue=None)\n",
    "print(\"\\n--- zip_longest Example ---\")\n",
    "print(list(paired))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Best Practices & Enterprise Considerations\n",
    "\n",
    "1.  **Use Generators for Large/Infinite Sequences:** Prefer generators or generator expressions over lists when dealing with potentially large amounts of data to conserve memory.\n",
    "2.  **Favor Generator Expressions for Simplicity:** For straightforward map/filter operations without complex logic, generator expressions are often the most concise and Pythonic.\n",
    "3.  **Readability is Key:** While generators can be powerful, ensure the logic remains understandable. A slightly more verbose `for` loop might be better than an overly complex generator expression.\n",
    "4.  **Iterators are Single-Pass:** Remember that standard iterators (including generators) can only be consumed once. If you need to iterate multiple times, either convert to a list/tuple first (if memory allows) or regenerate the iterator.\n",
    "5.  **Chaining:** Build complex data processing pipelines by chaining generators together. This remains memory-efficient as data flows through the pipeline item by item.\n",
    "6.  **Error Handling:** Include `try...except` blocks within your generator functions if individual items might cause errors during generation, allowing the generator to continue if appropriate.\n",
    "7.  **Resource Management:** If your generator function opens resources (like files), ensure they are closed properly, potentially using a `try...finally` block or a context manager *inside* the generator function.\n",
    "8.  **`yield from`:** Use `yield from` to simplify code when delegating iteration to another iterable within a generator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Pitfalls and Common Interview Questions\n",
    "\n",
    "**Common Pitfalls:**\n",
    "\n",
    "*   **Treating Generators like Lists:** Trying to index (`gen[0]`) or get the length (`len(gen)`) of a generator directly (doesn't work without consuming it into a list).\n",
    "*   **Forgetting Iterators are Single-Pass:** Trying to loop over the same generator object multiple times.\n",
    "*   **Memory Issues with Intermediate Lists:** Converting large generators to lists unnecessarily (e.g., `list(map(...))` when the result will just be iterated over anyway).\n",
    "*   **Unintended Side Effects in Generators:** Performing actions with side effects within a generator might lead to unexpected behavior due to lazy evaluation (the side effect only happens when that `yield` is reached).\n",
    "*   **Blocking Generators:** Performing long-running synchronous operations inside a generator can block consumption (especially relevant in async contexts).\n",
    "\n",
    "**Common Interview Questions:**\n",
    "\n",
    "1.  What is the difference between an iterable and an iterator in Python?\n",
    "2.  How does a generator function differ from a regular function? What does `yield` do?\n",
    "3.  What are the main advantages of using generators?\n",
    "4.  What is a generator expression? How does its syntax differ from a list comprehension?\n",
    "5.  Can you iterate over a generator multiple times? Why or why not?\n",
    "6.  Give an example of where using a generator would be more memory-efficient than using a list.\n",
    "7.  What does `yield from` do?\n",
    "8.  (Advanced) Can you send values *into* a generator? How? (`send()`)\n",
    "9.  How do generators relate to lazy evaluation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Challenge: Streaming CSV Reader\n",
    "\n",
    "**Goal:** Create a generator function that reads a potentially large CSV file row by row, yielding each row as a dictionary, without loading the entire file into memory.\n",
    "\n",
    "**Tasks:**\n",
    "\n",
    "1.  **Create Sample CSV:** Create a sample CSV file (`sensor_data.csv`) with headers and a few rows (or many rows to simulate size):\n",
    "    ```csv\n",
    "    Timestamp,SensorID,Temperature,Humidity\n",
    "    2023-11-01T10:00:00Z,SensorA,22.5,45.1\n",
    "    2023-11-01T10:01:00Z,SensorB,21.8,46.5\n",
    "    2023-11-01T10:02:00Z,SensorA,22.6,45.2\n",
    "    INVALID LINE\n",
    "    2023-11-01T10:03:00Z,SensorC,23.1,44.9\n",
    "    2023-11-01T10:04:00Z,SensorB,21.9,46.8\n",
    "    ```\n",
    "2.  **Write Generator Function:** Create a function `read_csv_as_dicts(filepath: Path) -> Generator[Dict[str, str], None, None]`:\n",
    "    *   It should take the file path (`pathlib.Path` object) as input.\n",
    "    *   Open the file using `with open(...)`.\n",
    "    *   Read the header row separately.\n",
    "    *   For each subsequent row:\n",
    "        *   Split the row into fields (handle potential errors like incorrect number of fields).\n",
    "        *   Create a dictionary mapping header names to field values for that row.\n",
    "        *   `yield` the dictionary.\n",
    "    *   Include basic error handling (e.g., `FileNotFoundError`, skipping lines with wrong field count with a log message).\n",
    "3.  **Test:**\n",
    "    *   Call your generator function.\n",
    "    *   Iterate through the resulting generator object using a `for` loop.\n",
    "    *   Print each dictionary (row) received.\n",
    "    *   (Optional) Process only the first few rows to demonstrate lazy evaluation.\n",
    "\n",
    "**(Bonus):** Modify the generator to optionally attempt type conversion (e.g., float for Temperature/Humidity) within a `try...except ValueError` block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created sample CSV file: sensor_data.csv\n",
      "INFO: CSV Headers: ['Timestamp', 'SensorID', 'Temperature', 'Humidity']\n",
      "WARNING: Line 5: Skipping row. Expected 4 fields, got 2. Row: ['INVALID LINE', ' only one field']\n",
      "WARNING: Line 7: Skipping row. Expected 4 fields, got 5. Row: ['2023-11-01T10:04:00Z', 'SensorB', '21.9', '46.8', 'extra_field']\n",
      "INFO: CSV Headers: ['Timestamp', 'SensorID', 'Temperature', 'Humidity']\n",
      "WARNING: Line 5: Skipping row. Expected 4 fields, got 2. Row: ['INVALID LINE', ' only one field']\n",
      "WARNING: Line 7: Skipping row. Expected 4 fields, got 5. Row: ['2023-11-01T10:04:00Z', 'SensorB', '21.9', '46.8', 'extra_field']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing CSV Generator (Raw Strings) ---\n",
      "  Row 1: {'Timestamp': '2023-11-01T10:00:00Z', 'SensorID': 'SensorA', 'Temperature': '22.5', 'Humidity': '45.1'}\n",
      "  Row 2: {'Timestamp': '2023-11-01T10:01:00Z', 'SensorID': 'SensorB', 'Temperature': '21.8', 'Humidity': '46.5'}\n",
      "  Row 3: {'Timestamp': '2023-11-01T10:02:00Z', 'SensorID': 'SensorA', 'Temperature': '22.6', 'Humidity': '45.2'}\n",
      "  (Stopping early to demonstrate lazy evaluation)\n",
      "  Row 4: {'Timestamp': '2023-11-01T10:03:00Z', 'SensorID': 'SensorC', 'Temperature': '23.1', 'Humidity': '44.9'}\n",
      "\n",
      "--- Testing CSV Generator (with Type Conversion) ---\n",
      "  Conv Row 1: {'Timestamp': '2023-11-01T10:00:00Z', 'SensorID': 'SensorA', 'Temperature': 22.5, 'Humidity': 45.1} (Temp Type: <class 'float'>)\n",
      "  Conv Row 2: {'Timestamp': '2023-11-01T10:01:00Z', 'SensorID': 'SensorB', 'Temperature': 21.8, 'Humidity': 46.5} (Temp Type: <class 'float'>)\n",
      "  Conv Row 3: {'Timestamp': '2023-11-01T10:02:00Z', 'SensorID': 'SensorA', 'Temperature': 22.6, 'Humidity': 45.2} (Temp Type: <class 'float'>)\n",
      "  Conv Row 4: {'Timestamp': '2023-11-01T10:03:00Z', 'SensorID': 'SensorC', 'Temperature': 23.1, 'Humidity': 44.9} (Temp Type: <class 'float'>)\n"
     ]
    }
   ],
   "source": [
    "# --- Solution Space for Challenge ---\n",
    "import csv # Can use csv module for more robust parsing!\n",
    "from pathlib import Path\n",
    "from typing import Generator, Dict, List, Optional, Union\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s', force=True)\n",
    "\n",
    "# 1. Create Sample CSV\n",
    "csv_content = \"\"\"\n",
    "Timestamp,SensorID,Temperature,Humidity\n",
    "2023-11-01T10:00:00Z,SensorA,22.5,45.1\n",
    "2023-11-01T10:01:00Z,SensorB,21.8,46.5\n",
    "2023-11-01T10:02:00Z,SensorA,22.6,45.2\n",
    "INVALID LINE, only one field\n",
    "2023-11-01T10:03:00Z,SensorC,23.1,44.9\n",
    "2023-11-01T10:04:00Z,SensorB,21.9,46.8,extra_field\n",
    "\"\"\"\n",
    "csv_filepath = Path(\"sensor_data.csv\")\n",
    "try:\n",
    "    csv_filepath.write_text(csv_content.strip(), encoding='utf-8')\n",
    "    logging.info(f\"Created sample CSV file: {csv_filepath}\")\n",
    "except IOError as e:\n",
    "    logging.error(f\"Failed to write CSV file: {e}\")\n",
    "    exit()\n",
    "\n",
    "# 2. Write Generator Function (using csv module for robustness)\n",
    "def read_csv_as_dicts(filepath: Path, delimiter: str = ',') -> Generator[Dict[str, str], None, None]:\n",
    "    \"\"\"Reads a CSV file line by line, yielding each row as a dictionary.\"\"\"\n",
    "    try:\n",
    "        with filepath.open('r', encoding='utf-8', newline='') as f:\n",
    "            # Use csv.reader for robust parsing\n",
    "            reader = csv.reader(f, delimiter=delimiter)\n",
    "            try:\n",
    "                header = next(reader) # Read header row\n",
    "                logging.info(f\"CSV Headers: {header}\")\n",
    "                num_headers = len(header)\n",
    "                \n",
    "                for i, row_list in enumerate(reader, 2): # Start line count from 2\n",
    "                    if len(row_list) != num_headers:\n",
    "                        logging.warning(f\"Line {i}: Skipping row. Expected {num_headers} fields, got {len(row_list)}. Row: {row_list}\")\n",
    "                        continue # Skip malformed row\n",
    "                    \n",
    "                    # Create dictionary using zip\n",
    "                    row_dict = dict(zip(header, row_list))\n",
    "                    yield row_dict # Yield the dictionary for this row\n",
    "                    \n",
    "            except StopIteration:\n",
    "                logging.warning(f\"CSV file '{filepath}' is empty or has only a header.\")\n",
    "            except csv.Error as csv_e:\n",
    "                 logging.error(f\"CSV parsing error in '{filepath}' near line {reader.line_num}: {csv_e}\")\n",
    "                 # Could choose to stop or continue here\n",
    "                 \n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"File not found: {filepath}\")\n",
    "        # Optionally raise an error here if needed\n",
    "        # raise\n",
    "    except IOError as e:\n",
    "        logging.error(f\"IOError reading file {filepath}: {e}\")\n",
    "    except Exception as e:\n",
    "         logging.exception(f\"Unexpected error reading CSV {filepath}: {e}\")\n",
    "\n",
    "# Bonus: Generator with Type Conversion\n",
    "def read_csv_converted(filepath: Path, delimiter: str = ',') -> Generator[Dict[str, Any], None, None]:\n",
    "     for row_dict in read_csv_as_dicts(filepath, delimiter):\n",
    "         converted_row = row_dict.copy() # Work on a copy\n",
    "         try:\n",
    "            # Attempt conversions - add more as needed\n",
    "            if 'Temperature' in converted_row:\n",
    "                converted_row['Temperature'] = float(converted_row['Temperature'])\n",
    "            if 'Humidity' in converted_row:\n",
    "                 converted_row['Humidity'] = float(converted_row['Humidity'])\n",
    "            # Could add datetime parsing for 'Timestamp' here too\n",
    "            yield converted_row\n",
    "         except (ValueError, TypeError) as conv_e:\n",
    "             logging.warning(f\"Could not convert types for row: {row_dict}. Error: {conv_e}\")\n",
    "             # Decide whether to yield original row, None, or skip\n",
    "             # yield row_dict # Yield original if conversion fails\n",
    "             continue # Skip row if conversion fails\n",
    "\n",
    "# 3. Test\n",
    "print(\"\\n--- Testing CSV Generator (Raw Strings) ---\")\n",
    "row_count = 0\n",
    "csv_gen = read_csv_as_dicts(csv_filepath)\n",
    "for row in csv_gen:\n",
    "    row_count += 1\n",
    "    print(f\"  Row {row_count}: {row}\")\n",
    "    if row_count == 3:\n",
    "         print(\"  (Stopping early to demonstrate lazy evaluation)\")\n",
    "         # break # Uncomment to stop early\n",
    "\n",
    "print(\"\\n--- Testing CSV Generator (with Type Conversion) ---\")\n",
    "row_count_conv = 0\n",
    "csv_gen_conv = read_csv_converted(csv_filepath)\n",
    "for row_conv in csv_gen_conv:\n",
    "     row_count_conv += 1\n",
    "     print(f\"  Conv Row {row_count_conv}: {row_conv} (Temp Type: {type(row_conv.get('Temperature'))})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Conclusion\n",
    "\n",
    "Generators are a cornerstone of efficient and elegant Python programming, particularly when dealing with iteration and data processing. By embracing lazy evaluation through generator functions (`yield`) and generator expressions (`(...)`), you can significantly reduce memory consumption, handle potentially infinite sequences, and build clean, composable data pipelines.\n",
    "\n",
    "Understanding the underlying iterator protocol provides a solid foundation, while tools like `yield from` and the `itertools` module offer further power and conciseness. When combined with functional concepts, generators enable a highly effective style for tackling many common programming challenges in Python."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
