{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ§µ Mastering Threading in Python: Concurrency for I/O-Bound Tasks\n",
    "\n",
    "**Welcome!** This notebook focuses on Python's `threading` module, a fundamental tool for achieving concurrency (handling multiple tasks seemingly simultaneously) within a single process. We'll explore how to create and manage threads, the critical importance of synchronization for shared data, and modern approaches using `concurrent.futures`.\n",
    "\n",
    "**Target Audience:** Python developers needing to improve the responsiveness of applications involving I/O operations (like network requests, file access, GUIs) or manage concurrent workflows.\n",
    "\n",
    "**Learning Objectives:**\n",
    "*   Create, start, and manage `Thread` objects.\n",
    "*   Understand the concept of shared memory between threads and its implications (race conditions).\n",
    "*   Implement thread synchronization using `Lock`, `RLock`, `Event`, `Semaphore`, `Condition`.\n",
    "*   Use `queue.Queue` for thread-safe communication and task distribution.\n",
    "*   Understand daemon threads and their lifecycle.\n",
    "*   Utilize the high-level `concurrent.futures.ThreadPoolExecutor` for simplified thread pool management.\n",
    "*   Learn best practices for thread safety, resource management, and debugging.\n",
    "*   Identify common pitfalls like race conditions and deadlocks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction: Why Use Threading?\n",
    "\n",
    "As discussed in the comparison notebook, threading allows a single process to manage multiple execution contexts (threads) that share the same memory space.\n",
    "\n",
    "**Key Use Case: I/O-Bound Tasks**\n",
    "The primary benefit of threading in CPython (due to the GIL) is improving performance and responsiveness for **I/O-bound** tasks. When a thread makes a blocking I/O call (e.g., waiting for a network response, reading a large file), it releases the GIL, allowing other threads to run Python code or perform their own I/O. This prevents the entire application from freezing while waiting.\n",
    "\n",
    "**Analogy: The Efficient Waiter**\n",
    "Imagine a waiter (your program) serving multiple tables (tasks). \n",
    "*   **Without Threading:** The waiter takes an order from Table 1, goes to the kitchen, waits for the food, delivers it, takes the order from Table 2, waits, delivers, etc. Tables wait idly while the waiter is busy with *one* specific task (especially waiting).\n",
    "*   **With Threading:** The waiter (main thread) can delegate tasks. One helper thread takes Table 1's order and goes to the kitchen. While waiting, the main waiter (or another thread) can take Table 2's order. Another thread might be waiting to deliver food. They coordinate (synchronization) but make progress on multiple tables concurrently, even if only one *chef* (CPU core executing Python) is active at a time due to the GIL. The overall throughput and responsiveness improve because waiting time is utilized effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating and Managing Threads (`threading.Thread`)\n",
    "\n",
    "The basic way to create a thread is using the `threading.Thread` class.\n",
    "\n",
    "**Steps:**\n",
    "1.  Define a target function that the thread will execute.\n",
    "2.  Create a `Thread` instance, passing the `target` function and any arguments (`args` tuple or `kwargs` dict).\n",
    "3.  Call the `start()` method on the `Thread` object. This invokes the target function in a new thread of control.\n",
    "4.  Optionally, call the `join()` method on the `Thread` object. This makes the main thread (or calling thread) wait until the target thread finishes execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] (MainThread) Main thread starting.\n",
      "[INFO] (MainThread) Starting threads...\n",
      "[INFO] (Worker-A  ) Starting task 1...\n",
      "[INFO] (Worker-B  ) Starting task 2...\n",
      "[INFO] (MainThread) Threads started.\n",
      "[INFO] (MainThread) Waiting for threads to join...\n",
      "[INFO] (Worker-B  ) Finished task 2.\n",
      "[INFO] (Worker-A  ) Finished task 1.\n",
      "[INFO] (MainThread) All threads finished.\n",
      "[INFO] (MainThread) Main thread finished.\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, \n",
    "                    format='[%(levelname)s] (%(threadName)-10s) %(message)s',\n",
    "                    force=True)\n",
    "\n",
    "def worker_task(task_id: int, duration: float):\n",
    "    \"\"\"Simulates a task performed by a thread.\"\"\"\n",
    "    thread_name = threading.current_thread().name\n",
    "    logging.info(f\"Starting task {task_id}...\")\n",
    "    time.sleep(duration)\n",
    "    logging.info(f\"Finished task {task_id}.\")\n",
    "\n",
    "# --- Main Thread --- \n",
    "logging.info(\"Main thread starting.\")\n",
    "\n",
    "# Create thread objects\n",
    "thread1 = threading.Thread(target=worker_task, args=(1, 1.5), name=\"Worker-A\")\n",
    "thread2 = threading.Thread(target=worker_task, args=(2, 0.5), name=\"Worker-B\")\n",
    "\n",
    "# Start the threads\n",
    "logging.info(\"Starting threads...\")\n",
    "thread1.start()\n",
    "thread2.start()\n",
    "logging.info(\"Threads started.\")\n",
    "\n",
    "# Wait for threads to complete (optional but often needed)\n",
    "logging.info(\"Waiting for threads to join...\")\n",
    "thread1.join()\n",
    "thread2.join()\n",
    "logging.info(\"All threads finished.\")\n",
    "\n",
    "logging.info(\"Main thread finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Shared Data and Race Conditions\n",
    "\n",
    "**The Challenge:** Threads within the same process share memory. While convenient for communication, this is also the biggest source of complexity and bugs in threaded applications.\n",
    "\n",
    "**Race Condition:** Occurs when multiple threads access and manipulate shared data concurrently, and the final result depends on the unpredictable order (timing) in which their operations are interleaved by the scheduler.\n",
    "\n",
    "**Example:** Incrementing a shared counter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Demonstrating Race Condition ---\n",
      "Expected Counter Value: 200000\n",
      "Actual Counter Value:   200000\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "SHARED_COUNTER = 0\n",
    "NUM_ITERATIONS = 100000 # Enough iterations to likely see the race condition\n",
    "\n",
    "def increment_counter_unsafe():\n",
    "    global SHARED_COUNTER\n",
    "    for _ in range(NUM_ITERATIONS):\n",
    "        # --- This sequence is NOT atomic --- \n",
    "        current_value = SHARED_COUNTER  # 1. Read\n",
    "        # Context switch could happen here!\n",
    "        current_value += 1            # 2. Increment local copy\n",
    "        # Context switch could happen here!\n",
    "        SHARED_COUNTER = current_value  # 3. Write back\n",
    "        # ------------------------------------\n",
    "\n",
    "print(\"--- Demonstrating Race Condition ---\")\n",
    "t1 = threading.Thread(target=increment_counter_unsafe)\n",
    "t2 = threading.Thread(target=increment_counter_unsafe)\n",
    "\n",
    "t1.start()\n",
    "t2.start()\n",
    "\n",
    "t1.join()\n",
    "t2.join()\n",
    "\n",
    "expected_value = 2 * NUM_ITERATIONS\n",
    "print(f\"Expected Counter Value: {expected_value}\")\n",
    "print(f\"Actual Counter Value:   {SHARED_COUNTER}\") # Likely less than expected!\n",
    "\n",
    "# Why? Both threads might read the *same* value, increment their local copy,\n",
    "# and then both write back the *same* incremented value, losing one increment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Synchronization Primitives\n",
    "\n",
    "To prevent race conditions and coordinate threads, Python's `threading` module provides several synchronization primitives.\n",
    "\n",
    "### 4.1 `threading.Lock`: Mutual Exclusion\n",
    "*   The most basic synchronization primitive.\n",
    "*   Has two states: locked and unlocked.\n",
    "*   `lock.acquire(blocking=True, timeout=-1)`: Acquires the lock. \n",
    "    *   If unlocked, it locks it and returns `True` immediately.\n",
    "    *   If locked, it *blocks* until the lock is released (if `blocking=True`).\n",
    "    *   If `blocking=False`, it returns `True` if acquired, `False` otherwise (doesn't block).\n",
    "    *   `timeout` specifies max seconds to block.\n",
    "*   `lock.release()`: Releases the lock. Raises `RuntimeError` if called on an unlocked lock or by a different thread than the one holding it.\n",
    "*   **Best Practice:** Use a `Lock` as a context manager (`with lock:`) to ensure it's always released, even if errors occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Fixing Race Condition with Lock --- \n",
      "Expected Counter Value: 200000\n",
      "Actual Counter Value:   200000\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "SHARED_COUNTER_LOCKED = 0\n",
    "# NUM_ITERATIONS defined previously\n",
    "\n",
    "# Create a lock object\n",
    "counter_lock = threading.Lock()\n",
    "\n",
    "def increment_counter_safe():\n",
    "    global SHARED_COUNTER_LOCKED\n",
    "    for _ in range(NUM_ITERATIONS):\n",
    "        # Acquire the lock before accessing shared resource\n",
    "        # --- Manual Acquire/Release (less safe) --- \n",
    "        # counter_lock.acquire()\n",
    "        # try:\n",
    "        #     current_value = SHARED_COUNTER_LOCKED\n",
    "        #     current_value += 1\n",
    "        #     SHARED_COUNTER_LOCKED = current_value\n",
    "        # finally:\n",
    "        #     counter_lock.release() # CRITICAL to release!\n",
    "        \n",
    "        # --- Using Lock as Context Manager (Recommended) --- \n",
    "        with counter_lock:\n",
    "            current_value = SHARED_COUNTER_LOCKED\n",
    "            current_value += 1\n",
    "            SHARED_COUNTER_LOCKED = current_value\n",
    "        # Lock is automatically released upon exiting the 'with' block\n",
    "\n",
    "print(\"\\n--- Fixing Race Condition with Lock --- \")\n",
    "t3 = threading.Thread(target=increment_counter_safe)\n",
    "t4 = threading.Thread(target=increment_counter_safe)\n",
    "\n",
    "t3.start()\n",
    "t4.start()\n",
    "\n",
    "t3.join()\n",
    "t4.join()\n",
    "\n",
    "expected_value = 2 * NUM_ITERATIONS\n",
    "print(f\"Expected Counter Value: {expected_value}\")\n",
    "print(f\"Actual Counter Value:   {SHARED_COUNTER_LOCKED}\") # Should now be correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 `threading.RLock`: Re-entrant Lock\n",
    "*   A lock that can be acquired multiple times *by the same thread*.\n",
    "*   It maintains an internal counter, incremented on `acquire()` and decremented on `release()` by the owning thread.\n",
    "*   The lock is only fully released (and available to other threads) when the counter reaches zero.\n",
    "*   Useful in recursive functions or complex scenarios where a thread might need to re-acquire a lock it already holds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- RLock Demonstration ---\n",
      "(Thread-7 (recursive_function)) Acquiring RLock (depth 3)...\n",
      "(Thread-7 (recursive_function)) Acquired RLock (depth 3). Owning thread can re-acquire.\n",
      "(Thread-7 (recursive_function)) Acquiring RLock (depth 2)...\n",
      "(Thread-7 (recursive_function)) Acquired RLock (depth 2). Owning thread can re-acquire.\n",
      "(Thread-7 (recursive_function)) Acquiring RLock (depth 1)...\n",
      "(Thread-7 (recursive_function)) Acquired RLock (depth 1). Owning thread can re-acquire.\n",
      "(Thread-7 (recursive_function)) Base case reached.\n",
      "(Thread-7 (recursive_function)) Released RLock (depth 1).\n",
      "(Thread-7 (recursive_function)) Released RLock (depth 2).\n",
      "(Thread-7 (recursive_function)) Released RLock (depth 3).\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "\n",
    "r_lock = threading.RLock()\n",
    "\n",
    "def recursive_function(depth):\n",
    "    if depth <= 0:\n",
    "        print(f\"({threading.current_thread().name}) Base case reached.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"({threading.current_thread().name}) Acquiring RLock (depth {depth})...\")\n",
    "    with r_lock:\n",
    "        print(f\"({threading.current_thread().name}) Acquired RLock (depth {depth}). Owning thread can re-acquire.\")\n",
    "        # Call recursively - the same thread can acquire the RLock again\n",
    "        recursive_function(depth - 1)\n",
    "    print(f\"({threading.current_thread().name}) Released RLock (depth {depth}).\")\n",
    "\n",
    "print(\"\\n--- RLock Demonstration ---\")\n",
    "r_thread = threading.Thread(target=recursive_function, args=(3,))\n",
    "r_thread.start()\n",
    "r_thread.join()\n",
    "\n",
    "# Note: If a regular Lock were used above, the second acquire() call \n",
    "# within the same thread would block indefinitely, causing a deadlock."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 `threading.Semaphore`: Bounded Resource Access\n",
    "*   Manages an internal counter which is decremented by `acquire()` and incremented by `release()`.\n",
    "*   The counter represents the number of available resources or allowed concurrent accesses.\n",
    "*   If the counter is zero on `acquire()`, the call blocks until another thread calls `release()`.\n",
    "*   Useful for limiting access to a resource with a fixed capacity (e.g., limiting concurrent downloads, database connections)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Semaphore Demonstration (Max 3 concurrent) ---\n",
      "Thread 1: Trying to acquire semaphore...\n",
      "Thread 1: Acquired semaphore. Accessing resource...\n",
      "Thread 2: Trying to acquire semaphore...\n",
      "Thread 2: Acquired semaphore. Accessing resource...\n",
      "Thread 3: Trying to acquire semaphore...\n",
      "Thread 3: Acquired semaphore. Accessing resource...\n",
      "Thread 4: Trying to acquire semaphore...\n",
      "Thread 5: Trying to acquire semaphore...\n",
      "Thread 6: Trying to acquire semaphore...\n",
      "Thread 7: Trying to acquire semaphore...\n",
      "Thread 3: Releasing semaphore.\n",
      "Thread 4: Acquired semaphore. Accessing resource...\n",
      "Thread 2: Releasing semaphore.\n",
      "Thread 5: Acquired semaphore. Accessing resource...\n",
      "Thread 1: Releasing semaphore.\n",
      "Thread 6: Acquired semaphore. Accessing resource...\n",
      "Thread 5: Releasing semaphore.\n",
      "Thread 7: Acquired semaphore. Accessing resource...\n",
      "Thread 4: Releasing semaphore.\n",
      "Thread 6: Releasing semaphore.\n",
      "Thread 7: Releasing semaphore.\n",
      "Semaphore demo finished.\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "import random\n",
    "\n",
    "# Limit concurrent access to a resource to 3 threads\n",
    "MAX_CONNECTIONS = 3\n",
    "semaphore = threading.Semaphore(value=MAX_CONNECTIONS)\n",
    "\n",
    "def access_resource(thread_id):\n",
    "    print(f\"Thread {thread_id}: Trying to acquire semaphore...\")\n",
    "    with semaphore: # Acquire semaphore (blocks if count is 0)\n",
    "        print(f\"Thread {thread_id}: Acquired semaphore. Accessing resource...\")\n",
    "        # Simulate using the resource\n",
    "        time.sleep(random.uniform(0.5, 1.5))\n",
    "        print(f\"Thread {thread_id}: Releasing semaphore.\")\n",
    "    # Semaphore released automatically by 'with' statement\n",
    "\n",
    "print(\"\\n--- Semaphore Demonstration (Max 3 concurrent) ---\")\n",
    "threads = []\n",
    "for i in range(7): # Create 7 threads trying to access the resource\n",
    "    t = threading.Thread(target=access_resource, args=(i+1,))\n",
    "    threads.append(t)\n",
    "    t.start()\n",
    "\n",
    "# Wait for all threads to complete\n",
    "for t in threads:\n",
    "    t.join()\n",
    "\n",
    "print(\"Semaphore demo finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 `threading.Event`: Signaling Between Threads\n",
    "*   A simple mechanism for one thread to signal an event to other threads.\n",
    "*   Manages an internal flag.\n",
    "*   `event.set()`: Sets the internal flag to `True`.\n",
    "*   `event.clear()`: Resets the internal flag to `False`.\n",
    "*   `event.wait(timeout=None)`: Blocks until the internal flag is `True`. If `timeout` is set, blocks for at most that many seconds.\n",
    "*   `event.is_set()`: Returns `True` if the internal flag is set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Event Demonstration ---\n",
      "Waiter-1: Waiting for event to be set...\n",
      "Waiter-2: Waiting for event to be set...\n",
      "Setter: Sleeping for 1.0 seconds...\n",
      "Setter: Setting the event!\n",
      "Waiter-2: Event received! Proceeding.\n",
      "Waiter-1: Event received! Proceeding.\n",
      "Waiter-2: Finished work.\n",
      "Waiter-1: Finished work.\n",
      "Event demo finished.\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "event = threading.Event()\n",
    "\n",
    "def waiter(event_obj: threading.Event, name: str):\n",
    "    print(f\"{name}: Waiting for event to be set...\")\n",
    "    event_obj.wait() # Blocks here until event.set() is called\n",
    "    print(f\"{name}: Event received! Proceeding.\")\n",
    "    # Do work after event\n",
    "    time.sleep(0.1)\n",
    "    print(f\"{name}: Finished work.\")\n",
    "\n",
    "def setter(event_obj: threading.Event, delay: float):\n",
    "    print(f\"Setter: Sleeping for {delay} seconds...\")\n",
    "    time.sleep(delay)\n",
    "    print(\"Setter: Setting the event!\")\n",
    "    event_obj.set()\n",
    "\n",
    "print(\"\\n--- Event Demonstration ---\")\n",
    "\n",
    "waiter1 = threading.Thread(target=waiter, args=(event, \"Waiter-1\"), name=\"Waiter-1\")\n",
    "waiter2 = threading.Thread(target=waiter, args=(event, \"Waiter-2\"), name=\"Waiter-2\")\n",
    "setter_thread = threading.Thread(target=setter, args=(event, 1.0), name=\"Setter\")\n",
    "\n",
    "waiter1.start()\n",
    "waiter2.start()\n",
    "setter_thread.start()\n",
    "\n",
    "waiter1.join()\n",
    "waiter2.join()\n",
    "setter_thread.join()\n",
    "\n",
    "print(\"Event demo finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 `threading.Condition`: Complex Synchronization\n",
    "*   Combines a `Lock` (or `RLock`) with the ability for threads to `wait()` for a condition and be `notify()`'d (or `notify_all()`) when the condition might be met.\n",
    "*   Used for more complex producer-consumer scenarios or situations where threads need to wait for a specific state change protected by a lock.\n",
    "*   `cond.acquire()` / `cond.release()`: Acquire/release the underlying lock.\n",
    "*   `cond.wait()`: Releases the underlying lock and blocks until notified by another thread calling `notify()` or `notify_all()`. Re-acquires the lock before returning.\n",
    "*   `cond.notify(n=1)`: Wakes up *at most* `n` threads waiting on the condition.\n",
    "*   `cond.notify_all()`: Wakes up *all* threads waiting on the condition.\n",
    "\n",
    "**Important:** Threads must acquire the lock *before* calling `wait()`, `notify()`, or `notify_all()`. `wait()` should typically be called inside a `while` loop that re-checks the actual condition, as notifications can be spurious."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Condition Variable Demonstration (Producer/Consumer) ---\n",
      "Consumer 1: Queue empty. Waiting...\n",
      "Consumer 2: Queue empty. Waiting...\n",
      "Producer: Added Item-0. Queue size: 1\n",
      "Consumer 1: Woke up.\n",
      "Consumer 1: Consumed Item-0. Queue size: 0\n",
      "Consumer 2: Woke up.\n",
      "Consumer 2: Queue empty. Waiting...\n",
      "Producer: Added Item-1. Queue size: 1\n",
      "Consumer 2: Woke up.\n",
      "Consumer 2: Consumed Item-1. Queue size: 0\n",
      "Producer: Added Item-2. Queue size: 1\n",
      "Consumer 1: Consumed Item-2. Queue size: 0\n",
      "Consumer 2: Queue empty. Waiting...\n",
      "Producer: Added Item-3. Queue size: 1\n",
      "Consumer 2: Woke up.\n",
      "Consumer 2: Consumed Item-3. Queue size: 0\n",
      "Consumer 1: Queue empty. Waiting...\n",
      "Producer: Added Item-4. Queue size: 1\n",
      "Consumer 1: Woke up.\n",
      "Consumer 1: Consumed Item-4. Queue size: 0\n",
      "Consumer 2: Queue empty. Waiting...\n",
      "Producer: Added Item-5. Queue size: 1\n",
      "Consumer 2: Woke up.\n",
      "Consumer 2: Consumed Item-5. Queue size: 0\n",
      "Consumer 1: Queue empty. Waiting...\n",
      "Producer: Added Item-6. Queue size: 1\n",
      "Consumer 1: Woke up.\n",
      "Consumer 1: Consumed Item-6. Queue size: 0\n",
      "Consumer 2: Received sentinel. Exiting.\n",
      "Consumer 1: Received sentinel. Exiting.\n",
      "Condition demo finished.\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "import collections\n",
    "\n",
    "MAX_QUEUE_SIZE = 3\n",
    "item_queue = collections.deque(maxlen=MAX_QUEUE_SIZE) # Shared resource\n",
    "condition = threading.Condition() # Uses a Lock by default\n",
    "\n",
    "def producer(cond: threading.Condition, queue: collections.deque):\n",
    "    for i in range(7):\n",
    "        with cond: # Acquire the lock\n",
    "            while len(queue) >= MAX_QUEUE_SIZE:\n",
    "                print(f\"Producer: Queue full ({len(queue)} items). Waiting...\")\n",
    "                cond.wait() # Wait for consumer to make space\n",
    "                print(\"Producer: Woke up.\")\n",
    "            \n",
    "            item = f\"Item-{i}\"\n",
    "            queue.append(item)\n",
    "            print(f\"Producer: Added {item}. Queue size: {len(queue)}\")\n",
    "            cond.notify() # Notify ONE waiting consumer\n",
    "        time.sleep(0.3) # Simulate production time\n",
    "    \n",
    "    # Signal producer is done (optional)\n",
    "    with cond:\n",
    "         queue.append(None) # Sentinel value\n",
    "         cond.notify_all() # Wake all consumers to check for None\n",
    "\n",
    "def consumer(cond: threading.Condition, queue: collections.deque, consumer_id: int):\n",
    "    while True:\n",
    "        with cond:\n",
    "            while not queue: # Check condition inside loop\n",
    "                print(f\"Consumer {consumer_id}: Queue empty. Waiting...\")\n",
    "                cond.wait() # Wait for producer to add item\n",
    "                print(f\"Consumer {consumer_id}: Woke up.\")\n",
    "                # Check if woken up by sentinel after waiting\n",
    "                if queue and queue[0] is None:\n",
    "                   print(f\"Consumer {consumer_id}: Detected sentinel. Exiting.\")\n",
    "                   return \n",
    "                if not queue: # Check again after wait if queue still empty\n",
    "                    continue \n",
    "                    \n",
    "            item = queue.popleft()\n",
    "            \n",
    "            # Check for sentinel value\n",
    "            if item is None:\n",
    "                print(f\"Consumer {consumer_id}: Received sentinel. Exiting.\")\n",
    "                # Put sentinel back for other consumers if any\n",
    "                queue.append(None)\n",
    "                cond.notify() # Notify another consumer\n",
    "                break # Exit loop\n",
    "                \n",
    "            print(f\"Consumer {consumer_id}: Consumed {item}. Queue size: {len(queue)}\")\n",
    "            cond.notify() # Notify producer that space is available\n",
    "            \n",
    "        # Simulate consumption time outside the lock\n",
    "        time.sleep(random.uniform(0.4, 0.8))\n",
    "\n",
    "print(\"\\n--- Condition Variable Demonstration (Producer/Consumer) ---\")\n",
    "producer_thread = threading.Thread(target=producer, args=(condition, item_queue), name=\"Producer\")\n",
    "consumer1_thread = threading.Thread(target=consumer, args=(condition, item_queue, 1), name=\"Consumer-1\")\n",
    "consumer2_thread = threading.Thread(target=consumer, args=(condition, item_queue, 2), name=\"Consumer-2\")\n",
    "\n",
    "consumer1_thread.start()\n",
    "consumer2_thread.start()\n",
    "producer_thread.start()\n",
    "\n",
    "producer_thread.join()\n",
    "consumer1_thread.join()\n",
    "consumer2_thread.join()\n",
    "\n",
    "print(\"Condition demo finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Thread-Safe Data Exchange: `queue.Queue`\n",
    "\n",
    "While locks protect shared variables, passing data between threads using shared variables directly can still be complex to manage correctly.\n",
    "\n",
    "The `queue` module provides synchronized (thread-safe) queue classes (`Queue`, `LifoQueue`, `PriorityQueue`). These are excellent for passing tasks or data between threads without needing explicit locks for the queue operations themselves.\n",
    "\n",
    "*   `q.put(item, block=True, timeout=None)`: Adds an item. Blocks if the queue is full (if `maxsize` was set).\n",
    "*   `q.get(block=True, timeout=None)`: Removes and returns an item. Blocks if the queue is empty.\n",
    "*   `q.task_done()`: Indicates that a formerly enqueued task is complete.\n",
    "*   `q.join()`: Blocks until all items in the queue have been gotten and processed (i.e., `task_done()` called for each item put into the queue).\n",
    "*   `q.qsize()`: Approximate size.\n",
    "*   `q.empty()` / `q.full()`: Check status (can be unreliable in concurrent environments)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Queue Demonstration --- \n",
      "Producer: Adding 'Task Data 0' to queue.\n",
      "Worker 1: Processing 'Task Data 0'...\n",
      "Producer: Adding 'Task Data 1' to queue.\n",
      "Worker 2: Processing 'Task Data 1'...\n",
      "Worker 1: Finished 'Task Data 0'. Result: 'TASK DATA 0'\n",
      "Producer: Adding 'Task Data 2' to queue.\n",
      "Worker 3: Processing 'Task Data 2'...\n",
      "Worker 2: Finished 'Task Data 1'. Result: 'TASK DATA 1'\n",
      "Producer: Adding 'Task Data 3' to queue.\n",
      "Worker 1: Processing 'Task Data 3'...\n",
      "Producer: Adding 'Task Data 4' to queue.\n",
      "Worker 2: Processing 'Task Data 4'...\n",
      "Worker 3: Finished 'Task Data 2'. Result: 'TASK DATA 2'\n",
      "Producer: Adding 'Task Data 5' to queue.\n",
      "Worker 3: Processing 'Task Data 5'...\n",
      "Worker 1: Finished 'Task Data 3'. Result: 'TASK DATA 3'\n",
      "Worker 2: Finished 'Task Data 4'. Result: 'TASK DATA 4'\n",
      "Producer: Adding 'Task Data 6' to queue.\n",
      "Worker 1: Processing 'Task Data 6'...\n",
      "Producer: Adding 'Task Data 7' to queue.\n",
      "Worker 2: Processing 'Task Data 7'...\n",
      "Worker 3: Finished 'Task Data 5'. Result: 'TASK DATA 5'\n",
      "Producer: Adding 'Task Data 8' to queue.\n",
      "Worker 3: Processing 'Task Data 8'...\n",
      "Worker 2: Finished 'Task Data 7'. Result: 'TASK DATA 7'\n",
      "Producer: Adding 'Task Data 9' to queue.\n",
      "Worker 2: Processing 'Task Data 9'...\n",
      "Worker 1: Finished 'Task Data 6'. Result: 'TASK DATA 6'\n",
      "Producer: Finished adding tasks and sentinels.\n",
      "Worker 1: Received sentinel. Exiting.\n",
      "Producer thread has finished.\n",
      "Main thread waiting for queue tasks to complete...\n",
      "Worker 3: Finished 'Task Data 8'. Result: 'TASK DATA 8'\n",
      "Worker 3: Received sentinel. Exiting.\n",
      "Worker 2: Finished 'Task Data 9'. Result: 'TASK DATA 9'\n",
      "Worker 2: Received sentinel. Exiting.\n",
      "All tasks processed (queue joined).\n",
      "\n",
      "--- Processing Results --- \n",
      "Collected results: [(1, 'TASK DATA 0'), (2, 'TASK DATA 1'), (3, 'TASK DATA 2'), (1, 'TASK DATA 3'), (2, 'TASK DATA 4'), (3, 'TASK DATA 5'), (2, 'TASK DATA 7'), (1, 'TASK DATA 6'), (3, 'TASK DATA 8'), (2, 'TASK DATA 9')]\n",
      "Queue demo finished.\n"
     ]
    }
   ],
   "source": [
    "import queue\n",
    "import threading\n",
    "import time\n",
    "import random\n",
    "\n",
    "task_queue = queue.Queue(maxsize=5) # Optional max size\n",
    "result_queue = queue.Queue()\n",
    "SENTINEL = object() # Unique object to signal end of tasks\n",
    "\n",
    "def task_producer(q: queue.Queue):\n",
    "    \"\"\"Produces tasks and puts them onto the queue.\"\"\"\n",
    "    for i in range(10):\n",
    "        task_data = f\"Task Data {i}\"\n",
    "        print(f\"Producer: Adding '{task_data}' to queue.\")\n",
    "        q.put(task_data)\n",
    "        time.sleep(random.uniform(0.1, 0.3))\n",
    "    # Add sentinel values for each consumer thread\n",
    "    for _ in range(NUM_WORKERS):\n",
    "        q.put(SENTINEL) \n",
    "    print(\"Producer: Finished adding tasks and sentinels.\")\n",
    "\n",
    "def task_consumer(in_q: queue.Queue, out_q: queue.Queue, worker_id: int):\n",
    "    \"\"\"Consumes tasks from the queue, processes them, puts result on another queue.\"\"\"\n",
    "    while True:\n",
    "        task_data = in_q.get() # Blocks if empty\n",
    "        if task_data is SENTINEL:\n",
    "            print(f\"Worker {worker_id}: Received sentinel. Exiting.\")\n",
    "            in_q.task_done() # Mark sentinel as done\n",
    "            break # Exit loop\n",
    "        \n",
    "        print(f\"Worker {worker_id}: Processing '{task_data}'...\")\n",
    "        # Simulate work\n",
    "        time.sleep(random.uniform(0.2, 0.6))\n",
    "        result = task_data.upper()\n",
    "        print(f\"Worker {worker_id}: Finished '{task_data}'. Result: '{result}'\")\n",
    "        out_q.put((worker_id, result)) # Put result on output queue\n",
    "        in_q.task_done() # Signal task completion\n",
    "\n",
    "print(\"\\n--- Queue Demonstration --- \")\n",
    "NUM_WORKERS = 3\n",
    "\n",
    "# Start producer thread\n",
    "producer_t = threading.Thread(target=task_producer, args=(task_queue,), name=\"Producer\")\n",
    "producer_t.start()\n",
    "\n",
    "# Start consumer threads\n",
    "consumers = []\n",
    "for i in range(NUM_WORKERS):\n",
    "    consumer_t = threading.Thread(target=task_consumer, args=(task_queue, result_queue, i+1), name=f\"Consumer-{i+1}\")\n",
    "    # No need for daemon=True if we use sentinels and join the queue\n",
    "    consumer_t.start()\n",
    "    consumers.append(consumer_t)\n",
    "\n",
    "# Wait for producer to finish (optional)\n",
    "producer_t.join()\n",
    "print(\"Producer thread has finished.\")\n",
    "\n",
    "# Wait for all tasks in the queue to be processed\n",
    "print(\"Main thread waiting for queue tasks to complete...\")\n",
    "task_queue.join() # Blocks until task_done() called for all items\n",
    "print(\"All tasks processed (queue joined).\")\n",
    "\n",
    "# Consumers should exit now because of the sentinels\n",
    "# Join consumer threads (good practice to ensure they terminate cleanly)\n",
    "for c in consumers:\n",
    "    c.join()\n",
    "\n",
    "print(\"\\n--- Processing Results --- \")\n",
    "results_list = []\n",
    "while not result_queue.empty():\n",
    "    try:\n",
    "        res = result_queue.get_nowait() # Use nowait as we know consumers are done\n",
    "        results_list.append(res)\n",
    "    except queue.Empty:\n",
    "        break\n",
    "print(f\"Collected results: {results_list}\")\n",
    "\n",
    "print(\"Queue demo finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Daemon Threads\n",
    "\n",
    "A thread can be designated as a **daemon thread**. Daemon threads exit automatically when the main program exits (i.e., when all *non-daemon* threads have completed).\n",
    "\n",
    "*   Set using `thread.daemon = True` **before** calling `start()`.\n",
    "*   Useful for background tasks that are not critical and can be safely interrupted (e.g., periodic health checks, cleanup tasks).\n",
    "*   **Caution:** Daemon threads are abruptly stopped. Resources they hold (like open files) might not be cleaned up properly. Avoid using them for tasks that need guaranteed completion or cleanup. Using signaling mechanisms (like `Event` or sentinel values in a `Queue`) is often safer for controlling thread termination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] (DaemonTask) Background task running... (Count: 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Daemon Thread Demonstration ---\n",
      "Main thread doing some work...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] (DaemonTask) Background task running... (Count: 2)\n",
      "[INFO] (DaemonTask) Background task running... (Count: 3)\n",
      "[INFO] (DaemonTask) Background task running... (Count: 4)\n",
      "[INFO] (DaemonTask) Background task running... (Count: 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main thread exiting. Daemon thread will be terminated automatically.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] (DaemonTask) Background task running... (Count: 6)\n",
      "[INFO] (DaemonTask) Background task running... (Count: 7)\n",
      "[INFO] (DaemonTask) Background task running... (Count: 8)\n",
      "[INFO] (DaemonTask) Background task running... (Count: 9)\n",
      "[INFO] (DaemonTask) Background task running... (Count: 10)\n",
      "[INFO] (DaemonTask) Background task running... (Count: 11)\n",
      "[INFO] (DaemonTask) Background task running... (Count: 12)\n",
      "[INFO] (DaemonTask) Background task running... (Count: 13)\n",
      "[INFO] (DaemonTask) Background task running... (Count: 14)\n",
      "[INFO] (DaemonTask) Background task running... (Count: 15)\n",
      "[INFO] (DaemonTask) Background task running... (Count: 16)\n",
      "[INFO] (DaemonTask) Background task running... (Count: 17)\n",
      "[INFO] (DaemonTask) Background task running... (Count: 18)\n",
      "[INFO] (DaemonTask) Background task running... (Count: 19)\n",
      "[INFO] (DaemonTask) Background task running... (Count: 20)\n",
      "[INFO] (DaemonTask) Background task running... (Count: 21)\n",
      "[INFO] (DaemonTask) Background task running... (Count: 22)\n",
      "[INFO] (DaemonTask) Background task running... (Count: 23)\n",
      "[INFO] (DaemonTask) Background task running... (Count: 24)\n",
      "[INFO] (DaemonTask) Background task running... (Count: 25)\n",
      "[INFO] (DaemonTask) Background task running... (Count: 26)\n",
      "[INFO] (DaemonTask) Background task running... (Count: 27)\n",
      "[INFO] (DaemonTask) Background task running... (Count: 28)\n",
      "[INFO] (DaemonTask) Background task running... (Count: 29)\n",
      "[INFO] (DaemonTask) Background task running... (Count: 30)\n",
      "[INFO] (DaemonTask) Background task running... (Count: 31)\n",
      "[INFO] (DaemonTask) Background task running... (Count: 32)\n",
      "[INFO] (DaemonTask) Background task running... (Count: 33)\n",
      "[INFO] (DaemonTask) Background task running... (Count: 34)\n",
      "[INFO] (DaemonTask) Background task running... (Count: 35)\n",
      "[INFO] (DaemonTask) Background task running... (Count: 36)\n",
      "[INFO] (DaemonTask) Background task running... (Count: 37)\n",
      "[INFO] (DaemonTask) Background task running... (Count: 38)\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "import logging\n",
    "\n",
    "def background_task():\n",
    "    thread_name = threading.current_thread().name\n",
    "    counter = 0\n",
    "    while True:\n",
    "        counter += 1\n",
    "        logging.info(f\"Background task running... (Count: {counter})\")\n",
    "        time.sleep(0.5)\n",
    "        # This loop runs forever unless the thread is a daemon\n",
    "\n",
    "print(\"\\n--- Daemon Thread Demonstration ---\")\n",
    "\n",
    "daemon_thread = threading.Thread(target=background_task, name=\"DaemonTask\", daemon=True)\n",
    "# If daemon=False (default), the program would hang here waiting for it.\n",
    "\n",
    "daemon_thread.start()\n",
    "\n",
    "# Main thread does some work and then exits\n",
    "print(\"Main thread doing some work...\")\n",
    "time.sleep(2.1) \n",
    "print(\"Main thread exiting. Daemon thread will be terminated automatically.\")\n",
    "\n",
    "# No need to join the daemon thread explicitly if you want it to terminate with main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Modern Approach: `concurrent.futures.ThreadPoolExecutor`\n",
    "\n",
    "Managing individual threads, joining them, and handling results can be verbose. The `concurrent.futures` module provides a higher-level abstraction.\n",
    "\n",
    "`ThreadPoolExecutor` manages a pool of worker threads:\n",
    "*   You submit tasks (`submit(fn, *args, **kwargs)`).\n",
    "*   It returns `Future` objects, representing the eventual result of the task.\n",
    "*   You can check if futures are done (`.done()`), get their results (`.result()`, which blocks), or add callbacks (`.add_done_callback()`).\n",
    "*   The executor handles thread creation, reuse, and joining automatically, often via a context manager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ThreadPoolExecutor Demonstration --- \n",
      "Submitting tasks using executor.map...\n",
      "(Downloader_0) Fetching https://httpbin.org/delay/1...\n",
      "(Downloader_1) Fetching https://httpbin.org/delay/2...\n",
      "(Downloader_2) Fetching https://httpbin.org/delay/0.5...\n",
      "(Downloader_2) Finished https://httpbin.org/delay/0.5\n",
      "(Downloader_2) Fetching https://httpbin.org/delay/1.5...\n",
      "(Downloader_0) Finished https://httpbin.org/delay/1\n",
      "(Downloader_0) Fetching https://httpbin.org/status/404...\n",
      "Got result from map: ('https://httpbin.org/delay/1', 200, 356)\n",
      "(Downloader_1) Finished https://httpbin.org/delay/2\n",
      "Got result from map: ('https://httpbin.org/delay/2', 200, 356)\n",
      "Got result from map: ('https://httpbin.org/delay/0.5', 200, 358)\n",
      "(Downloader_0) Error fetching https://httpbin.org/status/404: 404 Client Error: NOT FOUND for url: https://httpbin.org/status/404\n",
      "(Downloader_2) Finished https://httpbin.org/delay/1.5\n",
      "Got result from map: ('https://httpbin.org/delay/1.5', 200, 358)\n",
      "Got result from map: ('https://httpbin.org/status/404', -1, 0)\n",
      "\n",
      "--- Results --- \n",
      "('https://httpbin.org/delay/1', 200, 356)\n",
      "('https://httpbin.org/delay/2', 200, 356)\n",
      "('https://httpbin.org/delay/0.5', 200, 358)\n",
      "('https://httpbin.org/delay/1.5', 200, 358)\n",
      "('https://httpbin.org/status/404', -1, 0)\n",
      "\n",
      "ThreadPoolExecutor finished in 5.00 seconds\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "import time\n",
    "import requests # Example I/O bound task (pip install requests)\n",
    "from typing import List, Tuple\n",
    "\n",
    "URLS = [\n",
    "    'https://httpbin.org/delay/1', # Simulate 1 second delay\n",
    "    'https://httpbin.org/delay/2',\n",
    "    'https://httpbin.org/delay/0.5',\n",
    "    'https://httpbin.org/delay/1.5',\n",
    "    'https://httpbin.org/status/404', # Example of a failed request\n",
    "]\n",
    "\n",
    "def download_url(url: str) -> Tuple[str, int, int]:\n",
    "    \"\"\"Downloads a URL and returns URL, status code, and content length.\"\"\"\n",
    "    thread_name = threading.current_thread().name\n",
    "    print(f\"({thread_name}) Fetching {url}...\")\n",
    "    try:\n",
    "        response = requests.get(url, timeout=5)\n",
    "        response.raise_for_status() # Raise HTTPError for bad responses (4xx or 5xx)\n",
    "        print(f\"({thread_name}) Finished {url}\")\n",
    "        return url, response.status_code, len(response.content)\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"({thread_name}) Error fetching {url}: {e}\")\n",
    "        return url, -1, 0 # Indicate error\n",
    "\n",
    "print(\"\\n--- ThreadPoolExecutor Demonstration --- \")\n",
    "start_time_pool = time.perf_counter()\n",
    "\n",
    "# Use context manager for automatic shutdown\n",
    "# max_workers defaults to min(32, os.cpu_count() + 4) in Python 3.8+\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=3, thread_name_prefix='Downloader') as executor:\n",
    "    # Method 1: Using submit() and collecting futures\n",
    "    # futures = [executor.submit(download_url, url) for url in URLS]\n",
    "    # results = []\n",
    "    # for future in concurrent.futures.as_completed(futures):\n",
    "    #     try:\n",
    "    #         result = future.result() # Get result (blocks if not done, re-raises exceptions)\n",
    "    #         results.append(result)\n",
    "    #         print(f\"Got result: {result}\")\n",
    "    #     except Exception as exc:\n",
    "    #         print(f\"Future generated an exception: {exc}\")\n",
    "            \n",
    "    # Method 2: Using executor.map() (simpler for applying same function)\n",
    "    # map() returns an iterator yielding results *in the order tasks were submitted*\n",
    "    # It implicitly waits for all tasks to complete.\n",
    "    # Exceptions raised during task execution will be raised when iterating over map results.\n",
    "    print(\"Submitting tasks using executor.map...\")\n",
    "    results_iterator = executor.map(download_url, URLS)\n",
    "    \n",
    "    results = []\n",
    "    try:\n",
    "        for result in results_iterator:\n",
    "             print(f\"Got result from map: {result}\")\n",
    "             results.append(result)\n",
    "    except Exception as exc:\n",
    "         print(f\"Map iterator raised an exception: {exc}\")\n",
    "\n",
    "end_time_pool = time.perf_counter()\n",
    "\n",
    "print(f\"\\n--- Results --- \")\n",
    "for res in results:\n",
    "    print(res)\n",
    "print(f\"\\nThreadPoolExecutor finished in {end_time_pool - start_time_pool:.2f} seconds\")\n",
    "\n",
    "# Compare with sequential execution (conceptual)\n",
    "# sequential_start = time.perf_counter()\n",
    "# sequential_results = [download_url(url) for url in URLS]\n",
    "# sequential_end = time.perf_counter()\n",
    "# print(f\"\\nSequential finished in {sequential_end - sequential_start:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Benefit:** `ThreadPoolExecutor` abstracts away the manual thread creation, starting, joining, and result collection, making concurrent I/O tasks much easier to manage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Best Practices & Enterprise Considerations\n",
    "\n",
    "1.  **Use for I/O-Bound Tasks:** Threading is most effective in CPython when tasks spend significant time waiting for external operations.\n",
    "2.  **Protect Shared Data:** *Always* use locks (`Lock`, `RLock`) or other appropriate synchronization primitives (`Semaphore`, `Event`, `Condition`) when multiple threads access mutable shared data. Use the `with` statement for locks.\n",
    "3.  **Prefer `queue.Queue`:** Use thread-safe queues for passing data/tasks between threads instead of complex manual locking on shared variables.\n",
    "4.  **Use `ThreadPoolExecutor`:** Prefer the high-level `concurrent.futures.ThreadPoolExecutor` for managing pools of threads over manual `threading.Thread` management for simpler use cases.\n",
    "5.  **Avoid Daemon Threads for Critical Tasks:** Ensure critical tasks complete and resources are cleaned up. Use signaling mechanisms (`Event`, sentinel values in queues) instead of relying on daemon behavior for termination.\n",
    "6.  **Beware of Deadlocks:** Occur when threads are stuck waiting for each other to release locks (e.g., Thread A holds Lock 1 and waits for Lock 2, while Thread B holds Lock 2 and waits for Lock 1). Avoid complex locking patterns; acquire locks in a consistent order.\n",
    "7.  **Resource Management:** Ensure resources acquired by a thread (files, connections) are properly released, even if errors occur (use `try...finally` or context managers within the thread's task).\n",
    "8.  **Testing:** Threading bugs (race conditions, deadlocks) can be hard to reproduce. Use tools, stress testing, and careful code design. Consider testing with tools like `ThreadSanitizer` if possible (more common in C/C++ contexts).\n",
    "9.  **Limit Thread Pool Size:** Creating too many threads can consume excessive memory and lead to performance degradation due to context switching overhead. `ThreadPoolExecutor`'s default is usually sensible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Pitfalls and Common Interview Questions\n",
    "\n",
    "**Common Pitfalls:**\n",
    "\n",
    "*   **Race Conditions:** Unprotected access to shared mutable data.\n",
    "*   **Deadlocks:** Threads waiting indefinitely for locks held by each other.\n",
    "*   **Forgetting `join()`:** The main thread might exit before worker threads complete their tasks if not joined (unless they are daemons).\n",
    "*   **Misusing Locks:** Forgetting to release a lock, using `Lock` where `RLock` is needed (recursion), unnecessary locking reducing concurrency.\n",
    "*   **Ignoring Return Values/Exceptions:** Not properly retrieving results or handling exceptions from threads (easier with `concurrent.futures`).\n",
    "*   **Using Threading for CPU-Bound Tasks (in CPython):** Expecting parallelism due to the GIL limitation.\n",
    "*   **Resource Leaks:** Threads terminating (especially daemons) without releasing resources.\n",
    "\n",
    "**Common Interview Questions:**\n",
    "\n",
    "1.  What is the difference between a thread and a process?\n",
    "2.  What is the Global Interpreter Lock (GIL) and how does it affect threading in CPython?\n",
    "3.  When is threading a suitable concurrency model in Python?\n",
    "4.  What is a race condition? How can you prevent it?\n",
    "5.  Explain the purpose of `threading.Lock`. How should it typically be used?\n",
    "6.  What is the difference between `Lock` and `RLock`?\n",
    "7.  How can threads communicate safely? (Mention `queue.Queue`).\n",
    "8.  What is a daemon thread?\n",
    "9.  What are the advantages of using `concurrent.futures.ThreadPoolExecutor` over managing `threading.Thread` objects directly?\n",
    "10. What is a deadlock?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Challenge: Threaded Web Status Checker\n",
    "\n",
    "**Goal:** Create a script that checks the status code of multiple URLs concurrently using threads.\n",
    "\n",
    "**Tasks:**\n",
    "\n",
    "1.  **URL List:** Define a list of URLs to check (include some valid, some potentially slow, and maybe one invalid/404 URL).\n",
    "2.  **Checker Function:** Create a function `check_url_status(url: str) -> Tuple[str, Optional[int]]` that:\n",
    "    *   Takes a URL string as input.\n",
    "    *   Uses the `requests` library (`pip install requests`) to make a GET request to the URL (use a timeout, e.g., 5 seconds).\n",
    "    *   Handles potential `requests.exceptions.RequestException` errors.\n",
    "    *   Returns a tuple containing the URL and the HTTP status code (or `None` if an error occurred).\n",
    "    *   Include logging within the function to show which thread is checking which URL.\n",
    "3.  **Concurrent Execution:**\n",
    "    *   Use `concurrent.futures.ThreadPoolExecutor` to run the `check_url_status` function concurrently for all URLs in the list.\n",
    "    *   Configure the executor with a reasonable number of worker threads (e.g., 5).\n",
    "4.  **Collect and Print Results:**\n",
    "    *   Retrieve the results from the executor (e.g., using `executor.map` or `submit`/`as_completed`).\n",
    "    *   Print the status for each URL.\n",
    "5.  **Timing:** Measure and print the total time taken for checking all URLs concurrently.\n",
    "\n",
    "**(Bonus):** Implement the same task sequentially (without threads) and compare the execution time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] (Checker_0 ) Checking https://www.google.com...\n",
      "[INFO] (Checker_1 ) Checking https://httpbin.org/delay/1...\n",
      "[INFO] (Checker_2 ) Checking https://httpbin.org/delay/0.5...\n",
      "[INFO] (Checker_3 ) Checking https://httpbin.org/status/404...\n",
      "[INFO] (Checker_4 ) Checking https://httpbin.org/delay/1.5...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Concurrent URL Check (Max Workers: 5) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] (Checker_0 ) Finished https://www.google.com - Status: 200\n",
      "[INFO] (Checker_0 ) Checking https://invalid.url.that.does.not.exist...\n",
      "[WARNING] (Checker_0 ) Connection error for https://invalid.url.that.does.not.exist\n",
      "[INFO] (Checker_0 ) Checking https://www.github.com...\n",
      "[INFO] (Checker_0 ) Finished https://www.github.com - Status: 200\n",
      "[INFO] (Checker_3 ) Finished https://httpbin.org/status/404 - Status: 404\n",
      "[INFO] (Checker_2 ) Finished https://httpbin.org/delay/0.5 - Status: 200\n",
      "[INFO] (Checker_1 ) Finished https://httpbin.org/delay/1 - Status: 200\n",
      "[INFO] (Checker_4 ) Finished https://httpbin.org/delay/1.5 - Status: 200\n",
      "[INFO] (MainThread) Checking https://www.google.com...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Concurrent Check Results ---\n",
      "  https://www.google.com                             -> Status: 200\n",
      "  https://httpbin.org/delay/1                        -> Status: 200\n",
      "  https://httpbin.org/delay/0.5                      -> Status: 200\n",
      "  https://httpbin.org/status/404                     -> Status: 404\n",
      "  https://httpbin.org/delay/1.5                      -> Status: 200\n",
      "  https://invalid.url.that.does.not.exist            -> Status: Error/Timeout\n",
      "  https://www.github.com                             -> Status: 200\n",
      "\n",
      "Total time (concurrent): 2.75 seconds\n",
      "\n",
      "--- Starting Sequential URL Check ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] (MainThread) Finished https://www.google.com - Status: 200\n",
      "[INFO] (MainThread) Checking https://httpbin.org/delay/1...\n",
      "[INFO] (MainThread) Finished https://httpbin.org/delay/1 - Status: 200\n",
      "[INFO] (MainThread) Checking https://httpbin.org/delay/0.5...\n",
      "[INFO] (MainThread) Finished https://httpbin.org/delay/0.5 - Status: 200\n",
      "[INFO] (MainThread) Checking https://httpbin.org/status/404...\n",
      "[INFO] (MainThread) Finished https://httpbin.org/status/404 - Status: 404\n",
      "[INFO] (MainThread) Checking https://httpbin.org/delay/1.5...\n",
      "[INFO] (MainThread) Finished https://httpbin.org/delay/1.5 - Status: 200\n",
      "[INFO] (MainThread) Checking https://invalid.url.that.does.not.exist...\n",
      "[WARNING] (MainThread) Connection error for https://invalid.url.that.does.not.exist\n",
      "[INFO] (MainThread) Checking https://www.github.com...\n",
      "[INFO] (MainThread) Finished https://www.github.com - Status: 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Sequential Check Results ---\n",
      "  https://www.google.com                             -> Status: 200\n",
      "  https://httpbin.org/delay/1                        -> Status: 200\n",
      "  https://httpbin.org/delay/0.5                      -> Status: 200\n",
      "  https://httpbin.org/status/404                     -> Status: 404\n",
      "  https://httpbin.org/delay/1.5                      -> Status: 200\n",
      "  https://invalid.url.that.does.not.exist            -> Status: Error/Timeout\n",
      "  https://www.github.com                             -> Status: 200\n",
      "\n",
      "Total time (sequential): 8.76 seconds\n"
     ]
    }
   ],
   "source": [
    "# --- Solution Space for Challenge ---\n",
    "import concurrent.futures\n",
    "import threading\n",
    "import requests\n",
    "import time\n",
    "import logging\n",
    "from typing import List, Tuple, Optional\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, \n",
    "                    format='[%(levelname)s] (%(threadName)-10s) %(message)s',\n",
    "                    force=True)\n",
    "\n",
    "# 1. URL List\n",
    "URLS_TO_CHECK = [\n",
    "    'https://www.google.com',\n",
    "    'https://httpbin.org/delay/1', # Delays 1 second\n",
    "    'https://httpbin.org/delay/0.5',\n",
    "    'https://httpbin.org/status/404', # Not Found\n",
    "    'https://httpbin.org/delay/1.5',\n",
    "    'https://invalid.url.that.does.not.exist',\n",
    "    'https://www.github.com',\n",
    "]\n",
    "\n",
    "# 2. Checker Function\n",
    "def check_url_status(url: str) -> Tuple[str, Optional[int]]:\n",
    "    \"\"\"Checks the HTTP status code for a given URL.\"\"\"\n",
    "    thread_name = threading.current_thread().name\n",
    "    logging.info(f\"Checking {url}...\")\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10) # Increased timeout\n",
    "        # No raise_for_status needed if we just want the code\n",
    "        status_code = response.status_code\n",
    "        logging.info(f\"Finished {url} - Status: {status_code}\")\n",
    "        return url, status_code\n",
    "    except requests.exceptions.Timeout:\n",
    "        logging.warning(f\"Timeout occurred for {url}\")\n",
    "        return url, None\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        logging.warning(f\"Connection error for {url}\")\n",
    "        return url, None\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logging.error(f\"Error checking {url}: {type(e).__name__}\")\n",
    "        return url, None # Return None for other request errors\n",
    "\n",
    "# 3 & 4: Concurrent Execution and Result Collection\n",
    "MAX_WORKERS = 5\n",
    "all_results = []\n",
    "\n",
    "print(f\"--- Starting Concurrent URL Check (Max Workers: {MAX_WORKERS}) ---\")\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS, thread_name_prefix='Checker') as executor:\n",
    "    # Using map for simplicity - order of results matches URLS_TO_CHECK\n",
    "    results_iterator = executor.map(check_url_status, URLS_TO_CHECK)\n",
    "    \n",
    "    # Collect results (map implicitly waits)\n",
    "    all_results = list(results_iterator)\n",
    "\n",
    "end_time = time.perf_counter()\n",
    "\n",
    "# 5. Print Results and Timing\n",
    "print(\"\\n--- Concurrent Check Results ---\")\n",
    "for url, status in all_results:\n",
    "    print(f\"  {url:<50} -> Status: {status if status is not None else 'Error/Timeout'}\")\n",
    "\n",
    "print(f\"\\nTotal time (concurrent): {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# Bonus: Sequential Comparison\n",
    "print(\"\\n--- Starting Sequential URL Check ---\")\n",
    "start_time_seq = time.perf_counter()\n",
    "sequential_results = []\n",
    "for url in URLS_TO_CHECK:\n",
    "    # Simulate running in the 'main' thread context\n",
    "    sequential_results.append(check_url_status(url))\n",
    "end_time_seq = time.perf_counter()\n",
    "\n",
    "print(\"\\n--- Sequential Check Results ---\")\n",
    "for url, status in sequential_results:\n",
    "     print(f\"  {url:<50} -> Status: {status if status is not None else 'Error/Timeout'}\")\n",
    "print(f\"\\nTotal time (sequential): {end_time_seq - start_time_seq:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Conclusion\n",
    "\n",
    "Threading in Python, facilitated by the `threading` module and the high-level `concurrent.futures.ThreadPoolExecutor`, provides an effective mechanism for achieving concurrency, particularly for I/O-bound tasks. While the GIL prevents true parallelism for CPU-bound work in CPython, threading allows applications to remain responsive by performing other tasks while waiting for I/O.\n",
    "\n",
    "The key challenge lies in managing shared data safely using synchronization primitives like Locks or thread-safe structures like Queues. By understanding these concepts and applying best practices, you can leverage threading to build more efficient and responsive Python applications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
