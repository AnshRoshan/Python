{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸªµ Mastering Python Logging: From Basics to Enterprise Patterns\n",
    "\n",
    "**Welcome!** This notebook is your comprehensive guide to understanding and effectively using Python's built-in `logging` module. We'll go beyond simple `print()` statements to explore how robust logging is essential for building maintainable, diagnosable, and production-ready applications.\n",
    "\n",
    "**Target Audience:** Python developers who want to implement professional-grade logging in their applications.\n",
    "\n",
    "**Learning Objectives:**\n",
    "*   Understand the *why* behind logging (debugging, monitoring, auditing).\n",
    "*   Learn the different logging levels and when to use them.\n",
    "*   Configure logging using `basicConfig`, `dictConfig`, Handlers, Formatters, and Filters.\n",
    "*   Implement structured logging (e.g., JSON) for better machine readability.\n",
    "*   Log exceptions effectively with tracebacks.\n",
    "*   Explore best practices for logging in modular applications and enterprise environments.\n",
    "*   Identify common pitfalls and prepare for related interview questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction: Why Logging? (Beyond `print()`)\n",
    "\n",
    "Think of logging as the **flight data recorder (black box)** for your application. While `print()` statements are useful for quick checks during development, they have major drawbacks in larger applications or production environments:\n",
    "\n",
    "*   **No Severity Levels:** You can't easily distinguish between informational messages, warnings, and critical errors.\n",
    "*   **Hard to Control:** Enabling/disabling `print` statements requires code changes.\n",
    "*   **No Standard Format:** Output is inconsistent and hard to parse automatically.\n",
    "*   **Performance:** Excessive printing can impact performance.\n",
    "*   **Destination Flexibility:** `print` only goes to standard output; logging can go to files, network sockets, external services, etc.\n",
    "\n",
    "**Logging provides solutions:**\n",
    "\n",
    "1.  **Debugging & Diagnosis:** Track the flow of execution and variable states to pinpoint issues.\n",
    "2.  **Monitoring:** Observe application health and performance in real-time.\n",
    "3.  **Auditing:** Record significant events (e.g., user actions, configuration changes) for security or compliance.\n",
    "4.  **Analysis:** Collect structured log data for later analysis (e.g., identifying usage patterns, performance bottlenecks).\n",
    "\n",
    "**Use Case Analogy:** Imagine building a complex web server. Using `print` is like shouting occasional updates into a noisy room. Using `logging` is like having dedicated channels (levels), structured reports (formatters), and multiple destinations (files for errors, console for warnings, a central dashboard for critical alerts) managed by a central dispatcher (the logging framework)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The Basics: Levels and `basicConfig`\n",
    "\n",
    "### 2.1 Logging Levels\n",
    "\n",
    "The `logging` module defines standard severity levels. When you configure logging, you set a minimum level; messages with that severity or higher will be processed.\n",
    "\n",
    "| Level      | Value | When to Use                                       |\n",
    "| :--------- | ----: | :------------------------------------------------ |\n",
    "| `DEBUG`    | 10    | Detailed information, typically only for diagnosis. |\n",
    "| `INFO`     | 20    | Confirmation that things are working as expected.   |\n",
    "| `WARNING`  | 30    | An indication of something unexpected or problematic in the near future (e.g., low disk space). The software is still working as expected. **(Default Level)** |\n",
    "| `ERROR`    | 40    | Due to a more serious problem, the software has not been able to perform some function. |\n",
    "| `CRITICAL` | 50    | A serious error, indicating that the program itself may be unable to continue running. |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:This is a warning message (visible)\n",
      "ERROR:root:This is an error message (visible)\n",
      "CRITICAL:root:This is a critical message (visible)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Default Logging --- \n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "# Default configuration only shows WARNING and above\n",
    "print(\"--- Default Logging --- \")\n",
    "logging.debug('This is a debug message (hidden by default)')\n",
    "logging.info('This is an info message (hidden by default)')\n",
    "logging.warning('This is a warning message (visible)')\n",
    "logging.error('This is an error message (visible)')\n",
    "logging.critical('This is a critical message (visible)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Basic Configuration (`logging.basicConfig`)\n",
    "\n",
    "`basicConfig` is a convenience function for simple configuration (e.g., scripts, small projects). **Important:** It only works if the root logger has not already been configured (e.g., by calling `logging.info` *before* `basicConfig`). Call it **once** at the very beginning of your application.\n",
    "\n",
    "Common `basicConfig` arguments:\n",
    "*   `level`: The minimum severity level to log (e.g., `logging.DEBUG`).\n",
    "*   `format`: A string defining the output format (see below).\n",
    "*   `datefmt`: A string defining the date/time format (used with `%(asctime)s` in the format string).\n",
    "*   `filename`: If provided, logs output to this file instead of the console (stderr).\n",
    "*   `filemode`: If `filename` is used, specifies the file mode ('a' for append (default), 'w' for write/overwrite).\n",
    "*   `force`: (Python 3.8+) If True, removes and replaces existing handlers on the root logger. Useful in some testing or interactive scenarios, but use with caution in applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-20 16:13:40 - DEBUG - root - 464591755.py:17 - This is a detailed debug message.\n",
      "2025-04-20 16:13:40 - INFO - root - 464591755.py:18 - Application starting up.\n",
      "2025-04-20 16:13:40 - WARNING - root - 464591755.py:19 - Configuration file not found, using defaults.\n",
      "2025-04-20 16:13:40 - ERROR - root - 464591755.py:20 - Failed to connect to database.\n",
      "2025-04-20 16:13:40 - CRITICAL - root - 464591755.py:21 - System meltdown imminent!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Custom BasicConfig Logging --- \n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import sys # To ensure output is fresh in notebooks if re-run\n",
    "\n",
    "# --- Configuration 1: Log DEBUG and above to console with a specific format ---\n",
    "log_format = '%(asctime)s - %(levelname)s - %(name)s - %(filename)s:%(lineno)d - %(message)s'\n",
    "date_format = '%Y-%m-%d %H:%M:%S'\n",
    "\n",
    "# Use force=True in notebooks/interactive sessions if you might re-run the cell\n",
    "# In a standard application, avoid 'force=True' unless you have a specific reason.\n",
    "logging.basicConfig(level=logging.DEBUG, \n",
    "                    format=log_format, \n",
    "                    datefmt=date_format,\n",
    "                    stream=sys.stderr, # Explicitly set stream for notebooks\n",
    "                    force=True) \n",
    "\n",
    "print(\"\\n--- Custom BasicConfig Logging --- \")\n",
    "logging.debug('This is a detailed debug message.')\n",
    "logging.info('Application starting up.')\n",
    "logging.warning('Configuration file not found, using defaults.')\n",
    "logging.error('Failed to connect to database.')\n",
    "logging.critical('System meltdown imminent!')\n",
    "\n",
    "# --- Configuration 2: Log INFO and above to a file (overwriting) ---\n",
    "# Note: Running this will change the logging destination for subsequent calls in this session\n",
    "# logging.basicConfig(level=logging.INFO, \n",
    "#                     format=log_format, \n",
    "#                     datefmt=date_format,\n",
    "#                     filename='app.log', \n",
    "#                     filemode='w',\n",
    "#                     force=True)\n",
    "# logging.info('This message goes to the file app.log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Common LogRecord Attributes for Formatting:**\n",
    "\n",
    "| Attribute      | Format                  | Description                                                 |\n",
    "| :------------- | :---------------------- | :---------------------------------------------------------- |\n",
    "| `asctime`      | `%(asctime)s`           | Human-readable time when the `LogRecord` was created.       |\n",
    "| `created`      | `%(created)f`           | Time when the `LogRecord` was created (Unix timestamp).     |\n",
    "| `filename`     | `%(filename)s`          | Filename portion of pathname.                               |\n",
    "| `funcName`     | `%(funcName)s`          | Name of function containing the logging call.               |\n",
    "| `levelname`    | `%(levelname)s`         | Text logging level for the message ('DEBUG', 'INFO', etc.). |\n",
    "| `levelno`      | `%(levelno)s`           | Numeric logging level for the message (10, 20, etc.).       |\n",
    "| `lineno`       | `%(lineno)d`            | Source line number where the logging call was issued.       |\n",
    "| `message`      | `%(message)s`           | The logged message itself.                                  |\n",
    "| `module`       | `%(module)s`            | Module name.                                                |\n",
    "| `msecs`        | `%(msecs)d`             | Millisecond portion of the creation time.                   |\n",
    "| `name`         | `%(name)s`              | Name of the logger used to log the call.                    |\n",
    "| `pathname`     | `%(pathname)s`          | Full pathname of the source file.                           |\n",
    "| `process`      | `%(process)d`           | Process ID (if available).                                  |\n",
    "| `processName`  | `%(processName)s`       | Process name (if available).                                |\n",
    "| `thread`       | `%(thread)d`            | Thread ID (if available).                                   |\n",
    "| `threadName`   | `%(threadName)s`        | Thread name (if available).                                 |\n",
    "\n",
    "Full list: [LogRecord attributes](https://docs.python.org/3/library/logging.html#logrecord-attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Loggers, Handlers, Formatters, and Filters: The Core Components\n",
    "\n",
    "`basicConfig` is limited. For more control (e.g., different formats for console vs. file, logging specific modules differently), you need to work with the core components:\n",
    "\n",
    "1.  **Loggers:** Your application code interacts directly with Logger objects (`logging.getLogger(...)`). They are arranged in a hierarchy (e.g., `myapp.network.utils` is a child of `myapp.network`, which is a child of `myapp`, which is a child of the `root` logger). Loggers decide *whether* to process a message based on their level.\n",
    "2.  **Handlers:** Take the log records from loggers and dispatch them to the appropriate destination (console, file, network socket, email, etc.). Handlers also have levels; a handler will only process messages at its level or higher.\n",
    "3.  **Formatters:** Specify the layout of the final log message string.\n",
    "4.  **Filters:** Provide fine-grained control over which log records are passed from loggers to handlers or from handlers onwards.\n",
    "\n",
    "**Flow:** Log message -> Logger (checks level) -> Filters (on Logger) -> Handlers (check level) -> Filters (on Handler) -> Formatter -> Destination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Getting a Logger (Best Practice: `__name__`)\n",
    "\n",
    "It's standard practice to get a logger specific to the current module using `logging.getLogger(__name__)`. This automatically uses the module's dotted path as the logger name, fitting it into the hierarchy and making it easy to configure logging per module.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-20 16:13:40 - INFO - __main__ - 3570662048.py:7 - This log message comes from the '__main__' logger.\n"
     ]
    }
   ],
   "source": [
    "# In your_module.py\n",
    "import logging\n",
    "\n",
    "# Get a logger named after the module (e.g., 'your_module')\n",
    "logger = logging.getLogger(__name__) \n",
    "\n",
    "logger.info(f\"This log message comes from the '{logger.name}' logger.\")\n",
    "\n",
    "# In another_module.py (assuming it's in a package 'mypackage')\n",
    "# import logging\n",
    "# logger = logging.getLogger(__name__) # logger name will be 'mypackage.another_module'\n",
    "# logger.debug(\"Debug info from another module.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Configuring Handlers and Formatters\n",
    "\n",
    "Let's manually configure a logger with two handlers: one for the console (showing INFO and above) and one for a file (showing ERROR and above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:13:40 - my_app_module - INFO - Application finished processing request.\n",
      "16:13:40 - my_app_module - WARNING - User authentication failed for user 'admin'.\n",
      "16:13:40 - my_app_module - ERROR - Database connection lost.\n",
      "16:13:40 - my_app_module - CRITICAL - System integrity compromised!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Manual Handler Configuration --- \n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "# 1. Get the logger (use __name__ or a specific name)\n",
    "module_logger = logging.getLogger('my_app_module')\n",
    "module_logger.setLevel(logging.DEBUG) # Process all messages from DEBUG upwards\n",
    "\n",
    "# Prevent messages from propagating to the root logger's handlers\n",
    "# Set this to False if you *only* want this logger's handlers to act\n",
    "module_logger.propagate = False \n",
    "\n",
    "# 2. Create Handlers\n",
    "# Console Handler (INFO and above)\n",
    "console_handler = logging.StreamHandler(sys.stderr) # Use stderr for logs by convention\n",
    "console_handler.setLevel(logging.INFO) \n",
    "\n",
    "# File Handler (ERROR and above)\n",
    "file_handler = logging.FileHandler('error.log', mode='a') # Append mode\n",
    "file_handler.setLevel(logging.ERROR)\n",
    "\n",
    "# 3. Create Formatters\n",
    "console_format = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s', datefmt='%H:%M:%S')\n",
    "file_format = logging.Formatter('%(asctime)s - %(process)d - %(thread)d - %(name)s - %(levelname)s - %(filename)s:%(lineno)d - %(message)s')\n",
    "\n",
    "# 4. Set Formatters on Handlers\n",
    "console_handler.setFormatter(console_format)\n",
    "file_handler.setFormatter(file_format)\n",
    "\n",
    "# 5. Add Handlers to the Logger\n",
    "# Ensure handlers aren't added multiple times if re-running cell in notebook\n",
    "if not module_logger.handlers:\n",
    "    module_logger.addHandler(console_handler)\n",
    "    module_logger.addHandler(file_handler)\n",
    "else:\n",
    "    # In a real app, you configure once. In notebooks, clear existing if re-running:\n",
    "    module_logger.handlers.clear()\n",
    "    module_logger.addHandler(console_handler)\n",
    "    module_logger.addHandler(file_handler)\n",
    "\n",
    "# 6. Log Messages\n",
    "print(\"\\n--- Manual Handler Configuration --- \")\n",
    "module_logger.debug(\"This debug message won't appear on console or file.\")\n",
    "module_logger.info(\"Application finished processing request.\") # Appears on console\n",
    "module_logger.warning(\"User authentication failed for user 'admin'.\") # Appears on console\n",
    "module_logger.error(\"Database connection lost.\") # Appears on console AND in error.log\n",
    "module_logger.critical(\"System integrity compromised!\") # Appears on console AND in error.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Logger Hierarchy and Propagation\n",
    "\n",
    "Loggers exist in a hierarchy based on their names (e.g., `a.b` is a child of `a`). By default, after a logger processes a message and sends it to its *own* handlers, it passes the message up to its parent's handlers. This continues up to the root logger.\n",
    "\n",
    "*   You can disable this by setting `logger.propagate = False`.\n",
    "*   This allows you to configure a high-level logger (e.g., `myapp`) and have all child loggers (`myapp.ui`, `myapp.db`) inherit that configuration unless they have specific handlers or propagation disabled.\n",
    "\n",
    "**Pitfall:** If you see duplicate log messages, it's often because a logger *and* one of its ancestors both have handlers (like the root logger configured by `basicConfig`) and propagation is enabled (the default)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Filters\n",
    "\n",
    "Filters provide more granular control than levels. You can filter based on logger name, level, or custom logic.\n",
    "\n",
    "A filter can be added to a Logger or a Handler using `addFilter()`. The filter object must have a `filter(record)` method that returns `True` if the record should be processed, `False` otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "myapp.network - INFO - Network connection established.\n",
      "myapp.network - WARNING - High latency detected.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Filter Demonstration --- \n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "# Filter to only allow records from a specific module/logger name\n",
    "class ModuleFilter(logging.Filter):\n",
    "    def __init__(self, module_name: str):\n",
    "        super().__init__()\n",
    "        self.module_name = module_name\n",
    "\n",
    "    def filter(self, record: logging.LogRecord) -> bool:\n",
    "        # Check if the record's logger name starts with the specified module name\n",
    "        return record.name.startswith(self.module_name)\n",
    "\n",
    "# --- Setup --- \n",
    "logger_a = logging.getLogger('myapp.network')\n",
    "logger_b = logging.getLogger('myapp.database')\n",
    "logger_a.setLevel(logging.INFO)\n",
    "logger_b.setLevel(logging.INFO)\n",
    "\n",
    "console_handler = logging.StreamHandler(sys.stderr)\n",
    "console_handler.setLevel(logging.INFO)\n",
    "console_format = logging.Formatter('%(name)s - %(levelname)s - %(message)s')\n",
    "console_handler.setFormatter(console_format)\n",
    "\n",
    "# Add filter to the handler: Only show messages from 'myapp.network'\n",
    "network_filter = ModuleFilter('myapp.network')\n",
    "console_handler.addFilter(network_filter)\n",
    "\n",
    "# Add handler to both loggers (normally might add to parent 'myapp')\n",
    "# Clear handlers if re-running cell\n",
    "for logger in [logger_a, logger_b]:\n",
    "    if not logger.handlers:\n",
    "        logger.addHandler(console_handler)\n",
    "    # Ensure propagation is off if adding handler directly to multiple children\n",
    "    # OR add the handler to the parent ('myapp') and let propagation work.\n",
    "    logger.propagate = False \n",
    "\n",
    "# --- Logging --- \n",
    "print(\"\\n--- Filter Demonstration --- \")\n",
    "logger_a.info(\"Network connection established.\") # Should appear (passes filter)\n",
    "logger_b.info(\"Database query executed.\")      # Should NOT appear (filtered out)\n",
    "logger_a.warning(\"High latency detected.\")     # Should appear (passes filter)\n",
    "\n",
    "# Cleanup: Remove filter and handlers for subsequent cells if needed\n",
    "console_handler.removeFilter(network_filter)\n",
    "logger_a.removeHandler(console_handler)\n",
    "logger_b.removeHandler(console_handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Advanced Configuration: `fileConfig` and `dictConfig`\n",
    "\n",
    "Manually creating handlers, formatters, etc., in code can become verbose. For complex applications, configuration is often externalized.\n",
    "\n",
    "*   **`logging.config.fileConfig()`:** Reads configuration from a file in a specific format (similar to `.ini` files). Less common now due to its inflexibility compared to `dictConfig`.\n",
    "*   **`logging.config.dictConfig()`:** Reads configuration from a Python dictionary. This is the **recommended modern approach** as dictionaries are easy to create, modify programmatically, load from JSON/YAML, and offer more flexibility.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 `dictConfig` Example\n",
    "\n",
    "This dictionary defines loggers, handlers, and formatters structurally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:13:40 - myapp.service - INFO - Service started successfully.\n",
      "16:13:40 - myapp.service - WARNING - Cache miss for resource X.\n",
      "16:13:40 - myapp.service - ERROR - Failed to process message ID 123.\n",
      "16:13:40 - third_party_lib - WARNING - Library component deprecated.\n",
      "16:13:40 - unconfigured_logger - WARNING - Warning from an unconfigured logger.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- dictConfig Logging --- \n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import logging.config\n",
    "import sys\n",
    "\n",
    "LOGGING_CONFIG = {\n",
    "    'version': 1, # Schema version\n",
    "    'disable_existing_loggers': False, # Keep loggers configured by libraries\n",
    "    \n",
    "    # Define formatters\n",
    "    'formatters': {\n",
    "        'simple': {\n",
    "            'format': '%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "            'datefmt': '%H:%M:%S'\n",
    "        },\n",
    "        'detailed': {\n",
    "            'format': '%(asctime)s - %(name)s - %(levelname)s - [%(filename)s:%(lineno)d] - %(process)d - %(thread)d - %(message)s'\n",
    "        },\n",
    "    },\n",
    "    \n",
    "    # Define handlers\n",
    "    'handlers': {\n",
    "        'console': {\n",
    "            'class': 'logging.StreamHandler',\n",
    "            'level': 'DEBUG', # Handler level\n",
    "            'formatter': 'simple', # Use the 'simple' formatter\n",
    "            'stream': 'ext://sys.stderr' # Direct output to stderr\n",
    "        },\n",
    "        'file_app': {\n",
    "            'class': 'logging.FileHandler',\n",
    "            'level': 'INFO',\n",
    "            'formatter': 'detailed',\n",
    "            'filename': 'application.log', # Log file name\n",
    "            'mode': 'a', # Append mode\n",
    "            'encoding': 'utf-8'\n",
    "        },\n",
    "        'file_errors': {\n",
    "            'class': 'logging.FileHandler',\n",
    "            'level': 'ERROR',\n",
    "            'formatter': 'detailed',\n",
    "            'filename': 'errors.log',\n",
    "            'mode': 'a',\n",
    "            'encoding': 'utf-8'\n",
    "        },\n",
    "    },\n",
    "    \n",
    "    # Define loggers\n",
    "    'loggers': {\n",
    "        'myapp': { # Configures logger named 'myapp' and its children\n",
    "            'level': 'INFO', # Logger level\n",
    "            'handlers': ['console', 'file_app', 'file_errors'], # Attach handlers\n",
    "            'propagate': False # Don't pass to root logger handlers\n",
    "        },\n",
    "        'third_party_lib': { # Example: Quieter logging for a library\n",
    "            'level': 'WARNING',\n",
    "            'handlers': ['console'],\n",
    "            'propagate': False\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    # Configure the root logger (optional, handles anything not caught by specific loggers)\n",
    "    'root': {\n",
    "        'level': 'WARNING',\n",
    "        'handlers': ['console']\n",
    "    }\n",
    "}\n",
    "\n",
    "# Apply the configuration\n",
    "logging.config.dictConfig(LOGGING_CONFIG)\n",
    "\n",
    "# Get loggers (names defined in the config)\n",
    "app_logger = logging.getLogger('myapp.service') # Child of 'myapp'\n",
    "lib_logger = logging.getLogger('third_party_lib')\n",
    "root_logger_test = logging.getLogger('unconfigured_logger') # Handled by root\n",
    "\n",
    "# Log some messages\n",
    "print(\"\\n--- dictConfig Logging --- \")\n",
    "app_logger.debug(\"Detailed service debug info.\") # Filtered by logger level 'INFO'\n",
    "app_logger.info(\"Service started successfully.\") # Goes to console, file_app\n",
    "app_logger.warning(\"Cache miss for resource X.\") # Goes to console, file_app\n",
    "app_logger.error(\"Failed to process message ID 123.\") # Goes to console, file_app, file_errors\n",
    "lib_logger.info(\"Some info from the library.\") # Filtered by logger level 'WARNING'\n",
    "lib_logger.warning(\"Library component deprecated.\") # Goes to console\n",
    "root_logger_test.warning(\"Warning from an unconfigured logger.\") # Handled by root -> console"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Structured Logging (e.g., JSON)\n",
    "\n",
    "**Why?** In modern systems (microservices, cloud), logs are often aggregated into centralized platforms (Elasticsearch/Logstash/Kibana - ELK, Splunk, Datadog). Plain text logs are hard for machines to parse reliably. Structured logs (like JSON) make querying, filtering, and analysis much easier.\n",
    "\n",
    "**How?** Use custom formatters or dedicated libraries.\n",
    "\n",
    "### 5.1 Using `python-json-logger`\n",
    "\n",
    "A popular library for creating JSON logs.\n",
    "\n",
    "`pip install python-json-logger`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9931/2235547257.py:16: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  now = datetime.datetime.utcnow().strftime('%Y-%m-%dT%H:%M:%S.%fZ')\n",
      "{\"timestamp\": \"2025-04-20T10:43:41.031386Z\", \"level\": \"INFO\", \"name\": \"json_app.worker\", \"message\": \"Worker process started.\", \"filename\": \"2235547257.py\", \"lineno\": 56}\n",
      "{\"timestamp\": \"2025-04-20T10:43:41.032850Z\", \"level\": \"INFO\", \"name\": \"json_app.worker\", \"message\": \"Processed task successfully.\", \"filename\": \"2235547257.py\", \"lineno\": 64, \"extra_data\": {\"user_id\": \"user-123\", \"request_id\": \"req-abc-987\", \"elapsed_ms\": 55.6}}\n",
      "{\"timestamp\": \"2025-04-20T10:43:41.034012Z\", \"level\": \"ERROR\", \"name\": \"json_app.worker\", \"message\": \"Failed to update record.\", \"filename\": \"2235547257.py\", \"lineno\": 65, \"record_id\": 456, \"reason\": \"DB timeout\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- JSON Structured Logging --- \n"
     ]
    }
   ],
   "source": [
    "# Install if you don't have it\n",
    "# !pip install python-json-logger\n",
    "\n",
    "import logging\n",
    "import logging.config\n",
    "from pythonjsonlogger import jsonlogger\n",
    "import datetime\n",
    "import sys\n",
    "\n",
    "# Define a custom JSON formatter\n",
    "# See library docs for more formatting options\n",
    "class CustomJsonFormatter(jsonlogger.JsonFormatter):\n",
    "    def add_fields(self, log_record, record, message_dict):\n",
    "        super(CustomJsonFormatter, self).add_fields(log_record, record, message_dict)\n",
    "        if not log_record.get('timestamp'):\n",
    "            now = datetime.datetime.utcnow().strftime('%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "            log_record['timestamp'] = now\n",
    "        if log_record.get('level'):\n",
    "            log_record['level'] = log_record['level'].upper()\n",
    "        else:\n",
    "            log_record['level'] = record.levelname\n",
    "\n",
    "JSON_LOGGING_CONFIG = {\n",
    "    'version': 1,\n",
    "    'disable_existing_loggers': False,\n",
    "    'formatters': {\n",
    "        'json': {\n",
    "            # Reference the custom class using its full path\n",
    "            '()': '__main__.CustomJsonFormatter', # Use '__main__' in notebooks, or the actual module path\n",
    "            'format': '%(timestamp)s %(level)s %(name)s %(message)s %(filename)s %(lineno)d'\n",
    "        }\n",
    "    },\n",
    "    'handlers': {\n",
    "        'json_console': {\n",
    "            'class': 'logging.StreamHandler',\n",
    "            'level': 'INFO',\n",
    "            'formatter': 'json',\n",
    "            'stream': 'ext://sys.stderr'\n",
    "        }\n",
    "    },\n",
    "    'loggers': {\n",
    "        'json_app': {\n",
    "            'level': 'INFO',\n",
    "            'handlers': ['json_console'],\n",
    "            'propagate': False\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "logging.config.dictConfig(JSON_LOGGING_CONFIG)\n",
    "\n",
    "json_logger = logging.getLogger('json_app.worker')\n",
    "\n",
    "print(\"\\n--- JSON Structured Logging --- \")\n",
    "# Logging simple messages\n",
    "json_logger.info(\"Worker process started.\")\n",
    "\n",
    "# Logging with extra context (becomes part of the JSON object)\n",
    "extra_data = {\n",
    "    'user_id': 'user-123',\n",
    "    'request_id': 'req-abc-987',\n",
    "    'elapsed_ms': 55.6\n",
    "}\n",
    "json_logger.info(\"Processed task successfully.\", extra={'extra_data': extra_data})\n",
    "json_logger.error(\"Failed to update record.\", extra={'record_id': 456, 'reason': 'DB timeout'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Libraries like `structlog` offer even more advanced features for structured logging, including processors for adding context automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Logging Exceptions\n",
    "\n",
    "It's crucial to log the full traceback when an exception occurs to understand the context of the error.\n",
    "\n",
    "*   **`logger.exception(msg, *args, **kwargs)`:** Logs a message with level ERROR and automatically includes the current exception information (traceback).\n",
    "*   **`logger.error(msg, *args, exc_info=True, **kwargs)`:** Logs a message with level ERROR and explicitly requests the exception information to be included.\n",
    "\n",
    "Use these inside an `except` block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Exception Logging --- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:13:41 - exception_demo - ERROR - Calculation failed due to division by zero. Original error: division by zero\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_9931/2592193953.py\", line 11, in <module>\n",
      "    result = 10 / 0\n",
      "             ~~~^~~\n",
      "ZeroDivisionError: division by zero\n",
      "16:13:41 - exception_demo - ERROR - Index out of bounds accessing list. Error: list index out of range\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_9931/2592193953.py\", line 18, in <module>\n",
      "    val = my_list[5]\n",
      "          ~~~~~~~^^^\n",
      "IndexError: list index out of range\n",
      "16:13:41 - exception_demo - ERROR - Could not convert string to int. Manual traceback logging needed if required.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "# Assuming basicConfig or dictConfig has been run previously\n",
    "# If not, uncomment the basicConfig line:\n",
    "# logging.basicConfig(level=logging.ERROR, force=True, stream=sys.stderr)\n",
    "logger = logging.getLogger('exception_demo')\n",
    "logger.propagate = True # Ensure it goes to root handler if basicConfig was used\n",
    "\n",
    "print(\"\\n--- Exception Logging --- \")\n",
    "try:\n",
    "    result = 10 / 0\n",
    "except ZeroDivisionError as e:\n",
    "    # Method 1: logger.exception (preferred for brevity)\n",
    "    logger.exception(f\"Calculation failed due to division by zero. Original error: {e}\")\n",
    "\n",
    "try:\n",
    "    my_list = [1, 2]\n",
    "    val = my_list[5]\n",
    "except IndexError as e:\n",
    "    # Method 2: logger.error with exc_info=True\n",
    "    logger.error(f\"Index out of bounds accessing list. Error: {e}\", exc_info=True)\n",
    "\n",
    "try:\n",
    "    x = int('abc')\n",
    "except ValueError:\n",
    "    # Example of logging without automatic traceback (less ideal for exceptions)\n",
    "    logger.error(\"Could not convert string to int. Manual traceback logging needed if required.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Useful Handlers\n",
    "\n",
    "Beyond `StreamHandler` and `FileHandler`:\n",
    "\n",
    "*   **`logging.handlers.RotatingFileHandler`:** Rotates log files when they reach a certain size (`maxBytes`). Keeps a specified number of backup files (`backupCount`). Essential for preventing log files from filling up disk space.\n",
    "*   **`logging.handlers.TimedRotatingFileHandler`:** Rotates log files at specific time intervals (`when`, `interval`, e.g., daily, hourly). Also keeps backups (`backupCount`). Useful for archiving logs based on time.\n",
    "*   **`logging.handlers.SocketHandler` / `DatagramHandler`:** Sends log records over TCP or UDP, respectively (e.g., to a central log server).\n",
    "*   **`logging.handlers.SysLogHandler`:** Sends logs to a Unix/Linux syslog daemon.\n",
    "*   **`logging.handlers.NTEventLogHandler`:** Sends logs to the Windows Event Log.\n",
    "*   **`logging.handlers.SMTPHandler`:** Sends critical logs via email.\n",
    "*   **`logging.handlers.QueueHandler` / `QueueListener`:** (Advanced) Useful for sending logs from multiple processes or threads to a central logging process without blocking the worker processes/threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- RotatingFileHandler Demo (logging to rotating_app.log) ---\n",
      "Check rotating_app.log and its backups (e.g., rotating_app.log.1)\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import time\n",
    "from logging.handlers import RotatingFileHandler, TimedRotatingFileHandler\n",
    "\n",
    "# --- RotatingFileHandler Example ---\n",
    "rotate_logger = logging.getLogger('rotator')\n",
    "rotate_logger.setLevel(logging.INFO)\n",
    "rotate_logger.propagate = False\n",
    "\n",
    "# Rotate after 1KB (small for demo), keep 3 backup files (app.log, app.log.1, app.log.2)\n",
    "rotate_handler = RotatingFileHandler('rotating_app.log', maxBytes=1024, backupCount=3, encoding='utf-8')\n",
    "rotate_format = logging.Formatter('%(asctime)s - %(message)s')\n",
    "rotate_handler.setFormatter(rotate_format)\n",
    "\n",
    "if not rotate_logger.handlers:\n",
    "    rotate_logger.addHandler(rotate_handler)\n",
    "\n",
    "print(\"\\n--- RotatingFileHandler Demo (logging to rotating_app.log) ---\")\n",
    "# Log enough data to trigger rotation\n",
    "for i in range(20):\n",
    "    rotate_logger.info(f\"Log entry number {i+1} with some padding text to increase size.\")\n",
    "print(\"Check rotating_app.log and its backups (e.g., rotating_app.log.1)\")\n",
    "\n",
    "# --- TimedRotatingFileHandler Example ---\n",
    "timed_logger = logging.getLogger('timer')\n",
    "timed_logger.setLevel(logging.DEBUG)\n",
    "timed_logger.propagate = False\n",
    "\n",
    "# Rotate every 5 seconds (short for demo), keep 2 backups\n",
    "# 'when' options: 's', 'm', 'h', 'd', 'midnight', 'w0'-'w6'\n",
    "timed_handler = TimedRotatingFileHandler('timed_app.log', when='s', interval=5, backupCount=2, encoding='utf-8')\n",
    "timed_format = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "timed_handler.setFormatter(timed_format)\n",
    "\n",
    "if not timed_logger.handlers:\n",
    "    timed_logger.addHandler(timed_handler)\n",
    "\n",
    "# print(\"\\n--- TimedRotatingFileHandler Demo (logging every second for ~12s) ---\")\n",
    "# for i in range(12):\n",
    "#     timed_logger.debug(f\"Timed log entry {i+1}\")\n",
    "#     time.sleep(1)\n",
    "# print(\"Check timed_app.log and its timestamped backups (e.g., timed_app.log.YYYY-MM-DD_HH-MM-SS)\")\n",
    "\n",
    "# Clean up handlers to avoid interference if cell is re-run\n",
    "rotate_logger.removeHandler(rotate_handler)\n",
    "timed_logger.removeHandler(timed_handler)\n",
    "rotate_handler.close()\n",
    "timed_handler.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Enterprise Best Practices & Considerations\n",
    "\n",
    "1.  **Use `getLogger(__name__)`:** Always get module-specific loggers.\n",
    "2.  **Configure via `dictConfig` (or File):** Externalize configuration from code. Load from YAML/JSON for flexibility.\n",
    "3.  **Use Structured Logging (JSON):** Essential for centralized logging systems (ELK, Splunk, Datadog, CloudWatch Logs, etc.). Makes logs searchable and analyzable.\n",
    "4.  **Log Exceptions Correctly:** Use `logger.exception()` or `logger.error(..., exc_info=True)`.\n",
    "5.  **Choose Appropriate Levels:** Don't overuse DEBUG in production. Log INFO for key workflow steps, WARNING for recoverable issues, ERROR/CRITICAL for serious problems.\n",
    "6.  **Include Context:** Add relevant information (user IDs, request IDs, correlation IDs) to log messages (use `extra` dictionary or structured logging features). This is vital for tracing requests across services.\n",
    "7.  **Avoid Logging Sensitive Data:** Never log passwords, API keys, personal information (PII), etc., unless absolutely necessary and properly secured/masked. Be mindful of GDPR and other privacy regulations.\n",
    "8.  **Use Rotating Handlers:** Prevent logs from consuming all disk space (`RotatingFileHandler` or `TimedRotatingFileHandler`).\n",
    "9.  **Performance:** Logging has overhead. Avoid excessive logging (especially DEBUG) in performance-critical code paths. Consider asynchronous logging (`QueueHandler`) if logging becomes a bottleneck.\n",
    "10. **Centralized Logging:** In distributed systems (microservices), send logs from all services to a central platform for unified viewing and analysis.\n",
    "11. **Consistency:** Establish logging conventions (format, levels, context fields) across your team or organization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Pitfalls and Common Interview Questions\n",
    "\n",
    "**Common Pitfalls:**\n",
    "\n",
    "*   **Calling `basicConfig` too late:** It has no effect if a logger has already been configured.\n",
    "*   **Duplicate Logs:** Usually caused by `propagate = True` (default) and handlers configured on both a child and ancestor logger.\n",
    "*   **Forgetting `getLogger(__name__)`:** Using the root logger directly everywhere makes fine-grained control difficult.\n",
    "*   **Logging Sensitive Information:** A major security risk.\n",
    "*   **Excessive Logging:** Filling disks or incurring high costs in cloud logging services.\n",
    "*   **Inconsistent Formatting:** Makes automated parsing difficult.\n",
    "*   **Not Logging Tracebacks:** Makes debugging errors much harder.\n",
    "*   **Blocking I/O:** Synchronous logging to slow destinations (network, busy disk) can block your application.\n",
    "\n",
    "**Common Interview Questions:**\n",
    "\n",
    "1.  Why use logging instead of `print()`?\n",
    "2.  Explain the different logging levels.\n",
    "3.  How do you configure logging in Python? (Mention `basicConfig`, `dictConfig`).\n",
    "4.  What are Handlers, Formatters, and Filters?\n",
    "5.  What is the purpose of `logging.getLogger(__name__)`?\n",
    "6.  What is logger propagation?\n",
    "7.  How would you log an exception with its traceback?\n",
    "8.  What is structured logging (e.g., JSON logging) and why is it important?\n",
    "9.  How can you prevent log files from becoming too large?\n",
    "10. What are some best practices for logging in a production application?\n",
    "11. How would you add contextual information (like a request ID) to all log messages for a specific request?\n",
    "12. What security considerations are important when logging?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Challenge: Configure Logging for a Multi-Module App\n",
    "\n",
    "**Scenario:** You have a simple application with two modules: `main_app.py` and `utils.py`.\n",
    "\n",
    "**`utils.py`:**\n",
    "```python\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__) # Should be 'utils'\n",
    "\n",
    "def process_data(data):\n",
    "    logger.debug(f\"Processing data: {data!r}\")\n",
    "    if not isinstance(data, dict):\n",
    "        logger.warning(\"Invalid data type received, expected dict.\")\n",
    "        return None\n",
    "    result = data.get('value', 0) * 2\n",
    "    logger.info(\"Data processed successfully.\")\n",
    "    return result\n",
    "```\n",
    "\n",
    "**`main_app.py`:**\n",
    "```python\n",
    "import logging\n",
    "import logging.config\n",
    "# Assume utils.py is in the same directory or sys.path\n",
    "import utils \n",
    "\n",
    "# --- Your logging configuration dictionary here --- \n",
    "LOGGING_CONFIG = {\n",
    "    'version': 1,\n",
    "    'disable_existing_loggers': False,\n",
    "    # ... Add formatters, handlers, loggers ... \n",
    "}\n",
    "\n",
    "logging.config.dictConfig(LOGGING_CONFIG)\n",
    "\n",
    "main_logger = logging.getLogger(__name__) # Should be '__main__'\n",
    "\n",
    "def run_app():\n",
    "    main_logger.info(\"Application starting.\")\n",
    "    result1 = utils.process_data({'value': 10})\n",
    "    main_logger.debug(f\"Result 1: {result1}\")\n",
    "    \n",
    "    result2 = utils.process_data(\"bad data\")\n",
    "    main_logger.debug(f\"Result 2: {result2}\")\n",
    "    \n",
    "    try:\n",
    "        x = 1 / 0\n",
    "    except ZeroDivisionError:\n",
    "        main_logger.exception(\"An error occurred during calculation.\")\n",
    "        \n",
    "    main_logger.info(\"Application finished.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_app()\n",
    "```\n",
    "\n",
    "**Task:**\n",
    "\n",
    "1.  Create the `LOGGING_CONFIG` dictionary for `main_app.py` using `dictConfig`.\n",
    "2.  Configure it to meet these requirements:\n",
    "    *   Log `INFO` level and above from *all* loggers (`__main__`, `utils`) to the console using a simple format (`%(levelname)s:%(name)s:%(message)s`).\n",
    "    *   Log `DEBUG` level and above *only* from the `utils` logger to a file named `utils_debug.log` using a detailed format (`%(asctime)s - %(name)s - %(levelname)s - %(message)s`).\n",
    "    *   Log `ERROR` level and above from *all* loggers to a file named `app_errors.log` including detailed formatting and traceback info where applicable.\n",
    "3.  Ensure logs are not duplicated unnecessarily.\n",
    "4.  (Bonus) Modify the configuration to use JSON formatting for the console output.\n",
    "\n",
    "*(Self-Correction Note: Think about logger levels vs handler levels and propagation when designing the config!)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Conclusion\n",
    "\n",
    "Effective logging is a cornerstone of professional software development. Moving beyond basic `print` statements to utilize Python's `logging` module provides structure, control, and invaluable insights into your application's behavior. By mastering levels, configuration (especially `dictConfig`), handlers, formatters, structured logging, and best practices, you can build applications that are significantly easier to debug, monitor, and maintain in any environment.\n",
    "\n",
    "Remember to treat logging configuration as part of your application's architecture, adapting it as your application grows and evolves."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
